{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPLyWIxYtgLcfkfDhNBjleT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chiseng/DeepLearning/blob/master/DL3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8j4ztTPBRXzK",
        "colab_type": "text"
      },
      "source": [
        "# Part 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuc77eA7ovQK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np, os, sys\n",
        " \n",
        "import matplotlib.pyplot as plt #patch-wise similarities, droi images\n",
        "from matplotlib import ticker, cm\n",
        " \n",
        "import torch.nn as nn\n",
        "import torch.utils.data \n",
        " \n",
        "import torch.optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kaye_h9Iz65u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def datagen2d_m(mean2, flip, num):\n",
        "   \n",
        "  a1=np.pi*0.0\n",
        "  mat1=np.array([ [np.cos(a1), np.sin(a1)  ], [ -np.sin(a1), np.cos(a1)] ] ) \n",
        " \n",
        "  a2=np.pi*0.2\n",
        "  mat2=np.array([ [np.cos(a2), np.sin(a2)  ], [ -np.sin(a2), np.cos(a2)] ] ) \n",
        " \n",
        " \n",
        "  z1=np.random.normal(size=(num//2,2))\n",
        "  z1[:,0]=z1[:,0]*3\n",
        "  x1=np.dot(z1,mat1) \n",
        "  z2=np.random.normal(size=(num-num//2,2))\n",
        "  z2[:,0]=z2[:,0]*3\n",
        "  x2=np.dot(z2,mat2) + mean2.reshape((1,2))\n",
        " \n",
        "  y1= (np.random.ranf(size=(num//2)) >= flip ).astype(dtype=np.float64)  #np.ones((num//2))+\n",
        "  y2=  (np.random.ranf(size=(num-num//2)) <= flip ).astype(dtype=np.float64) #np.zeros((num-num//2,2))\n",
        " \n",
        "  # random label noise in y1, y2\n",
        " \n",
        "  x=np.concatenate((x1,x2),axis=0) #existing axis\n",
        "  y=np.concatenate((y1,y2),axis=0) #existing axis\n",
        " \n",
        "  #x.shape=(numdata,dims) dims=2 here\n",
        "  #y.shape=(numdata)\n",
        " \n",
        "  print('means',np.mean(y1),np.mean(y2),np.mean(y))\n",
        "  print(x.shape,y.shape)\n",
        " \n",
        "  # randomly permute\n",
        "  inds=np.arange(num)\n",
        "  np.random.shuffle(inds)\n",
        "  x=x[inds,:]\n",
        "  y=y[inds]\n",
        " \n",
        "  return x,y # y is 0 or 1 \n",
        " \n",
        "def rndsplit_simple(x,y,numtr):\n",
        " \n",
        "  inds=np.arange(y.size)\n",
        "  np.random.shuffle(inds)\n",
        " \n",
        "  xtr=x[inds[0:numtr],:]\n",
        "  ytr=y[inds[0:numtr]]\n",
        " \n",
        "  xv=x[inds[numtr:],:]\n",
        "  yv=y[inds[numtr:]]\n",
        " \n",
        "  return xtr,ytr,xv,yv\n",
        " \n",
        " \n",
        "def gendata():\n",
        "  mean2=np.asarray([1,3])\n",
        "  flip=0.1\n",
        "  num=5000\n",
        "  x,y=datagen2d_m(mean2, flip, num)\n",
        "  numtr=3000\n",
        "  xtr,ytr,xvt,yvt=rndsplit_simple(x,y,numtr)\n",
        "  xv,yv,xt,yt=rndsplit_simple(xvt,yvt,numtr=1000)\n",
        " \n",
        "  return xtr,ytr,xv,yv,xt,yt\n",
        " \n",
        " \n",
        "def visualize_data(xv,yv,w,bias):\n",
        "   \n",
        "  possamples=xv[ yv>0, : ]\n",
        "  negsamples=xv[ yv<=0, : ]\n",
        " \n",
        "  plt.plot(negsamples[:,0],negsamples[:,1],'bx')\n",
        "  plt.plot(possamples[:,0],possamples[:,1],'rx')\n",
        " \n",
        "  #plot wx+b=0 ... wx= -b, x= a w^O + w/\\|w\\|^2 * -b\n",
        " \n",
        " \n",
        "  def vis1():\n",
        "    a=np.linspace(-10,10,200)\n",
        "    worthogonal = np.asarray ( [ -w[1] ,  w[0]   ] ) \n",
        "    normedwtimesbias= -bias * w / np.linalg.norm(w)\n",
        " \n",
        "    points=  a*  worthogonal / np.linalg.norm(w) + normedwtimesbias\n",
        "    points=points.T\n",
        "    print(points.shape, w.shape)  \n",
        " \n",
        "    plt.plot(points[:,0],points[:,1],'c-', linewidth=5)\n",
        " \n",
        "  def vis2():\n",
        "    delta=0.05\n",
        "    x = np.arange(-10.0, 12.0, delta)\n",
        "    y = np.arange(-10.0, 12.0, delta)\n",
        "    X, Y = np.meshgrid(x, y)  \n",
        " \n",
        "    U = bias + w[0]*X+ w[1]*Y  \n",
        "    Z= 1.0/(1.0+np.exp(-U))\n",
        " \n",
        "    CS = plt.contourf(X, Y, Z, levels=8,cmap=cm.viridis) #coolwarm\n",
        " \n",
        " \n",
        "  vis2()\n",
        "  plt.show()\n",
        " \n",
        " \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_oieNfqupb_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class logreglayer(nn.Module):\n",
        "  def __init__(self,dims):\n",
        "     \n",
        "    super(logreglayer, self).__init__() #initialize base class\n",
        " \n",
        "    self.bias=torch.nn.Parameter(data=torch.zeros(1),requires_grad=True)\n",
        "    self.w=torch.nn.Parameter(torch.randn((dims,1),dtype=torch.float64),requires_grad=True)     #TODO\n",
        " \n",
        "  def forward(self,x):\n",
        "    z = torch.matmul(x,self.w)\n",
        "    retval = torch.add(self.bias,z)\n",
        "    return retval"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3nYwkzd0MPK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_epoch(model,  trainloader,  criterion, device, optimizer, no_grad):\n",
        " \n",
        "     \n",
        "    model.train()\n",
        "  \n",
        "    losses = list()\n",
        "    for batch_idx, data in enumerate(trainloader):\n",
        " \n",
        "        inputs=data[0].to(device)\n",
        "        labels=data[1].to(device)\n",
        " \n",
        "        optimizer.zero_grad()\n",
        " \n",
        "        output = model(inputs)\n",
        " \n",
        "        loss = criterion(output.squeeze(1), labels)\n",
        "        loss.backward()\n",
        " \n",
        " \n",
        "        #apply gradient to your parameters in model ... model.w and model.bias ... remember about data and grad :) \n",
        "        #TODO\n",
        "        if no_grad:\n",
        "            with torch.no_grad():\n",
        "                model.w -= 0.01*model.w.grad\n",
        "                model.bias -= 0.01*model.bias.grad\n",
        "        else:\n",
        "            optimizer.step()\n",
        " \n",
        "        losses.append(loss.item())\n",
        " \n",
        "    return losses\n",
        "\n",
        "    \n",
        "\n",
        "def evaluate(model, dataloader, criterion, device):\n",
        " \n",
        "    model.eval()\n",
        " \n",
        "    gtpos=0\n",
        "    gtneg=0\n",
        "    tps=0\n",
        "    tns=0\n",
        "    fbeta=1\n",
        " \n",
        "    running_corrects = 0\n",
        "    with torch.no_grad():\n",
        "      for ctr, data in enumerate(dataloader):\n",
        " \n",
        "          print ('epoch at',len(dataloader.dataset), ctr)\n",
        "          inputs = data[0].to(device)        \n",
        "          outputs = model(inputs)\n",
        " \n",
        "          labels = data[1]\n",
        "          labels = labels.float()\n",
        "          cpuout= outputs.to('cpu')\n",
        " \n",
        "          #_, preds = torch.max(cpuout, 1)\n",
        "          preds = ( cpuout >= 0.5 ).squeeze(1)\n",
        "          running_corrects += torch.sum(preds == labels.data)\n",
        " \n",
        "      accuracy = running_corrects.double() / len(dataloader.dataset) # this does not work if one uses a datasampler!!!\n",
        " \n",
        "    return accuracy.item() \n",
        "\n",
        "\n",
        "\n",
        "def train_modelcv(dataloader_cvtrain, dataloader_cvtest ,  model ,  criterion, optimizer, scheduler, num_epochs, device, no_grad):\n",
        " \n",
        "  best_measure = 0\n",
        "  best_epoch =-1\n",
        " \n",
        "  for epoch in range(num_epochs):\n",
        "    print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "    print('-' * 10)\n",
        " \n",
        "    model.train(True)\n",
        "    losses=train_epoch(model,  dataloader_cvtrain,  criterion,  device , optimizer,no_grad)\n",
        "    #scheduler.step()\n",
        " \n",
        "    model.train(False)\n",
        "    measure = evaluate(model, dataloader_cvtest, criterion, device)\n",
        "    print(' perfmeasure', measure)\n",
        " \n",
        "    if measure > best_measure: \n",
        "      bestweights= model.state_dict()\n",
        "      best_measure = measure\n",
        "      best_epoch = epoch\n",
        "      print('current best', measure, ' at epoch ', best_epoch)\n",
        " \n",
        "  return best_epoch, best_measure, bestweights\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YYW6OQ-0KF0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run(no_grad=False):\n",
        " \n",
        "  #some parameters\n",
        "  #training batch size\n",
        "  batch_size=8\n",
        "  #validation batch size\n",
        "  valbatch_size=32\n",
        "  # number of epochs for training\n",
        "  maxnumepochs=12\n",
        "  # learning rate\n",
        "  learningrate=0.01\n",
        " \n",
        " \n",
        "   \n",
        "  #define dataset\n",
        "  xtr,ytr,xv,yv,xt,yt=gendata()\n",
        "  xtr = torch.from_numpy(xtr)\n",
        "  ytr = torch.from_numpy(ytr)\n",
        "  xv = torch.from_numpy(xv)\n",
        "  yv = torch.from_numpy(yv)\n",
        "  xt = torch.from_numpy(xt)\n",
        "  yt = torch.from_numpy(yt)\n",
        "  #Tensordataset\n",
        "  #TODO\n",
        "  dtr= torch.utils.data.TensorDataset(xtr,ytr) #TensorDataset from tensors from xtr, ytr - our training features and labels\n",
        "  dv= torch.utils.data.TensorDataset(xv,yv)# TensorDataset from tensors from xv, yv - our validation features and labels\n",
        "  #define dataloader over dataset\n",
        "  loadertr=torch.utils.data.DataLoader(dtr,batch_size=batch_size,shuffle=True) # returns an iterator\n",
        "  loaderval=torch.utils.data.DataLoader(dv,batch_size=valbatch_size,shuffle=False)\n",
        " \n",
        "  #model and loss\n",
        "  #TODO\n",
        "  model= logreglayer(xtr.shape[-1])# your logreglayer properly initialized\n",
        "  z = model.forward(xtr)\n",
        "  #TODO\n",
        "  criterion = torch.nn.BCEWithLogitsLoss() # which loss function suits here, given that our model produces 1-dimensional output  and we want to use it for classification?\n",
        " \n",
        "  optimizer=torch.optim.SGD(model.parameters(),lr=learningrate, momentum=0.0, weight_decay=0)\n",
        "  device=torch.device('cpu')\n",
        " \n",
        " \n",
        "  best_epoch, best_perfmeasure, bestweights = train_modelcv(dataloader_cvtrain = loadertr, dataloader_cvtest = loaderval ,  model = model ,  criterion = criterion , optimizer = optimizer, scheduler = None, num_epochs = maxnumepochs , device = device, no_grad = no_grad)\n",
        " \n",
        " \n",
        "   \n",
        "  model.load_state_dict(bestweights)\n",
        " \n",
        "  #TODO\n",
        "  dte= torch.utils.data.TensorDataset(xt,yt)# TensorDataset from tensors from xte, yte - our test features and labels\n",
        "  loaderte=torch.utils.data.DataLoader(dte,batch_size=valbatch_size,shuffle=False)\n",
        " \n",
        "  test_accuracy= evaluate(model = model, dataloader = loaderte, criterion = None, device = device)\n",
        " \n",
        "  print('validation accuracy',best_perfmeasure, 'test accuracy',test_accuracy)\n",
        " \n",
        "  visualize_data(xt,yt,model.w.detach(),model.bias.detach())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYzf1DTXkg76",
        "colab_type": "code",
        "outputId": "c21f99fe-095c-4ac4-9aa4-11ec3f0230b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "    #run with manual update, insert no_grad=True as parameter as parameter\n",
        "    run()\n",
        "    run(no_grad=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "means 0.8976 0.096 0.4968\n",
            "(5000, 2) (5000,)\n",
            "Epoch 0/11\n",
            "----------\n",
            "epoch at 1000 0\n",
            "epoch at 1000 1\n",
            "epoch at 1000 2\n",
            "epoch at 1000 3\n",
            "epoch at 1000 4\n",
            "epoch at 1000 5\n",
            "epoch at 1000 6\n",
            "epoch at 1000 7\n",
            "epoch at 1000 8\n",
            "epoch at 1000 9\n",
            "epoch at 1000 10\n",
            "epoch at 1000 11\n",
            "epoch at 1000 12\n",
            "epoch at 1000 13\n",
            "epoch at 1000 14\n",
            "epoch at 1000 15\n",
            "epoch at 1000 16\n",
            "epoch at 1000 17\n",
            "epoch at 1000 18\n",
            "epoch at 1000 19\n",
            "epoch at 1000 20\n",
            "epoch at 1000 21\n",
            "epoch at 1000 22\n",
            "epoch at 1000 23\n",
            "epoch at 1000 24\n",
            "epoch at 1000 25\n",
            "epoch at 1000 26\n",
            "epoch at 1000 27\n",
            "epoch at 1000 28\n",
            "epoch at 1000 29\n",
            "epoch at 1000 30\n",
            "epoch at 1000 31\n",
            " perfmeasure 0.617\n",
            "current best 0.617  at epoch  0\n",
            "Epoch 1/11\n",
            "----------\n",
            "epoch at 1000 0\n",
            "epoch at 1000 1\n",
            "epoch at 1000 2\n",
            "epoch at 1000 3\n",
            "epoch at 1000 4\n",
            "epoch at 1000 5\n",
            "epoch at 1000 6\n",
            "epoch at 1000 7\n",
            "epoch at 1000 8\n",
            "epoch at 1000 9\n",
            "epoch at 1000 10\n",
            "epoch at 1000 11\n",
            "epoch at 1000 12\n",
            "epoch at 1000 13\n",
            "epoch at 1000 14\n",
            "epoch at 1000 15\n",
            "epoch at 1000 16\n",
            "epoch at 1000 17\n",
            "epoch at 1000 18\n",
            "epoch at 1000 19\n",
            "epoch at 1000 20\n",
            "epoch at 1000 21\n",
            "epoch at 1000 22\n",
            "epoch at 1000 23\n",
            "epoch at 1000 24\n",
            "epoch at 1000 25\n",
            "epoch at 1000 26\n",
            "epoch at 1000 27\n",
            "epoch at 1000 28\n",
            "epoch at 1000 29\n",
            "epoch at 1000 30\n",
            "epoch at 1000 31\n",
            " perfmeasure 0.682\n",
            "current best 0.682  at epoch  1\n",
            "Epoch 2/11\n",
            "----------\n",
            "epoch at 1000 0\n",
            "epoch at 1000 1\n",
            "epoch at 1000 2\n",
            "epoch at 1000 3\n",
            "epoch at 1000 4\n",
            "epoch at 1000 5\n",
            "epoch at 1000 6\n",
            "epoch at 1000 7\n",
            "epoch at 1000 8\n",
            "epoch at 1000 9\n",
            "epoch at 1000 10\n",
            "epoch at 1000 11\n",
            "epoch at 1000 12\n",
            "epoch at 1000 13\n",
            "epoch at 1000 14\n",
            "epoch at 1000 15\n",
            "epoch at 1000 16\n",
            "epoch at 1000 17\n",
            "epoch at 1000 18\n",
            "epoch at 1000 19\n",
            "epoch at 1000 20\n",
            "epoch at 1000 21\n",
            "epoch at 1000 22\n",
            "epoch at 1000 23\n",
            "epoch at 1000 24\n",
            "epoch at 1000 25\n",
            "epoch at 1000 26\n",
            "epoch at 1000 27\n",
            "epoch at 1000 28\n",
            "epoch at 1000 29\n",
            "epoch at 1000 30\n",
            "epoch at 1000 31\n",
            " perfmeasure 0.73\n",
            "current best 0.73  at epoch  2\n",
            "Epoch 3/11\n",
            "----------\n",
            "epoch at 1000 0\n",
            "epoch at 1000 1\n",
            "epoch at 1000 2\n",
            "epoch at 1000 3\n",
            "epoch at 1000 4\n",
            "epoch at 1000 5\n",
            "epoch at 1000 6\n",
            "epoch at 1000 7\n",
            "epoch at 1000 8\n",
            "epoch at 1000 9\n",
            "epoch at 1000 10\n",
            "epoch at 1000 11\n",
            "epoch at 1000 12\n",
            "epoch at 1000 13\n",
            "epoch at 1000 14\n",
            "epoch at 1000 15\n",
            "epoch at 1000 16\n",
            "epoch at 1000 17\n",
            "epoch at 1000 18\n",
            "epoch at 1000 19\n",
            "epoch at 1000 20\n",
            "epoch at 1000 21\n",
            "epoch at 1000 22\n",
            "epoch at 1000 23\n",
            "epoch at 1000 24\n",
            "epoch at 1000 25\n",
            "epoch at 1000 26\n",
            "epoch at 1000 27\n",
            "epoch at 1000 28\n",
            "epoch at 1000 29\n",
            "epoch at 1000 30\n",
            "epoch at 1000 31\n",
            " perfmeasure 0.74\n",
            "current best 0.74  at epoch  3\n",
            "Epoch 4/11\n",
            "----------\n",
            "epoch at 1000 0\n",
            "epoch at 1000 1\n",
            "epoch at 1000 2\n",
            "epoch at 1000 3\n",
            "epoch at 1000 4\n",
            "epoch at 1000 5\n",
            "epoch at 1000 6\n",
            "epoch at 1000 7\n",
            "epoch at 1000 8\n",
            "epoch at 1000 9\n",
            "epoch at 1000 10\n",
            "epoch at 1000 11\n",
            "epoch at 1000 12\n",
            "epoch at 1000 13\n",
            "epoch at 1000 14\n",
            "epoch at 1000 15\n",
            "epoch at 1000 16\n",
            "epoch at 1000 17\n",
            "epoch at 1000 18\n",
            "epoch at 1000 19\n",
            "epoch at 1000 20\n",
            "epoch at 1000 21\n",
            "epoch at 1000 22\n",
            "epoch at 1000 23\n",
            "epoch at 1000 24\n",
            "epoch at 1000 25\n",
            "epoch at 1000 26\n",
            "epoch at 1000 27\n",
            "epoch at 1000 28\n",
            "epoch at 1000 29\n",
            "epoch at 1000 30\n",
            "epoch at 1000 31\n",
            " perfmeasure 0.754\n",
            "current best 0.754  at epoch  4\n",
            "Epoch 5/11\n",
            "----------\n",
            "epoch at 1000 0\n",
            "epoch at 1000 1\n",
            "epoch at 1000 2\n",
            "epoch at 1000 3\n",
            "epoch at 1000 4\n",
            "epoch at 1000 5\n",
            "epoch at 1000 6\n",
            "epoch at 1000 7\n",
            "epoch at 1000 8\n",
            "epoch at 1000 9\n",
            "epoch at 1000 10\n",
            "epoch at 1000 11\n",
            "epoch at 1000 12\n",
            "epoch at 1000 13\n",
            "epoch at 1000 14\n",
            "epoch at 1000 15\n",
            "epoch at 1000 16\n",
            "epoch at 1000 17\n",
            "epoch at 1000 18\n",
            "epoch at 1000 19\n",
            "epoch at 1000 20\n",
            "epoch at 1000 21\n",
            "epoch at 1000 22\n",
            "epoch at 1000 23\n",
            "epoch at 1000 24\n",
            "epoch at 1000 25\n",
            "epoch at 1000 26\n",
            "epoch at 1000 27\n",
            "epoch at 1000 28\n",
            "epoch at 1000 29\n",
            "epoch at 1000 30\n",
            "epoch at 1000 31\n",
            " perfmeasure 0.758\n",
            "current best 0.758  at epoch  5\n",
            "Epoch 6/11\n",
            "----------\n",
            "epoch at 1000 0\n",
            "epoch at 1000 1\n",
            "epoch at 1000 2\n",
            "epoch at 1000 3\n",
            "epoch at 1000 4\n",
            "epoch at 1000 5\n",
            "epoch at 1000 6\n",
            "epoch at 1000 7\n",
            "epoch at 1000 8\n",
            "epoch at 1000 9\n",
            "epoch at 1000 10\n",
            "epoch at 1000 11\n",
            "epoch at 1000 12\n",
            "epoch at 1000 13\n",
            "epoch at 1000 14\n",
            "epoch at 1000 15\n",
            "epoch at 1000 16\n",
            "epoch at 1000 17\n",
            "epoch at 1000 18\n",
            "epoch at 1000 19\n",
            "epoch at 1000 20\n",
            "epoch at 1000 21\n",
            "epoch at 1000 22\n",
            "epoch at 1000 23\n",
            "epoch at 1000 24\n",
            "epoch at 1000 25\n",
            "epoch at 1000 26\n",
            "epoch at 1000 27\n",
            "epoch at 1000 28\n",
            "epoch at 1000 29\n",
            "epoch at 1000 30\n",
            "epoch at 1000 31\n",
            " perfmeasure 0.763\n",
            "current best 0.763  at epoch  6\n",
            "Epoch 7/11\n",
            "----------\n",
            "epoch at 1000 0\n",
            "epoch at 1000 1\n",
            "epoch at 1000 2\n",
            "epoch at 1000 3\n",
            "epoch at 1000 4\n",
            "epoch at 1000 5\n",
            "epoch at 1000 6\n",
            "epoch at 1000 7\n",
            "epoch at 1000 8\n",
            "epoch at 1000 9\n",
            "epoch at 1000 10\n",
            "epoch at 1000 11\n",
            "epoch at 1000 12\n",
            "epoch at 1000 13\n",
            "epoch at 1000 14\n",
            "epoch at 1000 15\n",
            "epoch at 1000 16\n",
            "epoch at 1000 17\n",
            "epoch at 1000 18\n",
            "epoch at 1000 19\n",
            "epoch at 1000 20\n",
            "epoch at 1000 21\n",
            "epoch at 1000 22\n",
            "epoch at 1000 23\n",
            "epoch at 1000 24\n",
            "epoch at 1000 25\n",
            "epoch at 1000 26\n",
            "epoch at 1000 27\n",
            "epoch at 1000 28\n",
            "epoch at 1000 29\n",
            "epoch at 1000 30\n",
            "epoch at 1000 31\n",
            " perfmeasure 0.765\n",
            "current best 0.765  at epoch  7\n",
            "Epoch 8/11\n",
            "----------\n",
            "epoch at 1000 0\n",
            "epoch at 1000 1\n",
            "epoch at 1000 2\n",
            "epoch at 1000 3\n",
            "epoch at 1000 4\n",
            "epoch at 1000 5\n",
            "epoch at 1000 6\n",
            "epoch at 1000 7\n",
            "epoch at 1000 8\n",
            "epoch at 1000 9\n",
            "epoch at 1000 10\n",
            "epoch at 1000 11\n",
            "epoch at 1000 12\n",
            "epoch at 1000 13\n",
            "epoch at 1000 14\n",
            "epoch at 1000 15\n",
            "epoch at 1000 16\n",
            "epoch at 1000 17\n",
            "epoch at 1000 18\n",
            "epoch at 1000 19\n",
            "epoch at 1000 20\n",
            "epoch at 1000 21\n",
            "epoch at 1000 22\n",
            "epoch at 1000 23\n",
            "epoch at 1000 24\n",
            "epoch at 1000 25\n",
            "epoch at 1000 26\n",
            "epoch at 1000 27\n",
            "epoch at 1000 28\n",
            "epoch at 1000 29\n",
            "epoch at 1000 30\n",
            "epoch at 1000 31\n",
            " perfmeasure 0.77\n",
            "current best 0.77  at epoch  8\n",
            "Epoch 9/11\n",
            "----------\n",
            "epoch at 1000 0\n",
            "epoch at 1000 1\n",
            "epoch at 1000 2\n",
            "epoch at 1000 3\n",
            "epoch at 1000 4\n",
            "epoch at 1000 5\n",
            "epoch at 1000 6\n",
            "epoch at 1000 7\n",
            "epoch at 1000 8\n",
            "epoch at 1000 9\n",
            "epoch at 1000 10\n",
            "epoch at 1000 11\n",
            "epoch at 1000 12\n",
            "epoch at 1000 13\n",
            "epoch at 1000 14\n",
            "epoch at 1000 15\n",
            "epoch at 1000 16\n",
            "epoch at 1000 17\n",
            "epoch at 1000 18\n",
            "epoch at 1000 19\n",
            "epoch at 1000 20\n",
            "epoch at 1000 21\n",
            "epoch at 1000 22\n",
            "epoch at 1000 23\n",
            "epoch at 1000 24\n",
            "epoch at 1000 25\n",
            "epoch at 1000 26\n",
            "epoch at 1000 27\n",
            "epoch at 1000 28\n",
            "epoch at 1000 29\n",
            "epoch at 1000 30\n",
            "epoch at 1000 31\n",
            " perfmeasure 0.773\n",
            "current best 0.773  at epoch  9\n",
            "Epoch 10/11\n",
            "----------\n",
            "epoch at 1000 0\n",
            "epoch at 1000 1\n",
            "epoch at 1000 2\n",
            "epoch at 1000 3\n",
            "epoch at 1000 4\n",
            "epoch at 1000 5\n",
            "epoch at 1000 6\n",
            "epoch at 1000 7\n",
            "epoch at 1000 8\n",
            "epoch at 1000 9\n",
            "epoch at 1000 10\n",
            "epoch at 1000 11\n",
            "epoch at 1000 12\n",
            "epoch at 1000 13\n",
            "epoch at 1000 14\n",
            "epoch at 1000 15\n",
            "epoch at 1000 16\n",
            "epoch at 1000 17\n",
            "epoch at 1000 18\n",
            "epoch at 1000 19\n",
            "epoch at 1000 20\n",
            "epoch at 1000 21\n",
            "epoch at 1000 22\n",
            "epoch at 1000 23\n",
            "epoch at 1000 24\n",
            "epoch at 1000 25\n",
            "epoch at 1000 26\n",
            "epoch at 1000 27\n",
            "epoch at 1000 28\n",
            "epoch at 1000 29\n",
            "epoch at 1000 30\n",
            "epoch at 1000 31\n",
            " perfmeasure 0.769\n",
            "Epoch 11/11\n",
            "----------\n",
            "epoch at 1000 0\n",
            "epoch at 1000 1\n",
            "epoch at 1000 2\n",
            "epoch at 1000 3\n",
            "epoch at 1000 4\n",
            "epoch at 1000 5\n",
            "epoch at 1000 6\n",
            "epoch at 1000 7\n",
            "epoch at 1000 8\n",
            "epoch at 1000 9\n",
            "epoch at 1000 10\n",
            "epoch at 1000 11\n",
            "epoch at 1000 12\n",
            "epoch at 1000 13\n",
            "epoch at 1000 14\n",
            "epoch at 1000 15\n",
            "epoch at 1000 16\n",
            "epoch at 1000 17\n",
            "epoch at 1000 18\n",
            "epoch at 1000 19\n",
            "epoch at 1000 20\n",
            "epoch at 1000 21\n",
            "epoch at 1000 22\n",
            "epoch at 1000 23\n",
            "epoch at 1000 24\n",
            "epoch at 1000 25\n",
            "epoch at 1000 26\n",
            "epoch at 1000 27\n",
            "epoch at 1000 28\n",
            "epoch at 1000 29\n",
            "epoch at 1000 30\n",
            "epoch at 1000 31\n",
            " perfmeasure 0.774\n",
            "current best 0.774  at epoch  11\n",
            "epoch at 1000 0\n",
            "epoch at 1000 1\n",
            "epoch at 1000 2\n",
            "epoch at 1000 3\n",
            "epoch at 1000 4\n",
            "epoch at 1000 5\n",
            "epoch at 1000 6\n",
            "epoch at 1000 7\n",
            "epoch at 1000 8\n",
            "epoch at 1000 9\n",
            "epoch at 1000 10\n",
            "epoch at 1000 11\n",
            "epoch at 1000 12\n",
            "epoch at 1000 13\n",
            "epoch at 1000 14\n",
            "epoch at 1000 15\n",
            "epoch at 1000 16\n",
            "epoch at 1000 17\n",
            "epoch at 1000 18\n",
            "epoch at 1000 19\n",
            "epoch at 1000 20\n",
            "epoch at 1000 21\n",
            "epoch at 1000 22\n",
            "epoch at 1000 23\n",
            "epoch at 1000 24\n",
            "epoch at 1000 25\n",
            "epoch at 1000 26\n",
            "epoch at 1000 27\n",
            "epoch at 1000 28\n",
            "epoch at 1000 29\n",
            "epoch at 1000 30\n",
            "epoch at 1000 31\n",
            "validation accuracy 0.774 test accuracy 0.773\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD4CAYAAADhNOGaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOydeXyU1fX/3/eZyUy2yTYhIZAEEgiL\nIpAQcC8BlIpUKVUCuNTSUoX2q63WvW5V22rVX1ttRZDWWhckLrghrhBcqhKSsKoQSEISsk8SZpJJ\nZjLz3N8fs5CEIGsQzH2/XvOamWfuPM+dmeScez/n3HOFlBKFQqFQ9F+077oDCoVCofhuUY5AoVAo\n+jnKESgUCkU/RzkChUKh6OcoR6BQKBT9HON33YGjwaSFyTBj1HfdDYVCoTilsHfWN0opB/Q8fko6\ngjBjFOckzP2uu6FQKBSnFO/ufWJPb8eVNKRQKBT9HOUIFAqFop+jHIFCoVD0c5QjUCgUin6OcgQK\nhULRz1GOQKFQKPo5yhEoFApFP0c5AoVCoejnKEegUCgU/RzlCBQKhaKfoxyBQqFQ9HOUI1AoFIp+\njnIECoVC0c9RjkChUCj6OcoRKBQKRT/nuDgCIcS/hRD1QohtXY7FCSE+EEKU+O9jD/Lea/xtSoQQ\n1xyP/igUCoXi8DleM4L/ABf1OHY78JGUMgP4yP+8G0KIOOBe4ExgEnDvwRyGQqFQKPqG4+IIpJQf\nA009Ds8CnvU/fhb4cS9v/SHwgZSySUrZDHzAgQ5FoVAoFH1IX25VmSilrPE/rgUSe2kzGKjs8rzK\nf+wAhBDXAtcChBosx7GbCoVC0b85IcFiKaUE5DGeY5mUMltKmW3Swo5TzxQKhULRl46gTgiRBOC/\nr++lzV4gpcvzZP8xhUKhUJwg+tIRvAkEsoCuAd7opc17wHQhRKw/SDzdf0yhUCgUJ4jjlT66Avgc\nGCmEqBJC/AJ4CLhQCFECXOB/jhAiWwixHEBK2QQ8ABT4b/f7jykUCoXiBHFcgsVSyvkHeWlaL203\nAgu7PP838O/j0Q+FQqFQHDlqZbFCoVD0c5QjUCgUin6OcgQKhULRz1GOQKFQKPo5yhEoFApFP0c5\nAoVCoejnKEegUCgU/RzlCBQKhaKfoxyBQqFQ9HOUI1AoFIp+jnIECoVC0c9RjkChUCj6OcoRKBSK\nk5pSxzRsroxux2yuDEodB9S0PCWuczKiHIFCoTipiTZVsKlpQdBI21wZbGpaQLSp4pS8zslIX+5Z\nrFAoFEdNqWMa0aYKrOYSxsc9w6amBQwwf0VdxziyrMuwmkuO6/W6Xic14lMq2s5jfNwzx/06JyN9\nOiMQQowUQmzqcrMLIX7bo02OEGJflzb39GWfFArFwTmZ5JGuI3SruYQB5q+obp9EYujmPjHOgc+Y\nGvEpux0XkRrxabfj32f61BFIKXdIKcdLKccDEwAnsKqXpp8E2kkp7+/LPikUioPTF/LI0TqXriP0\nLU1XUd0+kUFhG2hwnXbA+Y4H0aYKim0LKW+dzDDLu5S3TqbYtrBfSEMnMkYwDdgtpdxzAq+pUCiO\ngK7Gt8R+MZuaFhyzPHIszqXrTGBQWAFj454P9q8vnIEEhP+x8D/vD5zIGME8YMVBXjtbCLEZqAZu\nllJu79lACHEtcC1AqMHSZ51UKPo7VnNJUB4ZZnn3mGWYY9Heba4MajvGdZsJBM63z53KPndqMI7Q\n9T373KmkWz46on7uc6eSZV1Okysj+NnjzCXsc6d+7+MEJ2RGIIQwAZcCL/fychEwREo5DngCeL23\nc0gpl0kps6WU2SYtrO86q1D0c2yuDCrazmOY5V0q2s475pH30WrvgZnDBOuyA2YCVnMJ6ZaPDpht\nbGueS1EPOedwYxwBx9H1s3c9/n3mRElDM4AiKWVdzxeklHYpZav/8TtAiBAi/gT1S6H4XnC8grwB\n4zs+7hkyot45LjLM0Wrv+9yp3WYOXWcCAXpKWTXtWUFpp+vnORwZqi8++6nCiXIE8zmILCSEGCiE\nEP7Hk/x9sp2gfikUpyxdjX9gZFzmyAkeP5og7+EY3yPtGwS0do1mV9pha+/plo8OkGQCM4GexwKz\njaGR68m0Lg86hiLbtaRHvn+AdNSbgzxen/1UpM8dgRAiArgQeK3LsUVCiEX+p5cD2/wxgseBeVLK\n/hKjUSiOmp7plemR77PDPpvWzqSjDvIervE9kr7tc6cy3LIGKQVN7pEMiVxPlnX5cTOwPaUs2C9D\nJYZuprR1+mEFqo/XZz8V6fNgsZSyDbD2OPZUl8f/AP7R1/1QKL4vHGyhlS+oWkB1+6TjEuQ9mv50\nJTF0czBAXN46GU14SYv0Geu4wzSwvZ27azC4q5xjNZcQZy6hyLYQAUHHkB75fr9cJHYkqBITCsUp\nxsEWWsWGlNLgOu2gQd6+Wix2sPTQpPCi4MhcYiDTuvyItfdDpZ72lHPAl/Y5MKwoeK3S1ukMMH8V\nDFQrJ3AgyhEoFKcYvS20spq+xuYeRXrk+wc1tt9mVA/lJA72+sbG6wC6BWyLbQtJDN0M+DJw4kw7\nEHgP6P/hSEOHWtfQU87Z504l07qcMbErg+9Pj3yf2o5xxy0L6vuIcgQKxSlIz4VW1tCdjIxaFdTD\nDyfDpqtRPdTIu7fXi2zXEmawsalpATXOrOCo2ytDiDDWUeR3CPGh3zDcsuaoM3C6BoMPNaLv6Rhs\nrgxKW6czwbqs32UCHQmq6JxC0YccSuM+WmyuDOq6LLQaHPElVnMJUaa9wQVQgRvA5Y5CdpoS2WIG\ni3Evux0XcbnpSSY5NvIy2QBEh5RTZLuWxNDN1HaMw2Kswe4eHDzP+LhnKGy8FrPBjkeGMdyymtLW\n6aRHvk+JfSY6JkCiCS821wgEkBReBMCmpgWkR74fdEwBJ3S4n7VrMDiuy+c6FN+WCaQkov2oGYFC\n0Yf0Re2ewDmyDrLQKtCmKxvJ4jbbRwx1SOydqUzhA55038tGMim2LaSw8Vpa3MOICSmlun0SA0M3\nMzCsiB322ZQ5cgCwuwejY6LdO4BQrYko017Gxz3DLscMdIyAQKCTGLqZRtfpDLOs6eZESlun45Xm\nI8poOtbc/v6cCXQkKEegUPQhh1u750g0+sAoN3C8pwzUm/P5V+ufuTHsJu63r2BJ6GxeFbOZx/Pk\nuX6DR4agYyI6pBybe1RwltHmSSQl/BN22GfzZcMN7LDPRtCJxViBw5NCYeO1AJg1O2AAvIAelKts\nrpHBPnSVd4yi/YDvSeX2f7coR6BQ9DGHo3EfiUYfGM12fb3rKPc690v8IvKObs7nF5F3MMZbyhth\n2Sxsf49XQ89jjyVQYs1IqNaIzT26W2G3vc6JVDnPIUxrpNk9HNDRhMRssBNv3o6OiYLGX+H0JiDw\noOFBEzoabmrbM4PxA5srA5srgzLHFAQeXN4oim0Ljym3P/C+rvSX3cT6AuUIFIo+5nBq9/ScOfRc\nEWs1lxAdUk5h46JuMws4sGbPTlMiD7UuJ9f8T3Y7LiLX/E8eal1OlLmUOa71LA/7IbPaCxniEGjC\nDXjo0OOJMu7pVthtRNTbSATtejwaHYCGLjWa3cNIs6zDavoG30xAkBRWhCZ0QCcj6m3izDuodJ7P\nwNAiim0L2di4CB0TI6LeZEL8MiRQbFt41BVO+/NuYn2BcgQKxSE4lvz7I9G4u84cwg317HLM6Gbo\nmlwZ6GjdCrf1lv65xZzM7ZEL+Wv7o/xF+zV/bX+Ef4dexBzHFm6PXMiyiJnM43le4ipmiFcBA4JO\nnN6E4OKr/f3TAB2dUEBHYmRQWAEAze7hCDrRhJua9kyGWdaQZV2OxEB2/DJGRq1ib/uZGEUbkhCs\npm9Is+RjNZeQZV1OmKHhqHP7+6Jcdn9GOQKF4hAcy+jzSDTurjOHdm88UmoU+UfNRbaFABiEBw03\nZa1TKbIt7DX90+bK4GnHX1jKQm7Rn+SNsGzq27O4MewmnnY8SpljCjvDI/ml8RFO0yuJMlYwOLyA\nCGMdbZ7EYP9srpEMMG9BBCsDGTCJFmyuERTbFiKEh+z4p8iwvI0AdjlmAPurdaZZ8hkYupkOPZ5I\n415s7lHdAs8OTwqDwjYcdW7/kaSVKr4dcSqW9Yk2JcpzEuZ+191Q9CMCxr+vyhT0LJVgc2VQbFuI\nVxqRhCDoxCA8ZHapl68JNxOsS7tp5puaFmAx7iXTXcbL4nLWRJ7GzLat3B65kLVcgMDLDvtsrKZv\nsLlHBe9HRq0iyrS3Wx/KHDnBAHFgzCgxIPBiNX+D1byTNk8idR3jSI98nzZPIuHGxqAj2Nj4Sxpd\nYxgUVkCD6zQGhhZR6TyfcEM9Tm8CI6NWkWbJP+Cznyy/yfeRd/c+USilzO55XK0jUCgOg+O9WUtP\neps5DLOsYaf9Un8LwTDLGmB/vfzy1snUOLO6bc6SGvEpKQ4zK5nPb8JupyGqns3mZB5qWs6f4vay\nxZxMY8dobO7RRBr3YvekBBeijY97ptsGMmWOaX7px8twy9vscsxASh2JRpMrgyb3CAResqzLD/g+\nfDOTkRiEm8ERXzI44kt/DSAvTm8ig8I2kGbJD37WI83t763GkJKHjh4lDSkUh0HPgO+25rnHNWul\ntxWxuxwzMIhOhlnexSA6KbHPpNgvB2VEvUOWdTl1HeMQeNnUtICpjS2ktepMM77G5bzKBuNpjHVV\nMcJdx5/iZhDvsFDmyKG5M51I415aPYOJMlYiMXQzxAGHF2MqZXB4AVnW5aRZ8smyLkcIL5HGaiQG\ndGliaOT6Xg3vPncq2fFLybIuY1PTAppcGYCGQGeY5d0D9h0OOLPD/T5VWunxRTkCheIQ9BbwrW3P\nougwUyC78m2B566v1Tiz/BU012AQLjKtywGNGNPuA4yfxEB65Pu84/oZL8krWe+dQU1UCymOUG5t\nXMdGsthiTuZf5llBWcjpjQ/WJ2r3xAYNcVeHZ+9MDV4ncD80cj0OT2rQoB+suF1ghtLVsXilgQnx\nS3sNmh9pHEYtFDu+KEegUPTCoRZwZVqXkxRWdMRZKwGDd3HzHsa6qroZvKl8yDRbCzZXBuHGRoZZ\n1lDaOj1oVCfEP0WceXe3vgWMX5snkULjcC7nNVYyn3vkQ+SRy2Lz/SxzPEqZIweJgQHmLTS4xhIi\n2mhyDycl/BP2tp+JwEth47UUNi5ifNwzxJlLkEBte1Y347yndTIabjThJa5L5s7BitsF3iPwYBAH\nLzynsoC+W5QjUCh64XAWcI2JXXnIrJWeM4BANczXnb/iNttHRDWOID3yfaawjodal9NiqafItpDG\njlFB3b7riLy3fXptrgxq27NwegdQaXGxRC7mCkcBayJPwxFfQoZldXDDmib3KKKMFbj0OAAGhm9m\ngnUZbZ5EAqmiTcESFsvJ9G8gc3HzHqJtwxgYVsSE+KVkWpcTbRvG1c4PD1rcrsi2kELbdUhgcPiX\nDLesPsBpNLmG97r62GLcq5zACaTPg8VCiHLAgW/9uadnxNq/TeXfgYsBJ/AzKWVRX/dLofg2uo5Q\ne2alBKQP2B+43dM6GZfXEix/HMDpiafUMZ1Mf0DV5spgt2MG1cYGLvO8ziv8hKfs1/Er8T5/ss6g\nkBFIDDS5RzIobMNBi9X5DO21wQwc0MmyLmeCeyfX8QIPcAf/1/o4m83JYMnH0ZlMdfskf4A4lUFh\nG6jrOIPCxkUMDCumwXUaE+KfCmYkxZl2dHNABc0TySOXh8Kns8WczFhXFbdzB7/h9m7F7bp+f9Eh\nFTS5RzLM8m4wmNuz8Fxg3UJgxuXbwMbNvs7UbrWTFH3LicoamiKlbDzIazOADP/tTGCJ/16h+E45\nWKZQtKmCjY2LEOgMCt+IUTiRQLXTN8ZJCi8KGuyk8CJq2rMoti1kSOR6yhzTkEjaPEnsDKvlqfbr\n+D0P84C8g+fbfkxteyZCeBgUtoHq9olYHFWkWfLZ1jyXauckMqLeCvYtJqQUm3s0oDMy6nUmuHdy\nv/0l5vEiVVFOSjy38zfbI9wYdhMNrtO6BIj3EBlSw+CILylo/BXV7ZOwmr4G/IaYTprcw9nY+Euy\n458GoCG2njuNC/ij7b+8GzmSmW1b+ZN1Bg3m+l6/O5srA4dncLeKoV0da1fpJ8q0l2LbQnRpQBNe\nsqxLAZQ8dAI5GaShWcB/pY8vgBghRNJ33SmF4mClIXwj4B2+SpyeOHbYZzMorABN6HR4o5lma2Eq\nHwbbZlmX8w/5G25xrEJHIAlhcPjnzGvP57c8wf3cxWKWMqK9DQlkWZcTGVITLPi2pekqatuzkEhK\n7Jf46/bkYHOP8m/4Ithhv5QoexLzeZ4d4RaiTHv50ngGN4bdRKIzlJiQ3bR74zFpzdg9qTS7hlLj\nzMIgPIAXm3sUBY2LCchDGl4aXWOCC8ACheteCz2bKxwFrI44gy3m5IN+b72tpgZ6ldKs5hKiQirQ\nMTHEn4WksoBOLCfCEUjgfSFEoRDi2l5eHwxUdnle5T/WDSHEtUKIjUKIjW79wOqFCsXx5FClIbLj\nl/kqbLpHYxJ2Kp3nkxC6lX2dQ2mx1PMnxzMMaE4AYIJ7J3NZyVxWksN6UsI/YY7zCx7hdu7ifh4z\nLmQOL5PHHKbii0c4PfFUt59JmNZAdfsk7jXcylTWoQOFjYvYYZ/NVD7gVh4iylgBGPkLd7KOKUQY\n69jUtACBl3e8l/Mf80U0uMYSE1KKLkMBDw2usVQ7sxluWY1RuPH9mxrxSiOa0JkQv5SRUavY5ZjZ\nrXDdHNd6XrRMZGbbVsa6qnr97g6W2lnjzOrVsfacPfQMhCv6nhMhDZ0npdwrhEgAPhBCfCOl/PhI\nTyKlXAYsA9/K4uPdSYWiK4fa0MTmyqC2Y1xQbgGvv/zyBt72zGMXM8hrz+VVeR6z2gu5nJVEGmvJ\n88xjifM6buKv/I5HWapdTbtnAFtNTua5X2CyYQ1/sD2MxbgXrzTRLgcQqjXykWc2eczlZ9oTvKPP\nI4d1vCzmcGPYTdidqfhCcBo6BnY7ZhBj2sUuxwyy/MHeVk8SNvdowgyNSD0CXQpCDS3scsxkuGU1\nJY4foUsTYCAhdGtwVO7oTGa34yKuDHuYh1qX86e4GWwxJ7PZnMydTWuCz7tyMONd1zHugAVg6ZHv\ndwuKq4VhR077mAPGzQdnb++HT2iJCSHEfUCrlPLRLseWAvlSyhX+5zuAHCllzcHOo0pMKL5LArOF\n/SUT6nB6EwEd0NDoZFB4AQ8bbuQKRwEPcjtvxg/Cai5hcrXG7fLv3M9dPG66Apt7FOGGOjplJDEh\nu2lwjSVcq8OpD+AWHqWAieQzFfCQw8esYjYbmcA4tjKPF1hHDmBAYkCjHZ0wwBssCT3MsoY2TyLV\nzmz/DmICq+lrzAZHMDbQ7E5HYgAk0j82HBm1CiAoe/204z12m2Iot+xfVzDWVUWy08s/jD8/5Mj9\nYDu1lTmmkmZZGzxe6piGwOtbG+E/5/HY0e1U4IgM+lGy/r3bT3yJCSFEBKBJKR3+x9OB+3s0exP4\nPyHES/iCxPu+zQkoFIdDX20RCb7ZQmAkG8jL9xnvRECgE8KYjhoukjv4pymXxe6n2Ou+itp94/iF\nvIP7+T2LeYp89w/YZnbT4BpLlLGiy3kGYhStbJSZ5DGXXPLIJ4d5rMCMiwtYx9+MP2Wt50JyWMdE\nvuRx7Tpceiw+Z2TArNlIjfzUXyvIg0Ai8CAR2NyjABgUtoGa9iy/E3EzIX4Zdvdgdthns8P+Y0AE\n6wF95MrwlYiwEcyAWscUNnV8+5aTgS0y6fKdB1Y7v9LFqQQIpMYGztlVojsVOBHGvC/oa2koEVjl\nyxDFCLwopXxXCLEIQEr5FPAOvtTRXfjSRxf0cZ8U/YCuBiUg5RTariXDsrpbuyNxDgHnkm75iI2N\n1wULrYVp9Tj1gfjkGZjKhzynX8dlrKImtIVtoQn82f5fQDBfW87GkFGsc+WQx3xuNvwfq00mbO7R\nGGnFqSdioBWPjCSfaeSygjxyWcIirvQ7gv9yFVd63mEPj3EnD5PLS7j0WKJDdrOvcxig064PYKf9\nR1iMVTg8KUgk8ebtSGnwZxp1VQJ0MqJWd5ODqtsnYTFWdqsHlGVdTo0z64gKve00JXaTkMa6qoLP\ne+Pb0nZPJKeqQT9a+tQRSClLgXG9HH+qy2MJ/Lov+6Hof/RmUOJMO9nlmEGUaW/QORTZFpIUdvBl\nK11nFgHnkh75vl9fnwFo+NRVL2DAavqaHxufZH77c+wOM1Jpn80e7QeMxwXolERE0tI6jI/JYIHh\n72R1bGGfHAp48RCJWTThkrEYcOIljHymsoRF3MODtBHGPYab+Y33P6xhBo9xK7/jEfKZRrhWS5tn\nsL9SqAGJhiSENs9A8K/qDTM0Uek8H6vpa5rcw6lun4SG278BjQHwOcYG12ndArdd4yRWcwlmu+Ow\ni+9tMSfzp7gZ3Nm0htURZ/jSTnuJK/T87Y5Xgb/+ZtCPFlV9VPG9padBiTOX0GIbTpFtIUMj11Pe\nOhmBL+8fepeTBF4KbdcywbosuCo4oJuDhleaCNPqadcTgrV77hcPYrWUEEYnsabdNLuHs4inCDc0\n4HT4Km/Wd5zBO97LeYdcQCKQWIx7sHtSiTBU0+YdBEAO61nMEj5kKtkU8pn3h4Ri5C4e4r9cTQhe\nwOuXpbz+Mg5uwg0NODwp6IQwzPIu+9zJVDrPJyqkjCb3cCQavpiARpsnkQhjHR/X3kmH18qEeN84\nzeW1UGxbyMCwouBCuZ4ptXG9LCbryRZzMqsjzuAKRwEvWiZ+qxPoeo040w72tE4mYmQzsVbfAr5m\nWyoO+0BS0zYc4V+D4ts4GdYRKBR9gs2VQVnrlODmJ+DTt3VpZLfjIiSGoN4NvRc+K22dToa/NEKJ\n/WJKW6czKKyA6vZJRIeUYzV9Q7ueiMVYSZixiZTwT2hyjWS3YwZXtq1jnLvCv82jwOlNYLpYxZXt\n64g17URi9AdnNTTRSZSpiuiQ3V2cQD55zCGXPH4kXmY2q1jFZVzPP7ifu5jBGgrIxifz+PYe1qVG\nlnU5ZsM+AASd7GmdjFsP9z8P4JsBWEIqqXZms8M+G6d3AKBjdw9mU9MCIox13QSkI9ltrStjXVXM\nbNvKs+lTubjjK0YmddA+ZnCvt+qks9m07xeMznqL5LFFSE2wfdNsmm2pNNtS+XrzLCxRtcfyZ6Ho\nBTUjUHwvCRitDMtqSlunB0sZDAwtCmbG0CNhrqecVNY6hQzLatIs+XhkOLsdF2E1fU1tx7hgWQmv\nNAbLNTjbfZlDceYdNLvSWOe9lDzmMo8XWIsvsPu8vJZ5PEeDayz4F4NJdIZb1vjq/WMgkH10Fp+Q\nSx6fiSw6ZTRGnIDgJa7gXu6nwDCSV7w/4XJeI58pBByC3T2YfZ1pjIxaxW7HDMIMjdg703wF5pxn\nAz4HITHi6ExG4Jv5aKKTxNCtwRlPaev0bnsN7HOnMjrrLcKtTtoZTDhORtveotE+hvA0Z6+/w3jb\nbu7Y/D73Zl3NJuswiuOGcd/mF7lv3BVssg47oL3DPpDR494IzgBOz1zF9uLZVJSeTZsjodtriuOH\n2qFMcVJxONk+pY5pOD3xJIUXddudq8aZRYc3hjTL2m6btZQ5cthpvxSLv86Ohps0yzrKW6fwO/kY\n9qgayi37x8rWpsEMahe8EJZDg+s00iPfZ5djJgbhxK3HkBL+CQPDN7OxcRGgMTj8C5LCiyiyLURK\nAzoGApPtwKj+Ka5jEcvIZaU/HdS3endw+OdUOs8H/5pjn5OSwewhDRc6JkK1Rq7X/00B2eQzjUBZ\niWR7ONkU8S/zpYQa9vmygKSRjKi3SLPkU2K/mN2OixgUtgFNdFLtnIiOidT0z+hoj6a+ZgwAqemf\nAVBRei5RMZXYW1JITf+MtIxPD+t3qyibhCWqtpuRbralMr88n9qhspvRH2/bzSh7FS+lTT6sc5eV\nnEdF6blH1B9F7xwsfVRJQ4qTisOpSx9tqgjW7wmUOi6yLaS2PQureUewfSAgXNo6nThTCXbPEARe\nJsQvI85cAugUMoEH7c8HV8kOdUj+2v4I1WEyuL3iDvtsYkJKcesxgJea9omUOabgG81rNLnSsZpL\nGG5Z43cCBkBwC38BJEtYzN38iSVc5z/+MKARa9rF6bGvYDFWElgL4JsNeOjQ4xB40DECOh3+aqH4\ntX3wssMxC6O5HXN4C5YhDQw7/1OGZPyP8Kh6KjyT+cxxK6Vt00hI2kaDZwyNjEDHQISllsqySTTW\nj0AID6BTWTaJyrJJxMSVYW9JJiaujKryiVSWZVNRNumQv5slqpavN8+i2eYrCRGQcVYMzTlg5L/J\nOuywnUCzLZWaykxS0z+jpjIzeH7F8UXNCBQnHYezF23A+EsMIEET3m4VPru+P5DzH6o14/AkB/fQ\nDeSmj3Lu44mOP/KyeTKz2jdyT9R8yi3CX+htIrGm3djco4PB4MDoHXQkIcEZxm7HNPCP6EGQw0es\n4jJA8Dg3cAOPA5LZrCKfHECQEv4JVR1nI3UjPgXfd17QsERV4bAno2kedN1ADuvJI5dcVrIlPplx\njXtYyRXMEy/QOMEGwNebZzF63Bs01I6kpioTIbxomofwiAYc9mRAR9N8kpSuG0kfsZZ2Zyw1VZnB\n68bFl9DUmBG8Tx+xlpS0jYf83QLGPymlmJrKzGOWcQLnC5yn53PFkaNmBIpThq7ZPgPMXx0gEwU2\nhxkauR5dmroVKwu832LcG3x/aet0EkM3Myi8AIuxkur2SQwwfwX4dO+G2HpWR5zBwvb3eCMsOygT\nJYUXIYSk2T2MONMOmt3p+Ay1wS/hCOLN2wGN3Y6LCITcTKGBqusa+407BByE2dxCIGxb6TwfqfsK\nve1vZ0AzdOCwJ5M+Yi0xcWWAIJ8pzBUryGMuv2l8jpVcQS4rWCemULv3jG5GUiKwRFcjpQGv1xR0\nAkLoJCR9RcKgbaSPWItEIzR8H0nJxSAgNKyZpsYMYuLKaWkeGmxzOMRaK0hKKaai9FySUoqP2Vj3\njBfEWisYPe4NHPaBx3Te7zPNI03fejsYKlisOOkIpA/2LMXcNWvF5soI1q6XUqO8dUowldHmyqDJ\nPQyfjJPJCH/p5h322YDXv62j60gAACAASURBVKI2k/qOM8i0Lg9mtbxomcjlHZ+yLSmVTdZhuGzx\n0CwRQmK0dqLXBP6RfAZdYkS3mNBdgX8jHUt0La32BMDARAqYzatMIZ97eID7uZt15DDRVUBBfAkO\nexKdbgugoWmdRMVU0NKUxi08TIF3Ep+ZJtLcNITmxnSmiA+5IHYVd7f8jSXSt67gfu6mND2MAe07\nqK8ZQ0LStuDI2VY3ktHj3qB813nYW1L8/TOQkvYFBqO7Vz2/3RlHS9NQomIqaWlKIyFpW7eZwKFS\nN3vKODFxFcfkDHq7Tqz12M55qvBtRrsvUI5AcVLR1dhbzSVYHFXssM/G0ZncTc4psi1EAFnWpZQ5\ncmh0jaHIdi3DLavZ5ZiB0CRIEEJS0npJcKytGXSMSZ1oFV6kFIyNq+OOsvdZPOiPrJNTWZv0Co9u\n/hv3jbuClTU/JMTswGDw+oOqgVH+fjm1qTEDTfOQPHQDVeUTcexLBOGbCTzCreSQz2Ke8peaXsI6\npvAIt6A1eYK5/CAwGDtoaRqKprkp0H2bwOS6V5LfmEMO+ayU87kjfhGTm9Z3O9/6svNYb5hAQtI2\n6mtOB6C5MZ3R496g1Z6AvcU3EwCBEL5YwMDBW6kqOzM42t5S+BOabWkYDJ7geSItNf77OlLSNnaT\nZXqjp2wTE1ehZBxOvEE/WpQjUJxUdK362T5mMAMpoXnLdqprJpGa/hnhGU4qyiYxwLyDhKSvCbc6\nGWTbRlPxSLxeA3s6c5DCgKZ5GZL+GeW7foCuhwA66SPW4vGEUlF6LqFhTcRayxne1MB9465gO0nU\nFZ7OvziDZusQJpUX0NA8Cl0akLqREJPdP3rXuYXHKNLO4CN9BiCJjivnPPcXJMtPeET7HVLqCE1n\nsv6xv1bQSgoso1nnmBrU+PN1X7AZ4QVJ8Ny6HuKTgPBJQEtYxGKeIpeXEDthJfOZy4t8PXgAO0QM\nL1VdyTzvCzQO9sUIAjODVnsCpTunomkehPCSkPSVP2YgqanKJCm5mK83zyI2vpTmxuEAhIXXYWsY\nTlJyMTVVmcTFl1C6cyp1Nafj7oj6VqP+bTLOqe4IThVjfiyoYLHiuBAoLtZ11WiguNhzZ196ROfq\nmooYGGnGxpfSWDeCMVmv9mpYmm2pbCu6HF0PQdM6GZP1CgBbC3OR0oCmdTJ0+MdUlp2NKdSOs3UA\nUmrBQOjO7Rd2CZj6MuuF8KAZvJhMDtqd8QjhRkoT07R3WaH/lLniBdbJC5lueoPn3b9kcfyDvN58\nDVGxVbTYhnKz/H8UMIH1IgcpNWLiysls3k22LOAR7gB0DAY34ZE2HPsGsj9k5wva/oF7uIcHeYA7\nuYc/cgt/YVtYOntP7yTWWkFF2STOdhYxyl7Jk1HXUF99OlExe7HvG0x4RAMmk5N2Zyyh4S2MnfAq\nlWXZ1Nf6Cs61ORKxRNdgb0khwlJLYtJ2ykp+AAg0zcOQYZ/hbLNSVz0GKY3fi9TN/mDQD8WWx286\n8dVHFd8fDlWzZauto9tCocBCovvGXXHE1wqkIqakfU5l2dnB+6HDPzlsuaHVnsCe3ecihBchdHRd\no3TnVCxRe2lrS0AILyAp3TmVvRVZuDpiSEouxus1BXPrpfRl7rQ0DfU/NxMS4uCjzhnk8hJ5ch5P\nG37GL93/4ZqwJXxBJqdnrqKyPBspDTybdDENtaOREjTNQ2h4C5u1VNY1TkNobkAER+oxceW0NKUR\nqB6aw7ouEtBTrGMKj2k3Il2CNPv64OffNnAQX4SPp3736Qwd/glzdn3BV5GpvNt+GQkDv2Ffcwrn\ndBQyc9tm3hgDkVH1fL15FtGxvjhAVEwl7W1WIqPqSUnbQEXpuUgp8XhCaagdhWbwMDj1y+Oi+R8P\nlDHvG9SMoJ/Rl0W4xtt2c9/mF3kj5UxmVX550NWjh0OzLZVtxZcRn7AzqHkHZgiBgGVg5gCwvXg2\nCLAO2EVD3UikFGhCZ0zWqwBsLZyDlAYQOgats4tU4kHKEMyhzYwc8y7bi2fj9Yawf3Qu2D9L6M79\n4k7ulg/xR+1W7tIf4qH469gSOpIX9/6WWGspoDHRsYVxrp08n3whUmrUVZ+BlCCEzn2Rt7HO8SO2\nxCfTbEsnOraS8U1lzOMlfsIq/+KzKeSwjlcMP+G2Yf/Hv3beBxiIiy8heWgh24tno+tGQsOaMYS4\nOdOxjRX6VVwX9zCvN1/D/MF/44naPzBHf4VtiYOwNQwnLLyRVvtgYuLKse8bzNBhn7Cn9FyQMHhI\nIVXlk7rNrPoidVMZ9O8GNSP4nnEyVVWcV7aeb6KS2WQdxhspZ3JN6VreS8pklL3qqB1BrLWC5CEF\nwRWlXbXnwOPAzCEyei8IGJL+GZVlZ5M2/GPKdv2A6C4jWHOonY72OJBgTdhFTVUmmuZC10MxhrTi\n6ohhy8ZcNM1L+oh8SnfmEKjHs98Z7E8H/aF5FYtcy30jdv0pNkSdzgdNl7FCv4pacQaNQ20M3elh\nuesmFkY9Rl31GEzmVqTUuCv0LkpiB7Ku5hJeFpcz17aCWOs6Lmws5Ces4jVmB/cgAMhnCjck3c35\nfMS6Eesp3ZlDU2MGuh6ClBpSGmh3xqNpnWwflMB1zodZ2nQb50Zu4KdVr3J98r18ue8M2mqSAC9t\nrQNJSi6msW5U0AlIXSMh6Sti4irYWzEBIbsHxXvT/JUx//6gHMF3yMlkzHujq4EP0Ft5gG+ikrlv\n84s8n5bDrMoveS8pkwtrinnSMvOor32oVMSKsklc3/Y029O288zue4hP2Mme0nOZFfNfLuR1lmTV\nB/PNm22puF2R+NKIfAFVTetA10MxGJ0INCKjqmm1D0Ki0+6MhS4ZPT7259LnsJbnXNeRywryuYB1\nTCbPPp9cVjCXFbws5vB2UxY/ai0iV+Sx1n4BJrPfEaFTpI3jPzW/5ueWx5njWMnrzCassQM3IVzC\nW/66QYIc8jnHmM+SmKtY0/Fj9p7uIYWNREbVs6Uwt4uUBCBIHlqA0djBqqoFnBu5gd+1LuWvloW8\nWHUTQvP6Zz8GomPKaawbtX+WFTIAAYSPKGH7mlkMucSXbtu8cyTbt81iyIzVRKZUAbVYqKUZ5QBO\nBRzD9EM38qMcwXHgZDfoR0vAwAcknpu2vcbU2i3clXl1sE3AMTyflsOvdq7mg6RMzmzcyZMjZnJV\nWT67ogYd0aygomwSAp3KsrODhspo7GBb8WWMyXy122zgnd1Xs1LMpTUhkZU115PDhzzdcjP3D51H\nrLWCyvJsaqrOwNsZzpisV4OrbUGi62Y0rR1NEIxBxMWX0NI0xNdG6CC7LqQKLAzzMpGNQdlGCA/r\nySFX5jGRAh7hd7wY8yOuL32epUmzWV9/Pnglblc0AcfyjnMOC6NcPOP4NUv4FUZ0THjw+EtTgMYU\n8SF5Ipc5nleIjas4YGWvJnR0GahppJOa/j+qKieAEMxIfIGf1r3KX6yLWGB7hTfFXPL1C4hIriAk\nspWWb04jIqUczvEZ9ZSRH9FamUx9UXYXow+RKVW0jtiBs35g8JjixHMkBv1o6TNHIIRIAf6Lb5cy\nCSyTUv69R5sc4A2gzH/oNSllz60sTwjfV2N+LGyyDuO+cVcEdf+ptVu6SeWBmMB9465glL2KD5Iy\n+WFNMc+mT+WVtPPZFTXoiOUhS1QtWwvnMHDwlqA2XVl2NolJ26gsn9RNItqWNIo5e1/hpZorOY06\nFrOUBeH/YKs9BWHX/WmROnHxpbTaE6ivOQ3fn6IGdKLroSQOKqay7GziE7+hrmYM5lA77c44kAYQ\nXkJDW/wj+eBKBB7hNkAiNDchpg7cHVHkk0M+OeSwlnlN7/L/LL/kmvo88mQ+a/lh8PMZQ9rQvWbe\ntM/nSXZwD3+kjTDu5/fcwD9YxWwe53oWy6X85tzr2YFG7RfnBkft5tgm6jaf5e9NoE+C1vAIYkbs\nZPw3NTxn+z/maC+zznYhH0RcRF7bfOZqL5JfOxmhSSJSymmrHEJDUSYDsopprUxmz5qZ3ZxAgMiU\nKuUEjgMnwpgfC30WLBZCJAFJUsoiIYQFKAR+LKX8qkubHOBmKeWPjuTc3xYsVgb9+LOg5H2uKV3L\ns+lTg2WEewaEj2egOOcTG+udF/FVUgLNjemkpH1O2i4PkyPX8NHZScF2lWXZlO6cyh+4l3t4gD8b\nb+JOz6OYQ1uCWUB11WPQdQ0hhH8nMQ1Nc6PrJowhbXi9ZgYk7qChbhQxcWV4OsNx7BvUo0cBiUh0\nedzl/0boIA3ksJY85jKXFaxjir820NwuFUf979E8TDO9xysdVxGOEzcmLsEnx7zNTCJoZ33EJKZ5\n1zFkhm9rzZadI2nZOQLpDUFK6XNU6AiN4POk89bzq6oVfLrvQj5ouwTdYwDdwBTtA6amvsq91Y+D\nlAz90Vu0Nwyg5tPJxIz6Gkf50F6dgOJATnaDfijKfnPziQ0W+zegr/E/dgghvgYGA1996xsPAz0s\nRBn8E8R4225mVX7Js+lTmVX5JcVx+wPCz6ZP7eYEAsb/UDXnv42KskmUxBWR55xLbk0eRTHRDC3x\nskJexR0Dr+vWtr52NFP4kMUs4QHuZJFnGe9zMfkd0wiPrGfAwB3U156G8AdUQRJhqaWjPRZ0L57O\nCECnvmYMQnhotqWD1LBE7aW1daC/EJxEhLiQnaF0rxnE/sfSJ89MpMBv9HNAQL6cSi4rmUiBX/f3\nBZxz9PWs6FjAqxEz2NY2gXt5gFXM5g/cjUTgxsj49q+YmfoCa4suIH3W60SmVGGObaLmU1+uP0JH\nM3hB6MSO/IbWvSm0lIzk3qa/gxAMnfkmdRsn0VY5hHxtCpsjBjJ05psAOOsHkjBhI+2NCbR8cxoJ\nk77oV07gVDfmfcEJiREIIYYCmcCXvbx8thBiM1CNb3aw/SDnuBa4FsAcGtM3HVV0ozcD/2DxcyDo\n5hhG2au6Gf2ApHQ0WUOWqFpWlv6aWnEGeTKXJS2LWcwSfpt8O3vTPMF2zbZUzmzdygp8qZKrmn7O\nWqaSxzxyeYn81qls2ZiLJaoahz0waJC0OZKISK4gceKXlL4+2z+yltwsH6OACeSLHEJSG+HrRHJY\nx0Q28EjnbQijG6SG9AZ0fAlCggzMFASPGG4Eb4jvufQCOvlMIZ+phES10GmPASQTKeKK8H+zPdNC\nzaeTGcVOfspzPMztOIngUm0V5wx4jxfKb+RnYx6gBHwa/sZJRKRU0FY5FCTEZxVgMHV0G9nHjNhJ\nzIgdAHQ0DCBh0hc0Fo8H6K79VybjKB9KwqQvsG0ZS+TgylPOGSiDfvzoc0cghIgEXgV+K6W093i5\nCBgipWwVQlwMvA70uu+dlHIZsAzAEp186i1+OAXpaeABELB24FieyZj+rSP/TdZhRy0NISGbjazh\nh/5ibXexbugELg7P4/T6Sv4zYSr1hclcMXopi8WdrNq2gJCoFvLtvhH4edHvk79vGqD5q24S1MVB\n0l47kPaGAQiDRHp8QY8CJpFHLlfH/JP3ts0hh4/IYz65rAQk0msgLKGW9rouspHsIRV5TX6ZyFeh\ndH9Gj6TTHu0rJsdEHg35DdJpgs8kOXzEhLDPMba7CUHnIa7HGNbOzXXL+V/sGQz/po1Pwi/AtmUs\nCdkbqPvyLITBg/QaaCjMRmgeYkZ9HRzZDzzr8wM0/8jBlexZM5OYETuCTqC3178LeUgZ85ODPl1Q\nJoQIAd4G3pNS/r/DaF8OZEspG7+tnSU6WU44+/rj00kFcHipooebTvptHCr3vL4wGyG8zP10I49x\nKytCZzO942P+xK3cZXqA22ZeRUGKb6wQMGiWIeW07DiNkOgmOvfFAmCMdOBpteAz0l5/9qcOupHQ\nxGpcjYlIHf+MAITBy2R9HXnyCjYzlmwKmc2rrNdykLrGU/hkqUViiV8Z8sUEJrKRR7iZW3iEAiZ2\nkYAEOaznzJBPeNh7J+hGclhHHnOYH/Icn0Rmc07zVvJELm8nnMs1dW/hxoiXEF9ukjDwux9fxVt7\nf0r9hrOIGfkV9tL0oOzT9PXptHxzGmheNEMn8ZmbsG0Zy5AZq3HWDyQ8obabUW+tTA5KQvWF2d/6\n+tGgDPqpwQmPEQghBPAv4OuDOQEhxECgTkophRCT8P272vqqT4qD0zNVtKssFCBg7Lsa83WMZh2j\nj+ha9YXZXLvrNXZlRLEtyyfztVYmM6Z4H5fLF/m841zu5GHeizifmW0f8sGAM3ms4Tbujr0JcPKz\nwrW+WUFRNtHDd7Jv14j9Eog/7dPTGoVPvvGngeqChEk+KaX28/OQXl+a5q3iz2xNSOVdWy4fGyaz\nxHMd9/BH3P5N5SMGV3J+x+fMbVgJCF6Sc8lnKlND3uGlzmvIJQ8QbIlNJ695f2A4h7XkiVxyO/P8\nypFOvvwBueTxsncOS1oWsdjwJA+H3MStdY/zh6GLuL3yX0R4nUjgdzzMOw2TfDOBSV/QUDSB31vu\novT0UL5gDI7yoUSklDOxspTzot/jzbMGfuvIvmv2T2/GPjKlCplTgeOIfknFyUJk2r5jen9fSkPn\nAlcDW4UQm/zH7gRSAaSUTwGXA4uFb7+8dmCePBVrXpyidDXoQwprePrMadyz8UVeHnsOc7b9j6fP\nnMYQWcO6kUdm6A9FeEItgz93cGPdv/k1v+WLAWMY+lYUz3oW8lbiD2htqOBniX8lJqOEyf/7gjkN\nH/DygAvJcJdz01sfctslPudkSdlDzaeTSTpvPQOyimmvH4CjPL3H1XQQglvko2zcmMmeWfswx9m4\nvuFZ9FA3GWIHN9c/xmvk4xXwS56lAzMejLzLD9lWOYZhlPKycTYveq5hFbMpCjmDMzq/8S8omwxC\n54O2S7ki0khe61yW4ItrLD799+R/dT7ovoyesAEN5L8xmyf1X3MPD7B0woVE1VWz2HInzV+fhu79\nDwAuQhgTUUTNp7cEP1vk4Eo+fzuHlV/MZ65YAT9azfid1Swz3sur+37CmKJQtmXBkBmrafYmcqa+\nlrEVlSybNuW4/naKvuVYDfrR0pdZQ5/SW4GW7m3+Afyjr/rQXzgeS/23J6TwlzX/5bMho7huwwe8\nNXICv9j4EbfO+Olx6GF3IlOqWH/OYHI/Ffzz07/xONdzA0+gGT28Hn8Bm84ZRHvDAEb9LxGPZsQJ\nzGz8BLc08evzfsu2lBjqC7Np2TWcuDGbqd84Ca87FMeeof4rSMzWRly2ASANhCVWUzrAxMptV5K7\nagWlJGAc0MiDDY9yT+KN5La/zDtcTKh04SaEDsy8wHx+xVImUEwHZl70XAVIQnAztfNT7uf35Isc\nNIOH8ORK2ipS+dD9Y5ZQyD08wAPaHbz29fVYUvcQmVzpz1qCqeIjFot/8gB38qtNT3DbzOHEUMK/\ntt9LJyYeGzSPaxtXcJnzbV4/9698Gpftk12GVbB9cApXvvlPVtbP5QXnmVxZ/jnXL7oaV9UAlr7z\nd24YP58vcnQuKlnLE888x/UL9i/8u/ajdWxJTeGLjOHBY2eV7DrpnMWp0s9v47sy5seC4b777vuu\n+3DE/Pmh/3ffoJQzv+tuHFeaR5roiDcc1e14UB1txSs0rinOZ6d1IGdVlvDPs2bw7qgJTKwsYfqu\nzWwalHbA++oLs5FeDVO0PfjYbY+iZdcIIgZV01qZTMuuEbTVDAq2A6hPCmVt9Y+Za3+bC1mLF41F\n59zCN+eacdujGLFOI0/MZY7IoyXRwGTHRqRB8kHWSKqjrUivhm3LeJy1SZhjm9lXMorAuMMUa8Pd\nEochrBXZacbrMmPMLeCj0jm86FxItLmBG5xP85fUBdywdwVNIRbO1z/HiI6LUF7nx/yC/9BJiH8f\nMt+a3/vEfehCI49cfs5/+EI7iz1aCtHDS2mrTiZHruVR0008N2Ey19S/xkaZzd7RJqJzP8Nj0sjI\ns5BnyOWGRfN5edJZrNvwU5buuofYtjYGtzRzdfYf+eeeu9k0PJk59tWYkmz875L9GXIhVju2c1qJ\n6Ozghvc+ZPnUybxy1iRq00LZmjaYJ555jgiXi9veXM31C67uZkxnF2zkptXvkdxkw2k2k9zUxFPL\n/0NddBROs5mLN22mMP3A3/dEE+L18sQzz7E1NYUqaxxnleziiWee4z8551NljTuhfYlM24cp1nXE\nt5OZ+hUf19x3333Leh5XjuA4c7QG/WeFawnxeqiOtgbPdbgGOEDA6EYMqj7ifk+sLOG2j19nU1Ia\nmbV7+DxlBNN3bcYrNG77+HVeHP+Dbn0LIL0ae9bMJDyhjpCIVsrfvoSWklEMyCzEbY9iz5qZDBhf\nTEhEa7CdKdpOQ1EmUduiuYIXMeGhkxCerr6FUu9waj47n19m/ImV52Sje0O4q2wZTw2ay/j27Qjg\n4/TTMUXb+e2+p/A2xLCr7QxfKqd/w/ifdLxDTvj7GN0aZXIo6CG0VieRUNPJaPMWfupaydLBudxd\n/zgDk3ZwW/MSOjDzEHdwDv9jIkV0YsSMh2LGMwAbWRQDgrvFH7iOp1lPDjdqf+Wr8dEUF/yE6YNX\nstJ9Ndf/8kpW5kxia1oyz2y+m81JadSPkbRtGsn86Gd4MukqPksaS1hGJeWmZD7+eg5ntWzm9tNv\npOj8ONqKRrKreSw7LtKJDNt3gHE+q2QXt725muVTJ3Plp58HDWaVNY4Il6ubg+iK02xmZtEmTttb\nw6yNRVxStAldCN4bN5Z7Xn3jOzG0AC0fTUR6DYRYfX/HVdY4NmpZPPnSv4jwtPfq1I6EozXmJ7tB\nP1qUIzgCvovReYjXw1/W/JevElKojrYysbKEv6z572EZYFO0PZhBM2B8cTfncLhM37WZwsHDmL5r\nMx8OH8vU0m1sSkrj0m82ctPMBcFMnZ6You2EJ9SxZ81MjOEdOOuSQEqMEe3UfHZ+MHDZtV1HYzwP\nFj/Nn7kT3QjLMi5ljG0PV+ovEb/Xy5dZgyj7gRfvq9k8U/07rht1H/+s+T3lk+BXm9/m3S0/p25A\nBB0VSTzXspgCJlJOOlO0D8iTV/B3bqCyM5039VlEjCnhS3MWj1X+mT+L20jW9vJF0mimVW3iJ5YX\nuKTuY1yY6MTMu0xnCusx4MGIznNcwfn8j1A60BEY8JLDx3gxsnJEDjW2DEbU1JI14j3iqzp59uKJ\nfBJ1Jm2bRtKY3cHWoclkd26iMD2N0PRqNo1JYo85mfpnfsSNjcuIGbmLD1sv5r/111MzNJSH3n6O\nyzOW8PllkexqGcv2aSbOKtkVHK2fVbKLp5f+iycuupAl0y9ga2oKTzzzHF5N47INBcwuKKIobQjT\nt2xj89DUoGEPSCv/njKZWRuLCO/sJMTr5Z3McVz+ZcExGdpjRXoN1D/zI8ypdYRY7bSXpFD46s9J\nPGMzv/14ddCpfR9H598F/dIRHK1B/y6ojrbylV+nj+h08dvP3ubWGT89LAOsd5q6Gd2jIcTr4d61\neSydNJ2/nXcpKS2NXFC6jS+sp+EJFcFZSW+zDlO0Hb3TRP2GsxgwYSPhSbW+x1mFxJ3+1QHtbFsy\nWRTyOKfpO3jinBkQ7mFnw3jO8hRSHxLLvxt+y5+/+jtz7O+wiKfYPCqR+HGbMHyYgeYVRA2q4q2t\niymNSObLlinkMZdIHDws7/QFcLWplMt02oWZB+ofJdu+jZnibSJkB249hJVTJxDf3MrExp3owJ08\nxHrO5zFuRUfDjYn3uZDpfIgZF14MGPGiAUY8FJJJbss75HEZv5H/5OOB4/hH+hVszr+M1o2ncWHc\nKv78yXI+N03kBXk10mugbdNIcrwfM6viE7blhNG2eiL/LvgDX7ZMoT7TzcSCeh4UdzF63x62Z8Ww\na98ZnL3na5a8ujQ4Wr/ww3LWRZ7LDUWvs9Wvo3s1jZvfXkN6XQO//sU1FAxL55KiTczesJEOUwhm\njycorfxi3XqG1dWjAR5NY8zeat4ddwZGXT8hslBvxjxiWD3hI/ZS8+RsjKGSxldzmJv7B+785EWe\n/fFZzF+3gZKJcVQnqkWkx4PvlSN48G9/vS8857yT0qAfjMORfqqjrUT8f/bOOz6KOv//z5nZ3WwK\naZAE0khIJY2QEEhoAemCiFQF8RA95FRULJx6p2I9xYKKBSsCokdThNC7ISSShHSSkIRUQnohfcvM\n749NVoLinZ6cX/3d6/HYxyPz2c/OfCY7+y6vd/nou7jnzGE2RYzjm+CfVna9BPBVQvfnYnJhBt95\n+HNXylGMgsjNucmkOAQyujaLY3YjyPEecE2vo7XcnUsJY3CKSKUufSjtl/rjNCyF+swws8dy9TyH\nKpmEGHeWp++jXuXI7dVxvC/8mUxhCEts1zO/4QCONLA7eBhpqbO5u2Yr69sf5BmXhwmIPMHC1h00\nlvhxQojFhlae5gXyCKARR04LMVhH5hJdmY8DDYzlNI1W1qCXkFAYk5/HgPZG9tmPJb5zIg/yNm5U\n4kgjtUI/vmIOqdpQXLXlZOiH4kk5KgzdfT4FBlLBCSWWBeqtvOzxZx4u+JKzliEU1kYy0Wknm3Kf\n4AuX6bwQv5H0fj6kH1jINN9NZqFe7afi5aT1fNs6idU8h0W1hjXSY/xTWYClYz0Lz5zGzrKevx3b\nwT3THyAl0pWOAg/2HniU87foyB1qa44HLD0RT1xkOGunTyPJz5eKvo6ke3lyU2oasfn5TMnI4r67\n/kRQxUXuiE9ABOL9/fCqq0cvigRdrOTk4EDSvL3M3+eyo8dRG429qKIrPZNf2zrXuDQhd1hQs3Uc\ns2LeZf3RV3hs1Ry+mRROjq8rr67ZSY6v6/+Uwa+AaykC8ccm/16xJPUYUeUFvcaiygtYknrsN1rR\n9+jJyulZXw/1k+PsYZ4TVV7AvMzTfDB8EvMyT//gXq5Ga7m7Oc+8PjOM1nJTFW1N6jDz31fOrUn9\nQR2JGZ9F3sDnEeP4ZNgEHjm1m6o+9gxpKuClkMUsy96PzyEN3nE2vOizrJfXUSO7UXJoOk53xyEO\nL0MRFRQJxOFlON0dJFbrwQAAIABJREFUR8mh6dTIbtTIbhTH3czffFYyYfhGNt3jT+cZfw47jGRe\nfjwZ1gEsUG8l2JjLwro4DEi85HIfmwpW8bn1XF5ueIHVfVZxrHUGyWIEsyuO8zW38JDyFg/wNp1Y\nMJQ09JgarQkWOmJtDhBJGoXCQFzam6mxcEBLJxpFZpffKKIbc9iqnssu66lEkg4oLFF9QrFXH17t\nfIpqgwvHhXFIyIgoVOGEhIICTOYoH9kt5tXa5/mT/xo2nl/FUavRbK/+M38KWMNLOe/yJ/81bEp4\nluMOI/jw8BtmCqajwIODzTP5C+tJNUTylP5lcgc5sdz4CVvqlvGRwyIeTt7J5qhYdh1+nMZ9I6nZ\nMAPnO+Ow9Csnyc+XLaNjeODgEbaMjuHvC+b1onaS/Hz55IZY1EYZjdFIdEEhj8btp12t5vNRMYw+\nX0BCgB8qWSbT3417jx1lfEsGNt7N2Hg3UzDckXc2bTKPjW/J4J1NmygY7nhdMmJaM72p3x+F84IT\n+Ce2cf/c+0gO8wIgOcyLx1bNIaTg58e9/od/H79Lj+DF19au7hsS84Pxn8uz/zfxr6ifnrWumnYH\n3wSPMM/tuZercWWbAMfgc2aaqCdo+3PjBy0+MjpHhYiqC9T26cPYwvPIksDHc0ewXZ7HjZlZPC09\nx2dzI5lYmo5ia+CCrwNt6QHYjTvLeI4z+Wgx+XN12ETk01XWnz7DcrHwrKarrD/GZhu0AaXok33Z\ncPZpciP60LellRVF2+hCja3SRrJ+OHP4hi+5jcf5B2+2PUm+hQ8z2o/yuXoBqzrWoXKrJTdrEule\nniyo38tNxCEAXaKaJ3mBJ1lDmosX/XMFVsmvgyziRAPVOOFhNG1rme3uRkR5MW/FzOSt8ucI7joP\nCFigR9O3icV1u/i78XnuMHzJjcp+NOhJIZIACjEgIAKFGk9GtqSR5e9EaFEVbQ4iMy8fRRYENtbd\nh/+AZG4pjSdCTMW3+ZKZ6+4o8KBmwwwu3F3LmHN5xOqSKMOd0PoSNgZPorrGhyda3mL9lHEsTj1B\nzuC+ZMbPwcK7EoepSUDvgPHtiacpiHKkLtDSbHmPKs/n0a2H2DgrmvC8ckafLyQlxJMX75uODZ3Y\nt3QwrLCMPeNCORsykC0zRzA1Pgef8jrSgzyodLE3W+JWHTpWbjzKY6vmmIXzr4nWTG/K1szHc9U2\nHCelkRboyemP7sPStxKNSxMAlS72pAd5/Isz/f+HyZ75+NjV/6xX4vqcPw41dC1F8HN59v82for6\nmVyYwRfhY81r7bmX4JryH80aair0xyk8zWyda+wuw9AqWpv6o70hF41XNRd3zqDTWs3ig8k433iS\nS+O70DkqJoFfX8DE0nQSI73QOX5fw6c2GvnL4WN8fEMsoWUVzPkuFaGqDzNV37BA+oLkCFeGtWTx\n0pfbSfP2Ynbzfoa1ZPH0zm/4fPYQqv1UjGk4y+zm/UQWl2Bl10DdsE60gyrRel/CW1WILs+dvyZ/\nSWx1GnpJQBAh1ziYMZzmEBMZyykK8GUgpUTrz/ItoxkpJpIsRHChMRxV/wbyL4xhgvogg+RSVBh5\nVXyE9TPHEF8wi4daPuQOcSNpxmH4UgiAHa3mnqGNki19u5oYeekcalmPlaKjEwuOM45b2g+wwziP\nF0YtYmx5Fn4UY0DEnUp0qFAjk6v2xV1fzYt2K3mt/GUqtf1Ycnk7X9jdjE9nObfzOYtbdxBGOjpF\ny3tRM1h85ltaiz2JunCBvNl6xnOcO1OOoTIYceQyORYBjLqUzQz28aTFc3y2OIYsN2/W732TFHU4\nb9X/jf40YO9Sx5vv/ZNVj8/B3tiGc0MLcw+mmamTqMwSXl2zk8dWzaHSxZ7JCbnIgkC/pjYOjAmm\npm8fFuxPRRYEBl5qZNOsaADu2RrPlpkjzPRLpYs9Vh06lm+NZ+OsaL6ZFP6Ln/s7d55GbTD2onai\nMkuYcuocJxum0W9mEjZhpi1JNC5NWPpW0lHghnXQf7438v91/BJh3vP6Jfj/QhHAz+fZfyl+brpn\nz/sPJcSxKWIc8zJP97L20129zX/3WOfFXo6cCfYyC+8rX+rgi+DV3Hus72W0g0wu9H3p36DVtpAZ\nPweHiEw++e55jKJI1IVic6721SmDPTnbK+5czI7o4ZxRRTInN4FIJYMDkcFsnBnF6vcPcFfRHt6a\nPpmnd37DgMZG5iSnkujvw/uTJxJdUMj7H39GjZ0t8YEBfPT+Z7Q29yUzuL/pvZ0fsNc5loCmCvpT\nw/rJ45EFgZH1OaQQwT7LSZwwTOANHmUAVRxiImFSJi8Z/8Y69QpEjzpGlBWiETtZaVyHiAERheFK\nCvGtEwhrPc/9yvu8pPwNC7oIJx01BgRAjxojIi6dzWwceBNDG/NQKdCBFgURV6rYxnxmC18RWV7E\nGOEUMiKa7s+XWA3ARt+JpaznWe2TSG1qJIzM03/FJ7a3Mu/yfqoEF/pTgwoZFTInPMLpOO9Bk9GR\ne2q+pCYKhqhzcNM1UOVsS0hhJQZBor+hFgkD8cP8aAyChk2xtKb7IAkG3CYkoXK8zH0n99LnIrxx\n73gCLlTx2KeHOTHcn/W3xRJSUEl6kAd37Uig2L0vhQOdeXXNTh55fB77YkNBUbhvywmmxefw0JPz\n2RcbypT4HG45ks7kU+d4+Mn5Zos/KrOEu3YkcNPxLDbOimb+/tT/iKNXG4y9eP4eZbVl5giaxl82\nW/490Lg0/aZK4KcU17U8k18q0P/buJYi+MNtVXk1z57s5ntdPIIezr/H47iS2oEfNuGKLijklUOb\nuf9uE098crgP6zZsum6pe8liBJ+mPMvSYbAvdylvh5/hmV2b2RUVyZ+PnvjR64aVlfca19c40qVR\nUeDsxKzkVFBeYYKUh8agBzDz1AowKr+Qze+uJ6SsAgGIixhKkp8va6Ln8UzC54TUlXBDxVne8LqD\nx3M+RBCNPC89zgPH3sJC0XOs3zDG1aWS2xHMTL5Bh5pLDGAEZ3jW+AxPSi+yVbeAZ0re5YhwA39T\nPQeKwjRpD7f7rGVJzmHiKhYjYeQx9T9412UhoyrOsYSNABgRUGNa94cOC6HEGgU1KrrYajeZ6c0n\nAIUN/Ik0JZzXeZR2UUuNxgH3rmqMooBP+0XeF5dRgC9T1HFM6zyBD0Xo0HLH5Z1kE0yUcrZ7Q0uQ\nEZla/h16ztKhsmDblEhmHstkxVO3EnChivkHUjkeEEZlURCLDf9EQqFPtREvpwvE6WbSpWhZOOhd\nxrltYs6JBLYMH8eiMyex+6KRiNxytk6LZHJCLodHBbFhzkiiMkuYkJhn5tSvpHOSw7wIKK6mwc7a\nPPbFTcNZvjUeUf7eI4zKLOHNl7ahACu7lUPfpjbWvrTNfNwzL6Sgkg1zRv7kc1i7czTH/bx5bBW8\numYn26ZFMm9PGn8e/QwFYa2/7OG+TpjsaWrfrR1t5K1V29i8JoaiKGd8kmtY/Hoim9fEmOf80XBd\nu49eL1i5eCh+tz78g/ErhfHVwvmXKoOf6qrYY0FvGR3DolOJPynU/5ul8z089KxJL/Ph4TfYGDSV\nxcknOREwmHn58XwVFcmjt992zXUsO3ocgyjyl8PHODgkhLiIoSw/fIyx+ef5algEbRYWLEpIRCdJ\nKKIIsozWaDRZ3ZLIKzdN59Px33cj/fS1jYwrzyLBJpLg1kIElYHFw18AQWZTwrMIaj2Lh7/A3IQ0\n7uBz8vFlOR8A8DWzUQk68pVAgjhHF1ryJV9aAtuosbOjs8idrZazeK/kKXwooZL+xGknUdgVxDyr\nLxjcVsRXzOEONgOgRySzny+VdX5MZy9fWs/l5rZ9PMVzpDOUKJKJ5QQleOEplDJd2Y8sCqhkhXqN\nLSpBB7LELP0eToimPkLrWc4SNqDpVjRgUjxSNxklABXOdvStb+PloUv5+mkX3n32S0okd3xS2oiW\nk9k1JIZpGWfRoENEoRMLQCBeHMVE+SivLZ3E57Oi2b5iPQGltaQEebD05SVm63rbtEjm70+9Jpdf\nu3M046UjvLPjXf4c/QwW7nW8v2UdaoOCopIxCio+9r+FJSW7OBodwIGxIb2E/psvbePA6CCev39G\nL/oppKCSbD/XXte8UklcGQNYlbWB5VvjeUHzVz59OsBMB/3a+DWEtU9yDYtXJZI4z4eY7UVmpfB7\nx+vh2360++gfihq6Fs/uaywzc+E/9/VT+FfVnFcidZD3Dyo3K/o69srfvjJtr+dv94aGXgVFz27/\niho72x9QOleO9wRwfW1zGFRby4KsBPYFRDK+OJMDESHMSk6lVWtBmreXuUjpdICfOYVQbTTy8hfb\nOOPrTZtWy+Pf7MW7tpb4AH9iz+USfLESQZbRKApnvQbi2tSEpCgImPLTIwvKaW92JLoql5f+uZ2h\nlcVka/0Y1p5NruUg4qMGMvFiCpfz/PgoZhLbrWdx09k0ZrKXU8QwnFQyhBD+ySK60HAT+3ClCh0W\nfMltnBTHML8ljpPjfFn83THubNiBI41cwAtPKgg2nOcwE5mgP0kf2ggkD1CQEVAhY9WuJ5Qc3mc5\n+fpgXuNR3hYfYLswly+UO6gU+7NaeZ4zwnBaHFX4tF9EASRBD4h8ya0UefVjdvM+EoTR+CqF3Mh+\n82aWl60tsNKb6CQDEmWCJwPbqlEUGFWVybiUfD64dSyPbtmPt1zOtmmRTMjM5sjgoQRVlXfvbiBS\n42BLREcOh6XxrJ69iPc++oBh58o5P9CJkKJLBBVcwrWmiUpnexbtTSYjwI02SwtuPpphDvz2UBpn\n/bw4/dF9lM5t5+O4NdycfAaj0YJ77ryXPWHR3Jx8htjqNDbOiub1uyf3okUqXezJ8nfjnq3xPwge\n/xTtU+lib+b8B73kwtO57/GG9BB/Ub1L4Rjtv6Safku6pdHNGot2A5M+PMfJOwJInvXbt9/4NfCH\nihE8t27taosZI34gtM8Ee1Hs5dhrrNjL8boVy1yZvXH38W/pVKt65WNfmXv97+DKPivVdna8//Fn\n3HQ2nU/Gx+Le0MC6DZv5avgwnt75zQ96sVw5XjeskzENZ3n/489wab7M3vAwZmd9x9qbJvPKzTNo\n1Vrw5K499M+G+0/tY92NE/nL4WNkeXpQ0DAEp7MWzKo+jmtjEx1qDYNq69CpVOyNGMLwCyVojEZ0\nksRZby9GXCg2bwef4+6KTZcOS30XE8oyMLZrGVpZjADYGtrJsfElvD2PsPIKvhwZy5bFQ0n5+k/c\nYtzN/S0fc5v7ByguHVT4WvHoxY/xt8nmft0HgIKEgh4V37iP4++dL5OgH8vMvNPUa+zpqzNlQlkJ\nbRjQoKWT0ZxmO3OJJgkNeo5yA34UAWBJF2c1IYw0nuEtHuIE40m1DOER3dtUW9tzXDcVP8tsFuv/\niV9HKUbBlCmkkhWQBQ5N8eOlnLWs1T9CiTKIpdoPCDLko8KAgoCl3oARk1IQUdAK7RzjBvwpQqUY\n6dvUxo0ns7EwGtg6LZKX/nIjVh06Fh9NoAsNJxjHQKEYx442yl3sCW/JY0ZyChHFJRwf7s9dLy+h\n1dKC2/Ym419aS+CFKvaMCyU6vZhxKQV4V9Sx8ZYY3KqbzEK5LgwsfSs5/dF9TLGOw6+tnFdVK9nq\nOw2br9yYL20jLcidsSmFPxoPuFbw+FoZRiEFlagNRkKiqpnRfJrn9q3jha5ncI08T+7fbPjrcwfR\njJRxDOrkrq8S8LeuxTGo0yzMJ5/PZcihckqG9vvlP9D/AD7JNUx/K5OTdwQQs72I8mBHGt2sf5O1\n/Jr4QymCF9auXW07Mvo3XcPVgdVOtYond+3pZWlfHZC9uq8KmGictvQAtIMqqejraG4b0GhjzdDS\nMhSgvo+NuefKnsgI85wrG4xdPf63r3cjAMvvXoJKljk5ONAs7PdERuBZV8e8vFO8LjzMezdMMRUp\nfbwFkgbyQtWr3PfnxdT3sWH+mRSOO0Xi1l7H6MICZFFAUBQy+gYQUldKi5UGqy4DaYHueNQ1kuPb\nH6+qRmRBYFBzNccdRjCgsx4tnVweINK3uQ2A3aV3kDfOmtiOBNZmv8zT0jMkPKahb3geD395iCwx\niKmdJ6A76JpCJC5UM6b1DJIg46FUkG/vTVhjEY1aa6wMelTIJKmGMUCu4jJ9OC/4Y007tlwmkAKM\niIgo1OOAj7GMv/McuwbFMrr5DMN0GexgHlv1t5PmEIDQomE6+xCAsgEOWHXokBRTDcHI0jziLUbg\n2VVFq2jFc/rnkSUoUbxwot68Z1m+kyt921tQI9OGFS7UACApCipZIXdQfz6/OZobEvNYvjUenShh\nlNW0OEq4d9SiF0XsWzuocLHDu6GWEldHlqy5E4DMQHccm9oIKqxEZ6HGp6wWSVEQZQWDSqLO0eYH\naZ8alyZiSs5xZ04c64PmcHfTFpoy/HlbfIBHn7oFnUZNSshAHv/oYC8Lf8qpc8T0LWHx+u84eUcA\n0/dkM7y5BI8BzTgGdWLpb8SqQ8eCTamUD3Hg3CMeOKta+etzBykPdqTPATU7C27n76oX+Ef9M1ya\nquXyJAMe2Q2UDO2HZJBZvCrRLGx7aJn4Rf6/ifDtuf7mNTEkz/KmPNix1/p+z/ifIviVcWN6Bp+N\nG2Pm/NO8vWjVWrBy7wEsDAb+unsvB4eEcH7AALMiUIwSQR/34ZaGg6SHDDBz+XbjzvZqutVDN30w\nYRwZXp4/oJ6uRUldOZ4yyItn5s0myc+X1EHepHl7keXpQVhZObZOl1m222TZLSnczcm0RSS5D0XM\ndeApw8u8IT1EsT6Ap1I3sD54DjdeSEIj6FEpMkYk4oQbGd+eSHKIJ/5ldaQFuhNQVEOa/WDGFuaS\n49Mf+5YOdIIGr/aLGESREk9HAkprSA3yYMOwaTxz/h2cTlqysvgztolzOaYej3tjHeG1hZRK7txY\nc4p2LLFATwIxjCCZ44xjsHKeStmVVhsNYY1FlDr0o39rM0p359GBcgVyd01AMDnsYhbDSUZEQUDh\nosqF/nIdh5jIEnEjUxpPsEJ5jzd4mCjO4EwNj3a+zShOo6ULAyKOrR1IikItfbGlHaMo4NFVRbAq\ni4EO+bR22FHQ343olgzqREdQyVywcSWg8SI5DMaJOgZQg1EQzPSRDNh0dDHjeCZjUwupsrHD0GGJ\ntdiCR3stRwKHcG/bJ0xXfcOAphaqHaxxbmglLcjTbK3fui+F7VMj0Xbp8a5sQCUrnB7ijcooM/G7\nfIrd+tJiY2nOdJlzspzn/vkxq2fcz6sZL5GqDGODvJQvhIXkLfDGz/MCd69LIHuyGxPS8nDya+ev\nzx2kaZQVs9ak9xKMU9/LJvxgOWWhfXGsbGPma+kookCf+i7KQvtSFOVMebAji1ae4Uj+zTyqep0v\n34ri0lQtcaseQjOpmsbpJuq10c3aLGwt2g1MfyvzN+XkhxwqJ36Rv/n6PevrUVy/Z/xPEfzK+DHO\nP83bCwuDwSygj4UE92qpO6bhLBvOPs2rl56nWO9Hw+6x5mrRHlxJNy05eYohpWV8OGFcr06T0QWF\nPL43rlcvlrpAS0aV5/P3TXvZPyaYyIIyjk/xNY/flJPGoZsC0aq6zIE+x8vtpIR58mLG2zRl+POw\n6nWOjPFncekebqo4yVx2UFAfxu3CF1gYdZwVwnFWavEXCzkmxDK+Ko3TQ7wZkl9JhdGTiJZzlA5w\nwLesjlemzCexZCrjjfGIihGn5jYuOtvhX1LDJT8tYqvEpMunOMUo2hwknu16gVsqjrG/7FaW129C\npRjQoucC3oSRzWEmMIUj1NGXAVThqGvBIAg4dLQDvTe+EFGQAS06okhBRKEZW7R0YSu3cYgJTOIY\nmUoIw0nFiIovuZX+mossNW5ChYwlXeiREAGp+3w2dGAUQW1USIz0YvfkMBafPkGh8wAmVp2h3NIZ\nG3UL7y8ay+jMAs4ahjKMdPPaRL5XAiIgyAoaoykZwUJvxELsRCMbSQ90J6K4hDnKdhw6O6jqa4Nz\nQxs7pkawctNRbj6bzn5hMcIgA499vAu3miaE7pwGj+omrDu6QBRwbmilZqIt6rGgPt+fm57KQR+s\no3KELcMT86kUBhDjfoKJDd/ScmAgVT72uOkridhfRqe1ihG7itm8Jgb7qo4fCMayUFOq89R3s4nc\nW4oiCmx4azTpUz3N1nNRlDP1SV6sKP2Eb5f4kTzLGzu3WlyCL1CV7YPb0O+Duldz8taNXUgGuZcF\n7pNc84vponEb8v7t85UM7fcDy7/Rzfp3rwTg2orgureYEARhqiAI+YIgFAqC8PiPvG8hCMLW7ve/\nEwTB63qv6XohuqCQRacSeXvKRBadSgRgxZ2LWbdhMw/tO2Ciku5exNlYe5oOxmA7OgOnydnm0v6e\nUv5VT8wmY8wAEBVEUSFjzABWPTGbdzZtYnnGQd7ZtInHVs3hvUXjeGzVHF5ds5PbdyXx6pqdvLNo\nHKPPFvHx3FG9xrP9TJuuX5lWmO3nyl3/TGSbPJcXpL/xD/7KqDPFJIV7IaiNKHo18/U7MAgSj0qv\noFc0KKKASjYQq8SzSVzIyIxi1AYj/koRX4fH8K1NNO1qNQ/t38MK4S2KXR2QUCjBg1UzlqFTq1iw\nPxXfqkscEicwmcO4Ndah0RuwFNpYrP0UyQidWGFAwodiLjKAscTThhU2wvebKYpXxfJNQVaT1a3G\neOW28ljSiQ41bZIWweMyBfgQRRqHmYQBiThm8pzuefSoATAiosaIhNxNKUG1ow0qGXRqkRFZJTyw\n+RinBgUxvjqVdAd/bDs6UXcZeWDzMUold0Yp35nX1aK26KUQFAHUsolqUgTQynrKIx3Z88gQhuZV\nIFuAXVcnAI5tHSTO82HewbNYduppddTSP6SIxA/mIBgFJINCpfP3RonKaFJc58YMYMKnefgk11CV\n7cN3D7oRXFzMI+u2EnDzKb4WZuNVWoWoKCwxbOLxN7bg810dBrWIR14TeaP60+eAmjWsoijKmTMb\nZlKWHAxAUZQzO58aRpOlDZpOI6cW+lEU5UxRlDNHlwYy7jPTdecW7OfwsiBithfhk2yixjyjchh+\n5+5e351Pcg0x24vMc40qgcWrEs2f6aFrykN+Wavs8hDHX/V8fzRc783rJeA8MAmoAJKB2xRFOXfF\nnHuBMEVRlguCcCtwi6IoC37qvBaeHorbow9dt3X/XNh4N/dKqUsO8zIfH40JJLigkqALVaxfMIY1\noXfy+LPxDOyXy/GG6Wx7yg2bsGKiMktY8nUin90SQ3KYF3fuPN1LePfkiV85pwdXj/dc+1SEDxMT\n81jx1K0/mlLYmunNoJdc2Nc5k+RQTwILalnAVnJuFVi4JZ1pDrs4XHszg4ylbFXNwX50DttOPIqE\njIyAjIiEKW20XmWHYlTx4J1L8cts5pmUD6l1tMGxqY0sfzfC8yqosnTEpaMBEbjIACytWmiUbPFt\nqSQfHwZSgZYuOrHgE5ZyL++b19qJllmuG5ldfZDb+RKN3IH6ikdXgW5L/6iZfoHvrW8FOOAezQDr\nckLPX0RQIJVIwsjkBLFM4QgAOtTkuroypLLUfF4BKGcAblwiblwok07nYqkzcMHRGe+GGoo8B+BT\nfomUUH8iMwtQUJC6r62IAnXu1jiXtdJmaYF1RxcGlYDKoJjXaBRBlMGoEvjo/VjmrU6m38U2Oi1F\ntB2yqS5BlBBlI7JKYO+DYUgGBfmYI5OyEqm2dcTr8iW6VBIWBiMAhu55ziUt1LvbcOLOQMAkAJes\nTEAyyAhGBZVe5ny0C/5J1QiADhV6rUTuxP5ExJXykfoujr7niWdUDmXJwVxeGcHtU94m/SkH+my2\n4sHXv8JS04Gsgc/WjiJv/0ieP/Qmx+/xY8KneWxeE8NxxjNgfxcvHn/9RymfKzl5c97+qkSOLg1k\nwqd5v1oK5x81JfTn4Frpo9dbEcQAqxVFmdJ9/ASAoij/uGLOwe45iYIgqIAqwOmn9i6+XorgP2mo\n1SO4rxbQi3clMTalAL1aolNU8xxP85y8Gku9jpemLWB1wifMn/ss7+x49yf7uVzr/Ncq6rl3ywmW\nb41n/YIxvLdo3I+e79SlyaSNdeLNI2uZeSKLkgEOfNtnBJ8Vr2S7eg4rbv0LVZsnskC/g9l8zYNL\n72Tlnt0Mq803CzE9KiQM7BWm8eWdIbyz412ORgdAoSPzLhylw0LF/U/dxs1H0pl5Iqu72EpAhUK2\nzwCCiy5hQEIWQI8GC0WHCpMw06GmlIH4U4gONRtYQp7oxw0cZ6pyELVi4kN+7EHpWV/P9aSrZiUQ\nQ4BwngRlFDezGwMSYrf1r+rO+RG7G8zJIggyrBeX4R58nknFCai6jKj0MlkDfAm5VETFYHs8chvp\nsNBg1aUzXzsn1pXgbyu53FeLXV0nrbZqrC/ruRpGlYBRLSLpZCSjQqeVhLbdyOV+WmzrOhGAU1IM\nRbNtuWPHQb4dEUbQdxf5JHABd+VuA60ep85m813q1SJGC4nP1o4yC7txG/IoD3HEN7mGSR+abLFK\nP1tcCy5jlAQko+l+z4pD8JfOk2MMZricQuI8HxpdrSkPceTO+xJ4WlxN20Qdq/e+w3sP30Q4ady4\nLgtFFNALKuZIO7h9ytu0TNVznPHErXqIGWveZDzH8chuMCulHvSs60qh7JNcg0d2AxYdJrro8LIg\nDt4b8iPf9M/DlPeyf9Xz/d5wLUVwvakhN6D8iuOK7rEfnaMoigFoBn7QZU0QhGWCIKQIgpBibG27\n5gV7aJZf8vpPsGHOyB8V4mHnL/La0kl0qVVo9UZe63oSQVJ4bekk7k3YwxsRt7Fuy4f/sqlXtp8p\nRS8qswTge6v/0mRaM3unp4bs6mTerkzWLxjD/P2p5s9cfb6Pkp5l+YUvGX22iIQh3gy81MithUf4\nWryZFbf+hZp/jmMbCzg0bRB3DXuOtzZ8Srnr9660gqk///v8hbWqhwi7WMJjq+aAIDC+PJXnVY+j\nQ8X7z2xhSnzHEXoZAAAgAElEQVQubViiQzJz7sFFl0wFaNPm0qFYIykyxxhvtuizNYH4Ukgq4XRI\nGkLJ5HX5r0xWDqFSTJbyleL9Sk+g5z0BE8dfZ2Vnfr8TDaNIpEzwYCZ70KEGFNo0WtTdHo6A0t14\nGgRF4HDsMG4XvmBs1lmemPYI+/xjOe/tTsilIoo9++OZ24heI2LVpUPGZJHr1SIBiVWUhPbFtq6T\nFkcN1pf1yKKAQSUgS8L3sQ1ZocbLFlW3MFYZFGo9bbCr6zTfzyhjIrduP0a+oxexSZkkeYRzV95W\nTg6OoF9nM3L3/V3up0WtlxENvYshy0McWbIygbGb8tFpJQySwICCyxgFEI0KNR7WyCJEyhlo9AY2\n3zidxHk+jNxeRP+iZhavSuTgiiCe4GXC4i6xevr9OAeWMOHTPDIme6DpNHIx1A7btWdZdmwHm5Lv\nMysBz6gciqKcf6AEAE7cGfgDy7woypnyEMdedFEPrfNLcTX99J+e74+E302LCUVRPgQ+BLDyc1V+\nDxtEX8nH27Z1snxrPACZ/m58Pisa27ZOHti6h/ULxvzLzo497XivriJNw8lcuWkTVkzIrk7e2vAp\nK+5cRvYsLcmhXr0oqyvP9/HcUTy64TBxsaGMPltEYrg3I9OLEfVGbjlxlht4n2XjnyJtlBPjOU7V\nRWtmZySarGRMVoQRkbuFD/mTfiML61/DiUQmJObx3sSbaD1iw3Pyal4zPo6AzAkhlhiL06g6O+jZ\nLcKoEnHL7GK2tJM5xq+4l/fpEtQICkTosugSNfjIF/jGOJvb+ZxWBzV9Gk0Wt14jsn9FKNNfz0Di\ne8EPkCv4460qRq0YkAwKTu0mQQlgiQ4FiJTTabNVo7lsRIWMQVShCKAoAi30wZ7LGAGjIuIQD81O\nWow6NZrt9nwdPZNtlUvJ6+/DoLJL6DQiGp2MDOgtJSp97fA814iiKHhl1nM+2oWApGoanS2xr+kg\nd4wr/t9VIxmNGCXTqt3zGjFIAookkB/Tn+CTleYYQp2HDc5lrWjQ411/kS5Bw9SyE8SFxTLr3GFk\noANrmm2tcKurpWywAy0NDvhuauktZNtArRgp6KaDZMEUayl2cMW7vBKDKCIio0HPLfu/JVIqI3XG\nQIbFlXJ4WRBbAmfzviqCL7ULaTjyFxadOMPRe0wUTo+AHc9xyucFkfThXKKX7cAzKudn/3auposK\no5x7Hf/W5/stsdjh9C/+7OvXGL/eiuAicGWXJvfusR+bU9FNDdkB//1uTNcBPZRNVGYJC/ecocNC\nBQoEF17i9l1JzN+farbak0O9/i1lsG1apJnySQ7zwoZiPFdto2zNfJ72epgp2Wf5YOpEsmdpzZ/L\n9HdlydeJ5vP30Exqo0xcbCgzT2SRMMSbobkV7B4Xyo3fZjPvwlF2jwslbawTg15yYa28A6uuTgyA\nETUa9N1BVBm1AopKj19WEzMup/Px3FE89PUuXn/AkgFrJdqwphlbJilHqXW2oU8ZZutVrTdgYRRQ\njAKLVZvQGdQYBIk8ZTARpKFICslKFHcom/lcXMhwu5PYNF1EVODkkkD6lbWalQB8rwgGK+d5NfAe\nRgUeYeT2ItP7gqkGwsj3cQPry3oUQCeqEDtFsp39CKkpwEZoRVHAKKrQyRpq6cfghhyMejWOg8t4\nLGkbNzidxqOqDhnQ6GQz1y90KnhlNVDl3QeX4ha6LCU8sxtImTGQyLhSGvpbMji+ElklcnhZEGM3\n5aPpNHkiFyKdqB3Yh5E7imh00WJ9WU+TkyXOZa1cdHbEtaYBFQY6FEtESWRG5gkkFHSoORw2gqnn\nEigb7IBHbiMpYU6MjM+l8sV+9HW9hP839YgKHBXHMynpOPnRLrS02WGdDW3u4N0IalnmZPQQBl8s\nYmL5cVKVcPxPnOfwsiBGfFHC61+YYgRFXY48EbeGLeoF3PTBHo7eE4hkUNi8JoZFK8/wDY8QvWwH\nGdsn4xF17mcrA4/shl5CuijKmc1rYvDIbvjZgnvchjz6lrf+QOhn3eD2i873a+E/Eei/Nq53jECF\nKVg8AZPATwYWKoqSc8Wc+4DQK4LFsxVFmf9T57Xyc1V837j7uq3710RUZglrX9qGADz0pOm21j3/\nT7RdenP/mKsDzVfjysBxj0ewaM8Zc+8XgOotNxC0VWGX+iZEtcF8rSuvfWXvmFfX7OTjuaO4e0cC\nud4ujMwoZuu0SA6PCuLNl7ah0elRG2TOzhjI4KNV6DssyPLwZVj5OSzoRCeokQQjatlE0eQPcsf/\nQgWHAkcxujqF0hBHOpr6MDCrgflsQ1LrOGiYiqSYgqNxK4cw9d1sNJ1G2rDiWOhwavK9qPOxYkXu\nZ1jTzllhCBqli2DyODR4JFFFOWxX5nKn8pnZhJH0Mm22aqybdRgsJEpD++KTXIOoQDVOOAl1dFpL\naFt7dhjr9mREkOTvs4pKQh15beAKXoxbi43QikqRqbBxwrW1Fr2kRieqmKnfy8DoDF797gWSfYOZ\nWvAtBfjgT5HZsu7B6Xk+2Fe1ExR/CQCDRkQWTWpKpTMiyrD7kSHELw7gzhXxBMVfotlJi2WLHlFW\nOHOzN42u1oQdKsczt5GLzo441bSQO9iTsNwiujRqUozDGG1MpAJXkgaHMCfvEKfn+jDkSAUlYX0J\nPllJSpgpgH2+rxfu9dVIaj2ySmSXYRa36beiR83Ljyxi7pmDBMVfQq+SEARTELlisAPuuY28M2Yh\npesM6J/z5flDb5I1bQAjdxSROn0gIYcq2RcwlskVp8yB4SsDymXJwb3ood8C1wpG/xrewP8lYf7v\nIHxgxY/GCK6rR6AoikEQhPuBg4AEfKooSo4gCM8BKYqi7AY+ATYLglAINAC3Xs81/bcRUlDJwTHB\nHBgTbM4GOhPqBYDa+D2HezQ6gJCCyh9VBNl+rj9QJgv3nGHqqXMcGBvCccZTvz+KcwuSmbNnGzuN\nc3jn+S9BAYNK4vO3YnCI6mIy3XnbnhDf6MdjbxwmdfpAIg5Ucih2GDfHZ3BzfCafvTWKmjwv7l2/\ni2FxpVQE2vMP3wd5L241+VpvvPVllEY54p9UjV4tIhgUAi5UcD7ahalJCaR0Kw9NRw2fSEvovKue\n0RsKEBRTV05BhqnvZfPpujGEvdjEwM4KnPzL6NvUzI7c20GU0SMRIuegxkCWsx+Hv3TH5sVqlm3/\nhK9DJxBimYX/mRp0Wol6dxv6NDag6pJRdxgwWEhoOo24UEu54oZH60WMiKR4DiaqLMfEwcu94wse\nOY3cmJuEYiGj6pJp0Vji3lpLRR9n3FtqKJM9mDJ4Bw1JnuyLHs2fkr6hwdaGgMtFHBbHUx7uyNKz\nOwFTfMCptAXXgmbOjRlAYMIl1DqTwkydMZAhh8opC7BHMij4JNcwMLuB3Y8Mwbm4hfBD5WCQidhf\nRlmIIx65jZQNdsC2RE9i9GBikzJJmTGQ/oXNjM5LpJiB9NPU0lTkyqa5U5hz5ATIMsEnKzkf7UJY\nRhEH/MZwY8G3KIBeEEECB/dKhALQoOeRj7dg3axn9yNDcMtvYlhcKXpBpKPDit2PeHLnpzvZnBzD\n8WnBbKydxbK4rex+eAgTPs0je7Irt+w9yrnRAwCoyvah/9qzpEc54JNcw7jsPFhjGv+tFEGPN/FT\nGUO/N4H+a+P32X30d+QRXI1rpZn+q2DxU+/uZUZCFqcW+pkfZIA+B9QsO7bDbHGVJQczdEUbT3Su\nAfjR7IgeV1mtMzIsrpQdM2L5+MSjbFYvoibEmmfvWM7llRHsNMzFwqADWWCG1Tf4jEth9d53qAy0\nZ0huEfnRLpSF9WXSh+fMtEiDqxWOl9rZ6jWDPqUGpskHKIh2wS+pmjhxGpOEY1gau1AwWc2irBB+\nsBzZIPK58Xb+rP+Edqw47hnDTWVHUYA2rNgZPYn5Kfs5e4sHolEh/FA5kkHGaFBR7t6P2igtMduL\nzBa+ALR3Z+i0YIUNpsKzqy13WQSDKKExGM3eQq21A/3aGlEEAVFRSBXCCVTOY0U734TdwOisDC57\naBhUdolK5770qe9CbTSgpROjZKKfJNn0vy+Mcubu+75FrZPN106ZMZDAhCo2r4nhxjczaHXUsmHd\nGMBkvS59IN5UW9BuJD/ahY/Wx5q9htQZAwk9UoGm08hRaTxjhXgUlYKhO1vniZC/EZuUaf4fnIwO\nIzKpEOvu+wcoc3Nm4MUadKIIsmm/Bb1GZN+KUKa+l03JkH74J1WzTzWFje+PZDzHzc/ZhzfMpWWq\nnqIoZ3MGTsqMgeg1EqHHL14Xq/vfxb8S5i6vN9P/7RaqHuhD9SN2/5U1/V/DtTyC/ymC/zIme+b/\n4nzmH0t9O7NhJv1DiszWlk9yDXesSEQyKIgqI0aV2CuFsGfOkpUJAJxa6MfoLwqQjSLPKk/zBC/z\nDx7n76oXOX6PHxPfzUPplFCrdcgWAtum3cDc7fEUDh5AWG4ROq1ESbhJcPQ0n8uPdsEvqYbN8yYT\n3JHHsLhS6tys6XuxjU6VhlNLfbnh43OIsslCHnykCn2nBUY7GfuWVroELYpRRBSNqFR6ZIOAhWxk\nY/TNtN9lyl7JmOiOe24j/QrbEDpFFK1MSngAsUmZwPfK4CL9ccW0ReWVGUU9xwqQ5+xFYE2JKdW0\nO8c/39mLgJoSjIIIgsmzEgwKGtlA5mAfQnMvcC52AMEnKzEgokLmQ/VdaGdVcMf2g6ags2AKhgNU\n+djhkdto/g5KQx1ps7dgUFodYMrBBwg/UMbwry8gyVDpZ4dtXSdHlwYy9d1sJIPCd+5hRFVko8gg\niHBxsC3u55qRFYGL7k54l12i1U6NTXPvFFWdVuLEiKFMPpliqm4WQFCgU63mTWklDxnXotXrqQi0\np19FG4fuCWLKunPmVFH7oyIFb2NOAe0p0LryGQZ+lTz962GdW5/uxOu+Buput6bf522UvOtI20jt\nv/7gHwy/CTX0R8Z/0vO8KMqZxHk+ZqH+7/xYrk59K+yu4ryyQtMs4FWwYZ1JsCxZmcCSlQk/UAZX\nQ5Rk2sbpmB33DXtVUzk30VSV+uSNjzBGl8DcuJNU+Ngz58gJXnvkNhqKXVlT/AqaTiPWTd8XSVX6\n2eH/XbWJI8/V4V9Sy4WIfgw6W4dBEpDVAhfT/TFY5KPpMHkknw2fhbd4gdikTPSigCTLWNDJZhay\nwLAVjWyqEp575iCZbq6UhPVl5PYiNs2bgmJlyZIzu0jThRGRWkAblmjpMAeQXanqrjZWemUVKUDB\ncGe8k+sZXFOCXm2q0E2Z6Y2usg+xSRnkR7vgWNGKU0UbF8L7Ue9hg3tOA0Nyi6gItOe52+/h8fid\nRMiZ5Ee7MEidzsjtuRyKHYZ/wwW8shoQdTJVg2zNSqBHCA/MagBMcYLKQAdzkRdGBVE21QE4XGrn\n0D1BTFuXhSIJ7H0wlCnrctguzGGWxS5KhjnildKAwahCI+gYVHYJowg2zXpTTYJeNiu7A/eFAHo4\n2f19K2CQBLAA3T01HDo4mhvzT+KR14ROK1EZ6MDBFUE8v/YZOuKs+duMhxjPSXOh17UycHqe66oH\n+jByciEju7cK/S3RowR6hH9rjEWv4//hd9pr6MV1r692nBLxH5/nv71faA9+botbn+QabnsglbXL\n5nPubgdzg65UKYJTZ6eZe7YMOVTOZWdLDtwfSlGUs7knjGteI9ZNOnJjXc3zCoc741LUTOjxSk4s\nCeSfI6eh3uZIn6kl2BYaGZWXwck7AhBjG5jzaRIlYX1xz23k0PJgChbbMeHCaQqiXbBp7MI9rwmj\nRqJomDPemfUmHvxIBd51FTwvP8XUxmPUDrLGrraTb5WxzK44QPpUTxyL21FkidCqfAaVV9FibYlG\nZ0SNgeKIfsRWfgcKKIJAobcbLo1NuOU14VLSwqHYYXz07Sqern2FrMmuDM0/j0G24MDg0QTVFZm9\nE3OFsQCyYOo+Sve4YJRR6RQko4wkQ42nDeVqd0ITy9g/YzhRZ86jbTMFV/vUd5E50Z3Q45UIsoLl\nZT11df25of403y7xI/ToRbTadvbFxjDheDq7Vg/FqqkLp7JWbBq7zN9lvZs1Vpf1ps1qAu0JOlVF\nu70F3ml1aDqNKN2B9JN/CiT8YDn+31WjCAJnbxzIgQfCUOuNzEo+weuqR3h14t2o0ywIF9JRyaZ4\nk6CYvJqKwQ7Y13SY79+iVU/kvjKMkqlwDdlEX5252RsH63ouzrQk7EgFxeH96FPfxbA9JdQanOlX\n0YZGraOgJJzlB7bTPkNN/74tNC61pP+4ywyxLMfDpwFdmETkwVIG766i5s829Pu8jfYwNXqP397W\ntN/bQe1SG7PQ13uoaA9TY5Wpp32YxW+8uv8u1r95+Ud7Df0hqKHfevu4n6qMvLqA5pdkMIzbkEeq\nKoJXPn3LHAvos9kK3XveFLzNvwzC/dg1l6xMQDTKCArmatCYe3ay6oMtyEaRt5UHeYC3EFUyn60d\nRfj+MiL2lSJ3U015+0fyctyrqDBSHN4Pj7NNGEWJHeFTmFuw35w1NCi/moWaz2le2MmSDQdYpv/E\n1NLgu2p2PzwE+wSITcpAL4jIioQGPXJ3Ro+xu7o3TppGrOVJujQqnBouU2dpz+3SZraxgC1rh9Pn\ngJrIr0vxphhFFjks3sAMeT/QuxmdURJMzdkUxVxJ2eMldKJBi2kT+/vHvMCwO/aa6bMLQ/vh9101\nap2MTitx4L4QblyXhUon97Lo4XuKp4ciueGTXCSj6TdW6WeHa0Ezeo2IIgoYVSI541wZFldqotjC\n+uJxrtHsvfVQgeeHO/Phh+OY83wK4QfLObXQj2Gbypnd+Q33DX6ZObmHet1nzy9aFk1Fa4qAKUah\nBlTQOMuKpplWeC+tQzDCpVW2uLzXaraQrU934rW4HpVB4fwYT2yHNtL/7RbaseT434fj/ueiHzxj\nPVZ301RLmm6yBDBb3QBWmXpql/f5yef0f7j+uBY19Lv0CNZ98OLqW5ba/WYbQF+Nn9NP/Ze0uN2W\nvpSOIAX/SUnErXoIXbuWbZ89SP00gYjbDvzL9V3d5nfma+kAbHhrNGk3DiQsrpJFxi8ZnZKBIgpk\nTHPn/OR+tDfa4l9TTLWPLW0OFvh9V42ggHtuI7NPH0VtkNkyezLn5zsSur8Sg05NjaMDF+baMCSu\nkqM1UzmyYjAWfdqZ8mUG8zVbOfTgYBwr2zg9z4fJH5zDs6KKg4PG0L++kVo7e2wMrUjdGT0iphYN\npRH9aM4eQGh7Ppes++LU3oSXSx5H/zGI44zn9Q/fwOHeHMaeyeCCPIiRShIGtYoujZqDymT8FRM9\nISlQ5WeHbYPJQu+pNFYwNakrwRMb2sie50Jg1QUKhzvT0ldLl40a97xGJBkaB1hRHuyI75kaFElA\npZOJ/fw86VM8OHB/KB7ZDaRNH2jupCkoplgBQJ+GLgwaEYNG4uBfghFkhSFHKjCoRYwaia+fjDR3\n7zRKAmO3FHDyjgCC4i9hlATGb8tHEmTyJwTx9+RX+FqZzeDqCwiC3EsRfP9ggqCB9lEWaCoMKFoB\nQRSoetSOtpFa2iI0KBJY5Rq4+LSd2WLWlBuw3i3T5GGDR1Y1Nsk6FDUoGjjafzwDJxZhfboT+70d\nZou6x+ruDFCbFMJ0S5qmW2K/u53+b7dQu9Tm/4R38P87ruUR/C4VwWvvvbI6bI7Pb70MM35OP/Vf\n0uLWaFDh9wAM8C6m1Vci6cO5CKLC8sn/YOTZrH+rPe6VbX6Lw/vx9ZORZvrIQq/H/0w1jQOs+OIf\n0VT52rF8zX4SnnKn2seWm97IwCe5lv0PhOKfVI1DTQcoCpf692NqwSkmlpzihYZnyb65P9YJKqal\nnOYl+UncZmTRaG/LY5s+pz5QyxOtr3L+dnsu/NkKtU4m/GA58cPCmV1ykIaJCtOzvkUt6lF1b3t5\nyc8Ol+IWtH1aGVGcxWmnoTg1N3Ng8GimFCWQqw0gvmMcEf+vvXuPj6o6Fz7+ezK5X0gCAcJNQUQL\nKHJVATnSgogcxAultQqt0hppsAjSi35437621fdUe+hRXqW8UOGcA2qVIhUFuai1okGNcglBsAQI\ncktCIOSekEnW+WPviZNhJheSPQnO8/188mH2ZWY/s2aznr3XXnvt+94m5raTbM6bxg/+uYGCrsmE\nV9ex+vkbMeFCp7wqOp0vpahHLN2PlnH6snjiis/Xl00Y8CUDSKKUJyMeZ/q5DZy7KpIJKw+wNf0a\n8q5MZOgWa6SU6HI3Az/MY+P8IZwY1JnrN+RiwoS35w3h0Khu5A5LoX9mAXf+ficut3VsvmNGf7of\nLsHlNhhjqBobwTVvnqTrV6VU93Ph7uXi5DOJTFhwgN5XnbGe7LX+JMeXJ9Gr9BxVN7gYvuQYeQsS\n+PDGG7npqV1MunIzSSUlhLlrcZsIXNQ1uP4RBlQMCie8xBB5opbiyTFE/9PNkT93adBEUjoxhnN3\nxtZX0p4j+2MrEqmeGEbyhgrC3GBcUPCLeMa/8inGZej9m+IGlXvFyChq+oTXN7v0nXsWd+cwOq+v\n1Lb4DiRQInB8GOpQ4X0BeMeM/m3aZe6yUfuITD9C+uI3iVuVQHh0Nd/mXRb8/9eaPYyu98XmngeL\n/c6PKXPXfxdPv+vY0hrc4WFE1NQxbNNXhNdYbdFhwNFxiVw3Yys/+3Q1xfdWEb7oMC/e/6/cXfUG\nj/N7oqvPk/7HN9l9U19SBx9m9EPreOuX8/kqczBDN3/Fvn79eP+zaUx95llintxPzrWpUCtW7x2X\n0ONgMTuTBjHwg1NsvXkkt7jfZ+mjtzPp2IdkJV/NwNcLSb3mED/MXkf/zAK+dVsGR0ak0LPgLAcm\ndaNP9lkS+hbQ99xJPp7en6jKWr4amEzXr8qAr88Iagnjag7yxWV9+d9RT7L/y+HcvngP7862mvXu\nX/ARdeFh7J58GRE1dbgjwpj6pywmrPyCughwRdRxS3w2s5IzWPDXzaTN+wfub4VRPiyCuhgYveEQ\nhT+Po3hiFK46QISiqTFUDIog+lAt526PoXxMNPnp8aQuLqUmNZwjK60Ku2JIBN2XlpG3MAGpFY4c\n7k9sRBm99hVQMSySsu9EE+5y4w4Ppy7a+mEEqI2A2Gw3eY8kcPqBeDqvr6T4tmhisy4c8M5bbFZN\nfcWd9GYlJko4e3cMCKQ+V0rJ+ChSF5c2WrmXj4mmcGYcqUtKKZwZp0ngEqBnBG3E6Wec5py/ijWb\n5/FKzUyuGvI5TxT9X77Hq5yaHE1ir9NNxubv0Xu1LrngyVPeDxXxnEG895OBRFS4uWx/UYPRLVP2\nV/O3vffSbfYe9qydhLjqyPzPadQMrYL8KB764mXenno9KYn5DN94lDG7spEHTxCeGcsPN22ke/45\ndvzsMmJuO0n/zAImr9lNpLuW58fdy65FXRiy7RhXFJ5kRcSPeWrofMakr+V0SjJrtszjuusyGFq4\nn0wzisixhdy/4COGbzpKpzPV7JnUhxEbj3JgbCout6GwTzxj/nqIvRN6c8Wu01RHu4g4byW0mrBw\nqk0UhcmduTo/l+M3dOfbRzLIvGYoN2/fy6ATJ4kuqOH0/DiufL2Qggfjid9dTdh5CKsFEynkPZpA\n798UY1yG1MWl5C1M4PgfulB0TzzlwyNJ2lRJWKUhbq+bvIUJJL9ZSdnoKDptryZvYQLdl5YRVl5H\ntxfLyV3ehTMPJNQfaXuOsHv/ppjKgRHc/OqnSDgUzEkg8b0qiu6OIX7neSTCcP6ycCJO10GYJzaI\n/7iauKwazk2NIXl9JaU3R1ExIvAFUs+RfVxGFalLSsld1oXCBztRPiKSzq9XEru3hoL0BIq+Hx/w\nM+Iyquj5+5IOd9FYadOQo4LxjNNPXryTnUfHMuCaXczeuY43J40h55HoC5705E+g6xIj3jrKhl8M\n83u9wuWuq09sN718kKSCSqizLrKeGpDIcz+8h+s/srZbmFZDUp88/rF4JmEuwyPf/V/M27WKP4Yt\n4Adf/Y19E3twxa5Cwtx1jMvM4tYDHxJxvo6Nj17LwVmJ9THGFZ/nH7OuIusxq9yOXpdC7Llqused\n4t+zfkNMUgnbn7uPaxevp/Anbo5fm8SCFa/RP7WATp9XEV5ZR+m/RnH5h2fJW5jAsBXHCX/ITbea\nMtxdw+j/RiEl06KJP1wDdXDsulQ2nLmDYeG76SRlHPyXy+nzfgFHb+rB4H3/pGRiNElbqzg3NYYu\na60mjqLvxxP7eTVRR2opujuGqFw38Z+cp2RCNCn/XcGRlV0ovvPr37ymTzhSaejy10oKHozn9MOJ\nhJXXkbqk1O+0vwq2pk94/TqECUde7ELR9+OpGBJBn8fOkbcggdpOYXTafp7qPmG4ig2Vg8NxFdcR\nVglVA8KtswM76TSnYvbtaRN5zE3SpkrKR0WS+F51wM/w7qrpibHv3LOaDDqIb1SvodTBnc3Ml29p\n7zDqtaTX0MXwjNfyq9mPsHDlK2weeyM3b8xm6aO3UzqroukPaCHvxAZW00hERQ2uOisJ9DhYzPpr\nJ5CQdA6AO7LfI2XAUfL2DuDJK+fzSM6fWblkXIMHkrw7+1vcZo8tBNbdtX958oYG223sRqKce4fy\n/EePctW8PaQvtMZQjMuoovvzJSR8dJ7SsVHUdLPapD13jsZlVFldBO3KqHBmHF1XlFE2OpLTDybw\nfNZ8bnFtY/JzH1B5ZTgxB9xkTr+Wa9blUDkdUl6qoOjOGBI3V5G3MIHCBzvVV3T56fFIrVAxJIIr\nHigkrAq/d6z63siUnx5P96VlAaf9Nbl4PqNyYDixWTUcWf51O39cRhVdV5TS6b1qKq61KvzC+2JJ\n3lRF1eUuYvfUEFbHBWXSkh48vv3wfae9dV1WSsWQiAbzL2abyhnfqDuLO1oicNqnq6YxIfwdFq58\npf4idMLqWB5Zuo5Xloxo8nqE793HYCWXvGzrrMp32dDfFZFpRhHx6xzGrzpA8slyxqw9xBfjerDq\n/43jrroiRFMAABBzSURBVKc+Z8zaQ2TMsAY4+9XYx1j61hOkT32CJe/+tr7S9IjLqCJpQwWdX6uw\nmixcUBcrHFluPXaiqUoiM2M0G9Lu5aWamdwXsYZpy19mPH+nX5rVY+z0A/F0XVVW/9q7Qm1OJRaX\nUUW/2WconhxNp39U11fO3pW95z2exNLgvWlnqBgSScz+mgs+13tbKStK6PlUCScXdaLwwU4XTAeK\nrbH4PbGfnR5D53WVnJ0eQ/KmKoqmRNPltQqMCyqGRxKz333RF221cv/m0ETQwTV1VtGasw7fESC9\npwG/y5Ys/QmjxljPXe53fyGlYyMbVO4pK6wj8e1jb+CGp7L5eNQIbsz8nE8WXXNBP3OrsiokrNJq\ntzYur4Xh0uAI11dmxmh+OfdPPPPCTxnP3+mVVsLzNT9jXtgSwl3u+mTiSQqe6UAVtyce30rMexya\nuriwZr2nqUratwLtuqwU4zJIrXB6TsIF0/6201Ql7L3cs/2Sm6NI2mhd6PWUbWNH8Sp0aCLo4Jwa\nKtfT3OKpUGfMXM3aNbN45oWf1lf0jS1rjOd974wfx/DX97Pz7oFMfH/7Be/v9XgRndeVc+oXnagc\nHEm/tDNItQEDZ2fEceLfkgNuY9WyORzPvZzJ0zYwasyO+gp7T/dBbJ9wI+P+bWt9ZQhfn1205Ij1\nYseh6YhHyp7yKR0bRf7DCR0qNtX+NBFcAqb/9jOGbj12wQijdxze1Sb/eZcuXsjyJfNJm/dsfTu7\nv2X/J+6JZlVwq5bN4RbXNm5dur2+Et2SPo5ttbfwwJxl9ev5VpjeldXhl7s2Gbcn4axOn86tS7eT\nNf5qLltf4PfsoyU8R+Seu2pjs2qIOFZD53WV9d03L6XKUwdWU03RQec6gKZGVYybUUXUppr6Qbtu\nic9ucJt+a2RmjGbtmlmkzXuWtWtmMWp0RoMzAu9l09L/xq1zt/tt8vD28JBnLxjM69a527n6hX2U\n83UF5NuckrKmnLx5CaSsKScuo6rJymrUmB2sTp/ODU9l89ydc3jq/d+yepGVFHIHX3xlVzEkgn6z\nz5C30Dpyjtl3npSXKii8L7a+v31blb/TdGA11RqOJAIR+QNwO3AeOAQ8YIw552e9XKAU63klbn+Z\nqqNx+gEWJkKow9BteRldV5U12n7eXN7t7KPG7GDU6Iz6aeCCZbPmrrOOvudub/To0vvmI7BuJPIc\nWfuL2V9l5amIfS8u+x6FD6vdzX/deR8/X/8CafOepfeDh8gdHHhbzVE+JpojK7vQd+5ZXCWGlDXl\nnFzUye7F47qkKtKW/hZKeXOkaUhEJgHv2U8oexrAGPMrP+vlAiONMYUt+fy2aBrqaE8k8q4k43dU\nk7qklLpo4fCq1ieCVcvmcM2QPQ3a7TMzRpOddR1AwGWPlT/dpg/y8NemnrKihNTFpQ2aYvxVwBd7\nHaM5fB9Yog8wUd9U7XaNQETuAr5rjLnPz7JcWpEIOlpl3hreFzzr+7yvKqNoagwnfh/8polgtjc3\ntS3fMxrf6bbcdnP69St1qQqUCIIx1tBs4O0AywywVUQ+F5G05n5gF1fZNyoJwNft6J6j4fyFiRxZ\n3oWkLVXEZVQFNZa4jCpSZ1ewJX0c+QsTyX2hM33nnuX4iv6sWjanzbfX1Ng02VnXNaj0R43ZwTMv\n/LT+jOZieZ995C9MJD89np5PlZCfHt/gewe7/JUKtos+IxCRd4BUP4sWGWPesNdZBIwE7jZ+NiQi\nvYwxJ0SkG7AN+Jkx5oMA20sD0gB69HKNeDujx0XF3ZEFoztic7bRdVkpu1xDmbV0XX0FfHxFfz5d\nfDN9Vu5vsyYZ7+0H6+zD+/v7djsFmuzXr9SlLOhNQyJyP/AQMMEY0+Q4CCLyBFBmjPn3ptYdPCTS\nvPxW91bHGIpaMlyAk+3yFxPPpbg9pTqSoDYNichk4JfAtEBJQETiRCTB8xqYBGQ7EY/6mqc3Sd+5\nZ+m+uLjRSnDUmB3MmLma5UvmM2Pm6jZPAtB4bxcntOT7KxUqnLpG8DyQAGwTkd0isgxARHqKyCZ7\nne7AhyKyB/gU2GiMafpxW6rVmjtevO/9BZkZo9s8ltNzEi7YfvmYaEebYnS8fKUacuQ+AmPMlQHm\nnwSm2K8PA6272qcuiu9NXWWjowI2C/m798CJM4Ngas73VyqU6BPKQoxvT5lAPWOc6qnT3pr7/ZUK\nJZfkWEN6sfjidcSB0oIp1L+/Cm3fqEHnNBEopVTLtecNZUoppTowTQRKKRXiNBEopVSI00SglFIh\nThOBUkqFOE0ESikV4jQRKKVUiNNEoJRSIU4TgVJKhThNBEopFeI0ESilVIjTRKCUUiFOE4FSSoU4\nxxKBiDwhIifsJ5TtFpEpAdabLCJfikiOiDzmVDxKKaX8c+QJZV7+o7GH0YuIC3gBuAU4DmSKyAZj\nzBcOx6WUUsrW3k1D1wM5xpjDxpjzwF+AO9o5JqWUCilOJ4KHRSRLRFaKSLKf5b2AY17Tx+15FxCR\nNBH5TEQ+Kzpb50SsSikVklqVCETkHRHJ9vN3B/AnoD8wFDgFLG7Ntowxy40xI40xI5M7t/eJjFJK\nfXO06hqBMWZic9YTkRXAW34WnQD6eE33tucppZQKEid7DfXwmrwLyPazWiYwQET6iUgkcA+wwamY\nlFJKXcjJXkPPiMhQwAC5wEMAItIT+LMxZooxxi0iDwNbABew0hizz8GYlFJK+XAsERhjZgWYfxKY\n4jW9CdjkVBxKKaUap1ddlVIqxGkiUEqpEKeJQCmlQpwmAqWUCnGaCJRSKsRpIlBKqRCniUAppUKc\nJgKllApxmgiUUirEaSJQSqkQp4lAKaVCnCYCpZQKcZoIlFIqxGkiUEqpEKeJQCmlQpwmAqWUCnGO\nPJhGRF4FrrYnk4BzxpihftbLBUqBWsBtjBnpRDxKKaUCcyQRGGO+73ktIouB4kZW/7YxptCJOJRS\nSjXNyWcWIyICfA/4jpPbUUopdfGcvkYwDsg3xhwMsNwAW0XkcxFJa+yDRCRNRD4Tkc+Kzta1eaBK\nKRWqLvqMQETeAVL9LFpkjHnDfv0D4JVGPuYmY8wJEekGbBORA8aYD/ytaIxZDiwHGDwk0lxs3Eop\npRq66ERgjJnY2HIRCQfuBkY08hkn7H8LRGQ9cD3gNxEopZRyhpNNQxOBA8aY4/4WikiciCR4XgOT\ngGwH41FKKeWHk4ngHnyahUSkp4hssie7Ax+KyB7gU2CjMWazg/EopZTyw7FeQ8aY+/3MOwlMsV8f\nBq5zavtKKaWaR+8sVkqpEKeJQCmlQpwmAqWUCnGaCJRSKsRpIlBKqRCniUAppUKcJgKllApxmgiU\nUirEaSJQSqkQp4lAKaVCnCYCpZQKcZoIlFIqxGkiUEqpEKeJQCmlQpwmAqWUCnGaCJRSKsS1KhGI\nyAwR2ScidSIy0mfZ4yKSIyJfisitAd7fT0Q+sdd7VUQiWxOPUkqplmvtGUE21gPqGzxwXkQGYT2q\ncjAwGVgqIi4/738a+A9jzJVAEfDjVsajlFKqhVqVCIwx+40xX/pZdAfwF2NMtTHmCJADXO+9gogI\n8B3gr/as/wLubE08SimlWs6pZxb3Aj72mj5uz/PWBThnjHE3sk49EUkD0uzJ6qGXH89uo1jbUgpQ\n2N5B+KFxtYzG1TIdNS7ouLG1V1yX+5vZZCIQkXeAVD+LFhlj3mhtVM1ljFkOLLdj+swYM7KJtwSd\nxtUyGlfLaFwt11Fj62hxNZkIjDETL+JzTwB9vKZ72/O8nQGSRCTcPivwt45SSimHOdV9dANwj4hE\niUg/YADwqfcKxhgD/B34rj3rR0DQzjCUUkpZWtt99C4ROQ6MBjaKyBYAY8w+4DXgC2AzMNcYU2u/\nZ5OI9LQ/4lfAoyKSg3XN4MVmbnp5a+J2kMbVMhpXy2hcLddRY+tQcYl1YK6UUipU6Z3FSikV4jQR\nKKVUiOuwieBSGL7C/tzd9l+uiOwOsF6uiOy11/usrePws70nROSEV2xTAqw32S7DHBF5LAhx/UFE\nDohIloisF5GkAOsFpbya+v52Z4dX7eWfiEhfp2Lx2mYfEfm7iHxh7/+P+FlnvIgUe/2+v3Y6Lnu7\njf4uYllil1eWiAwPQkxXe5XDbhEpEZH5PusErbxEZKWIFIhItte8ziKyTUQO2v8mB3jvj+x1DorI\nj5yK0S9jTIf8AwYCVwPvAyO95g8C9gBRQD/gEODy8/7XgHvs18uAnzoc72Lg1wGW5QIpQSy7J4Cf\nN7GOyy67K4BIu0wHORzXJCDcfv008HR7lVdzvj+QDiyzX98DvBqE364HMNx+nQD8009c44G3grU/\nNfd3AaYAbwMC3Ah8EuT4XEAecHl7lRfwL8BwINtr3jPAY/brx/zt90Bn4LD9b7L9OjlYZddhzwjM\nJTR8hb297wGvOLUNB1wP5BhjDhtjzgN/wSpbxxhjtpqv7yT/GOvekfbSnO9/B9a+A9a+NMH+rR1j\njDlljNlpvy4F9tPIHfcdzB3AfxvLx1j3CfUI4vYnAIeMMUeDuM0GjDEfAGd9ZnvvR4HqoluBbcaY\ns8aYImAb1jhtQdFhE0EjegHHvKZbPXxFGxgH5BtjDgZYboCtIvK5PVRGMDxsn56vDHAq2pxydNJs\nrKNHf4JRXs35/vXr2PtSMda+FRR2U9Qw4BM/i0eLyB4ReVtEBgcppKZ+l/bep+4h8MFYe5SXR3dj\nzCn7dR7Q3c867Vp2To011CzSQYavaEwzY/wBjZ8N3GSMOSEi3YBtInLAPnJwJC7gT8DvsP7j/g6r\n2Wp2a7bXFnF5yktEFgFu4KUAH9Pm5XWpEZF4YB0w3xhT4rN4J1bzR5l9/edvWDdtOq3D/i72NcBp\nwON+FrdXeV3AGGNEpMP12W/XRGAugeErmopRRMKxhuIe0chnnLD/LRCR9VjNEq36D9TcshORFcBb\nfhY1pxzbPC4RuR+YCkwwduOon89o8/Lyoznf37POcft3TsTatxwlIhFYSeAlY8zrvsu9E4MxZpOI\nLBWRFGOMo4OYNeN3cWSfaqbbgJ3GmHzfBe1VXl7yRaSHMeaU3VRW4GedE1jXMjx6Y10fDYpLsWmo\now1fMRE4YIw57m+hiMSJSILnNdYFU0dHTvVpl70rwPYygQFi9a6KxDqt3uBwXJOBXwLTjDEVAdYJ\nVnk15/tvwNp3wNqX3guUvNqKfQ3iRWC/MeaPAdZJ9VyrEJHrsf4fO5qgmvm7bAB+aPceuhEo9moS\ncVrAs/L2KC8f3vtRoLpoCzBJRJLtptxJ9rzgCNZV6Zb+YVVgx4FqIB/Y4rVsEVaPjy+B27zmbwJ6\n2q+vwEoQOcBaIMqhOP8TmOMzryewySuOPfbfPqwmEqfLbjWwF8jC2gl7+MZlT0/B6pVyKEhx5WC1\ng+62/5b5xhXM8vL3/YHfYiUqgGh738mx96UrglBGN2E16WV5ldMUYI5nPwMetstmD9ZF9zFBiMvv\n7+ITlwAv2OW5F6/efg7HFodVsSd6zWuX8sJKRqeAGrv++jHWdaV3gYPAO0Bne92RwJ+93jvb3tdy\ngAeCUXaePx1iQimlQtyl2DSklFKqDWkiUEqpEKeJQCmlQpwmAqWUCnGaCJRSKsRpIlBKqRCniUAp\npULc/wBrj1cCCZVmlQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "means 0.896 0.0972 0.4966\n",
            "(5000, 2) (5000,)\n",
            "Epoch 0/11\n",
            "----------\n",
            "epoch at 1000 0\n",
            "epoch at 1000 1\n",
            "epoch at 1000 2\n",
            "epoch at 1000 3\n",
            "epoch at 1000 4\n",
            "epoch at 1000 5\n",
            "epoch at 1000 6\n",
            "epoch at 1000 7\n",
            "epoch at 1000 8\n",
            "epoch at 1000 9\n",
            "epoch at 1000 10\n",
            "epoch at 1000 11\n",
            "epoch at 1000 12\n",
            "epoch at 1000 13\n",
            "epoch at 1000 14\n",
            "epoch at 1000 15\n",
            "epoch at 1000 16\n",
            "epoch at 1000 17\n",
            "epoch at 1000 18\n",
            "epoch at 1000 19\n",
            "epoch at 1000 20\n",
            "epoch at 1000 21\n",
            "epoch at 1000 22\n",
            "epoch at 1000 23\n",
            "epoch at 1000 24\n",
            "epoch at 1000 25\n",
            "epoch at 1000 26\n",
            "epoch at 1000 27\n",
            "epoch at 1000 28\n",
            "epoch at 1000 29\n",
            "epoch at 1000 30\n",
            "epoch at 1000 31\n",
            " perfmeasure 0.518\n",
            "current best 0.518  at epoch  0\n",
            "Epoch 1/11\n",
            "----------\n",
            "epoch at 1000 0\n",
            "epoch at 1000 1\n",
            "epoch at 1000 2\n",
            "epoch at 1000 3\n",
            "epoch at 1000 4\n",
            "epoch at 1000 5\n",
            "epoch at 1000 6\n",
            "epoch at 1000 7\n",
            "epoch at 1000 8\n",
            "epoch at 1000 9\n",
            "epoch at 1000 10\n",
            "epoch at 1000 11\n",
            "epoch at 1000 12\n",
            "epoch at 1000 13\n",
            "epoch at 1000 14\n",
            "epoch at 1000 15\n",
            "epoch at 1000 16\n",
            "epoch at 1000 17\n",
            "epoch at 1000 18\n",
            "epoch at 1000 19\n",
            "epoch at 1000 20\n",
            "epoch at 1000 21\n",
            "epoch at 1000 22\n",
            "epoch at 1000 23\n",
            "epoch at 1000 24\n",
            "epoch at 1000 25\n",
            "epoch at 1000 26\n",
            "epoch at 1000 27\n",
            "epoch at 1000 28\n",
            "epoch at 1000 29\n",
            "epoch at 1000 30\n",
            "epoch at 1000 31\n",
            " perfmeasure 0.649\n",
            "current best 0.649  at epoch  1\n",
            "Epoch 2/11\n",
            "----------\n",
            "epoch at 1000 0\n",
            "epoch at 1000 1\n",
            "epoch at 1000 2\n",
            "epoch at 1000 3\n",
            "epoch at 1000 4\n",
            "epoch at 1000 5\n",
            "epoch at 1000 6\n",
            "epoch at 1000 7\n",
            "epoch at 1000 8\n",
            "epoch at 1000 9\n",
            "epoch at 1000 10\n",
            "epoch at 1000 11\n",
            "epoch at 1000 12\n",
            "epoch at 1000 13\n",
            "epoch at 1000 14\n",
            "epoch at 1000 15\n",
            "epoch at 1000 16\n",
            "epoch at 1000 17\n",
            "epoch at 1000 18\n",
            "epoch at 1000 19\n",
            "epoch at 1000 20\n",
            "epoch at 1000 21\n",
            "epoch at 1000 22\n",
            "epoch at 1000 23\n",
            "epoch at 1000 24\n",
            "epoch at 1000 25\n",
            "epoch at 1000 26\n",
            "epoch at 1000 27\n",
            "epoch at 1000 28\n",
            "epoch at 1000 29\n",
            "epoch at 1000 30\n",
            "epoch at 1000 31\n",
            " perfmeasure 0.701\n",
            "current best 0.701  at epoch  2\n",
            "Epoch 3/11\n",
            "----------\n",
            "epoch at 1000 0\n",
            "epoch at 1000 1\n",
            "epoch at 1000 2\n",
            "epoch at 1000 3\n",
            "epoch at 1000 4\n",
            "epoch at 1000 5\n",
            "epoch at 1000 6\n",
            "epoch at 1000 7\n",
            "epoch at 1000 8\n",
            "epoch at 1000 9\n",
            "epoch at 1000 10\n",
            "epoch at 1000 11\n",
            "epoch at 1000 12\n",
            "epoch at 1000 13\n",
            "epoch at 1000 14\n",
            "epoch at 1000 15\n",
            "epoch at 1000 16\n",
            "epoch at 1000 17\n",
            "epoch at 1000 18\n",
            "epoch at 1000 19\n",
            "epoch at 1000 20\n",
            "epoch at 1000 21\n",
            "epoch at 1000 22\n",
            "epoch at 1000 23\n",
            "epoch at 1000 24\n",
            "epoch at 1000 25\n",
            "epoch at 1000 26\n",
            "epoch at 1000 27\n",
            "epoch at 1000 28\n",
            "epoch at 1000 29\n",
            "epoch at 1000 30\n",
            "epoch at 1000 31\n",
            " perfmeasure 0.71\n",
            "current best 0.71  at epoch  3\n",
            "Epoch 4/11\n",
            "----------\n",
            "epoch at 1000 0\n",
            "epoch at 1000 1\n",
            "epoch at 1000 2\n",
            "epoch at 1000 3\n",
            "epoch at 1000 4\n",
            "epoch at 1000 5\n",
            "epoch at 1000 6\n",
            "epoch at 1000 7\n",
            "epoch at 1000 8\n",
            "epoch at 1000 9\n",
            "epoch at 1000 10\n",
            "epoch at 1000 11\n",
            "epoch at 1000 12\n",
            "epoch at 1000 13\n",
            "epoch at 1000 14\n",
            "epoch at 1000 15\n",
            "epoch at 1000 16\n",
            "epoch at 1000 17\n",
            "epoch at 1000 18\n",
            "epoch at 1000 19\n",
            "epoch at 1000 20\n",
            "epoch at 1000 21\n",
            "epoch at 1000 22\n",
            "epoch at 1000 23\n",
            "epoch at 1000 24\n",
            "epoch at 1000 25\n",
            "epoch at 1000 26\n",
            "epoch at 1000 27\n",
            "epoch at 1000 28\n",
            "epoch at 1000 29\n",
            "epoch at 1000 30\n",
            "epoch at 1000 31\n",
            " perfmeasure 0.724\n",
            "current best 0.724  at epoch  4\n",
            "Epoch 5/11\n",
            "----------\n",
            "epoch at 1000 0\n",
            "epoch at 1000 1\n",
            "epoch at 1000 2\n",
            "epoch at 1000 3\n",
            "epoch at 1000 4\n",
            "epoch at 1000 5\n",
            "epoch at 1000 6\n",
            "epoch at 1000 7\n",
            "epoch at 1000 8\n",
            "epoch at 1000 9\n",
            "epoch at 1000 10\n",
            "epoch at 1000 11\n",
            "epoch at 1000 12\n",
            "epoch at 1000 13\n",
            "epoch at 1000 14\n",
            "epoch at 1000 15\n",
            "epoch at 1000 16\n",
            "epoch at 1000 17\n",
            "epoch at 1000 18\n",
            "epoch at 1000 19\n",
            "epoch at 1000 20\n",
            "epoch at 1000 21\n",
            "epoch at 1000 22\n",
            "epoch at 1000 23\n",
            "epoch at 1000 24\n",
            "epoch at 1000 25\n",
            "epoch at 1000 26\n",
            "epoch at 1000 27\n",
            "epoch at 1000 28\n",
            "epoch at 1000 29\n",
            "epoch at 1000 30\n",
            "epoch at 1000 31\n",
            " perfmeasure 0.724\n",
            "Epoch 6/11\n",
            "----------\n",
            "epoch at 1000 0\n",
            "epoch at 1000 1\n",
            "epoch at 1000 2\n",
            "epoch at 1000 3\n",
            "epoch at 1000 4\n",
            "epoch at 1000 5\n",
            "epoch at 1000 6\n",
            "epoch at 1000 7\n",
            "epoch at 1000 8\n",
            "epoch at 1000 9\n",
            "epoch at 1000 10\n",
            "epoch at 1000 11\n",
            "epoch at 1000 12\n",
            "epoch at 1000 13\n",
            "epoch at 1000 14\n",
            "epoch at 1000 15\n",
            "epoch at 1000 16\n",
            "epoch at 1000 17\n",
            "epoch at 1000 18\n",
            "epoch at 1000 19\n",
            "epoch at 1000 20\n",
            "epoch at 1000 21\n",
            "epoch at 1000 22\n",
            "epoch at 1000 23\n",
            "epoch at 1000 24\n",
            "epoch at 1000 25\n",
            "epoch at 1000 26\n",
            "epoch at 1000 27\n",
            "epoch at 1000 28\n",
            "epoch at 1000 29\n",
            "epoch at 1000 30\n",
            "epoch at 1000 31\n",
            " perfmeasure 0.725\n",
            "current best 0.725  at epoch  6\n",
            "Epoch 7/11\n",
            "----------\n",
            "epoch at 1000 0\n",
            "epoch at 1000 1\n",
            "epoch at 1000 2\n",
            "epoch at 1000 3\n",
            "epoch at 1000 4\n",
            "epoch at 1000 5\n",
            "epoch at 1000 6\n",
            "epoch at 1000 7\n",
            "epoch at 1000 8\n",
            "epoch at 1000 9\n",
            "epoch at 1000 10\n",
            "epoch at 1000 11\n",
            "epoch at 1000 12\n",
            "epoch at 1000 13\n",
            "epoch at 1000 14\n",
            "epoch at 1000 15\n",
            "epoch at 1000 16\n",
            "epoch at 1000 17\n",
            "epoch at 1000 18\n",
            "epoch at 1000 19\n",
            "epoch at 1000 20\n",
            "epoch at 1000 21\n",
            "epoch at 1000 22\n",
            "epoch at 1000 23\n",
            "epoch at 1000 24\n",
            "epoch at 1000 25\n",
            "epoch at 1000 26\n",
            "epoch at 1000 27\n",
            "epoch at 1000 28\n",
            "epoch at 1000 29\n",
            "epoch at 1000 30\n",
            "epoch at 1000 31\n",
            " perfmeasure 0.726\n",
            "current best 0.726  at epoch  7\n",
            "Epoch 8/11\n",
            "----------\n",
            "epoch at 1000 0\n",
            "epoch at 1000 1\n",
            "epoch at 1000 2\n",
            "epoch at 1000 3\n",
            "epoch at 1000 4\n",
            "epoch at 1000 5\n",
            "epoch at 1000 6\n",
            "epoch at 1000 7\n",
            "epoch at 1000 8\n",
            "epoch at 1000 9\n",
            "epoch at 1000 10\n",
            "epoch at 1000 11\n",
            "epoch at 1000 12\n",
            "epoch at 1000 13\n",
            "epoch at 1000 14\n",
            "epoch at 1000 15\n",
            "epoch at 1000 16\n",
            "epoch at 1000 17\n",
            "epoch at 1000 18\n",
            "epoch at 1000 19\n",
            "epoch at 1000 20\n",
            "epoch at 1000 21\n",
            "epoch at 1000 22\n",
            "epoch at 1000 23\n",
            "epoch at 1000 24\n",
            "epoch at 1000 25\n",
            "epoch at 1000 26\n",
            "epoch at 1000 27\n",
            "epoch at 1000 28\n",
            "epoch at 1000 29\n",
            "epoch at 1000 30\n",
            "epoch at 1000 31\n",
            " perfmeasure 0.726\n",
            "Epoch 9/11\n",
            "----------\n",
            "epoch at 1000 0\n",
            "epoch at 1000 1\n",
            "epoch at 1000 2\n",
            "epoch at 1000 3\n",
            "epoch at 1000 4\n",
            "epoch at 1000 5\n",
            "epoch at 1000 6\n",
            "epoch at 1000 7\n",
            "epoch at 1000 8\n",
            "epoch at 1000 9\n",
            "epoch at 1000 10\n",
            "epoch at 1000 11\n",
            "epoch at 1000 12\n",
            "epoch at 1000 13\n",
            "epoch at 1000 14\n",
            "epoch at 1000 15\n",
            "epoch at 1000 16\n",
            "epoch at 1000 17\n",
            "epoch at 1000 18\n",
            "epoch at 1000 19\n",
            "epoch at 1000 20\n",
            "epoch at 1000 21\n",
            "epoch at 1000 22\n",
            "epoch at 1000 23\n",
            "epoch at 1000 24\n",
            "epoch at 1000 25\n",
            "epoch at 1000 26\n",
            "epoch at 1000 27\n",
            "epoch at 1000 28\n",
            "epoch at 1000 29\n",
            "epoch at 1000 30\n",
            "epoch at 1000 31\n",
            " perfmeasure 0.726\n",
            "Epoch 10/11\n",
            "----------\n",
            "epoch at 1000 0\n",
            "epoch at 1000 1\n",
            "epoch at 1000 2\n",
            "epoch at 1000 3\n",
            "epoch at 1000 4\n",
            "epoch at 1000 5\n",
            "epoch at 1000 6\n",
            "epoch at 1000 7\n",
            "epoch at 1000 8\n",
            "epoch at 1000 9\n",
            "epoch at 1000 10\n",
            "epoch at 1000 11\n",
            "epoch at 1000 12\n",
            "epoch at 1000 13\n",
            "epoch at 1000 14\n",
            "epoch at 1000 15\n",
            "epoch at 1000 16\n",
            "epoch at 1000 17\n",
            "epoch at 1000 18\n",
            "epoch at 1000 19\n",
            "epoch at 1000 20\n",
            "epoch at 1000 21\n",
            "epoch at 1000 22\n",
            "epoch at 1000 23\n",
            "epoch at 1000 24\n",
            "epoch at 1000 25\n",
            "epoch at 1000 26\n",
            "epoch at 1000 27\n",
            "epoch at 1000 28\n",
            "epoch at 1000 29\n",
            "epoch at 1000 30\n",
            "epoch at 1000 31\n",
            " perfmeasure 0.727\n",
            "current best 0.727  at epoch  10\n",
            "Epoch 11/11\n",
            "----------\n",
            "epoch at 1000 0\n",
            "epoch at 1000 1\n",
            "epoch at 1000 2\n",
            "epoch at 1000 3\n",
            "epoch at 1000 4\n",
            "epoch at 1000 5\n",
            "epoch at 1000 6\n",
            "epoch at 1000 7\n",
            "epoch at 1000 8\n",
            "epoch at 1000 9\n",
            "epoch at 1000 10\n",
            "epoch at 1000 11\n",
            "epoch at 1000 12\n",
            "epoch at 1000 13\n",
            "epoch at 1000 14\n",
            "epoch at 1000 15\n",
            "epoch at 1000 16\n",
            "epoch at 1000 17\n",
            "epoch at 1000 18\n",
            "epoch at 1000 19\n",
            "epoch at 1000 20\n",
            "epoch at 1000 21\n",
            "epoch at 1000 22\n",
            "epoch at 1000 23\n",
            "epoch at 1000 24\n",
            "epoch at 1000 25\n",
            "epoch at 1000 26\n",
            "epoch at 1000 27\n",
            "epoch at 1000 28\n",
            "epoch at 1000 29\n",
            "epoch at 1000 30\n",
            "epoch at 1000 31\n",
            " perfmeasure 0.728\n",
            "current best 0.728  at epoch  11\n",
            "epoch at 1000 0\n",
            "epoch at 1000 1\n",
            "epoch at 1000 2\n",
            "epoch at 1000 3\n",
            "epoch at 1000 4\n",
            "epoch at 1000 5\n",
            "epoch at 1000 6\n",
            "epoch at 1000 7\n",
            "epoch at 1000 8\n",
            "epoch at 1000 9\n",
            "epoch at 1000 10\n",
            "epoch at 1000 11\n",
            "epoch at 1000 12\n",
            "epoch at 1000 13\n",
            "epoch at 1000 14\n",
            "epoch at 1000 15\n",
            "epoch at 1000 16\n",
            "epoch at 1000 17\n",
            "epoch at 1000 18\n",
            "epoch at 1000 19\n",
            "epoch at 1000 20\n",
            "epoch at 1000 21\n",
            "epoch at 1000 22\n",
            "epoch at 1000 23\n",
            "epoch at 1000 24\n",
            "epoch at 1000 25\n",
            "epoch at 1000 26\n",
            "epoch at 1000 27\n",
            "epoch at 1000 28\n",
            "epoch at 1000 29\n",
            "epoch at 1000 30\n",
            "epoch at 1000 31\n",
            "validation accuracy 0.728 test accuracy 0.791\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD4CAYAAADhNOGaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\np4lAKaWCnCYCpZQKcv8HMLjOc+FL3/IAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6bBWWkCkjdw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8ukvGklRcv0",
        "colab_type": "text"
      },
      "source": [
        "# Part 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7o9GTqZRbhc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torchvision.transforms as transforms\n",
        "import pandas"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMDKhy0mSfH3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_sampler():\n",
        "    #change path to download here\n",
        "    path = \"../data\"\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        torchvision.datasets.FashionMNIST(path, train=True, download=True,\n",
        "                       transform=transforms.Compose([\n",
        "                           transforms.ToTensor(),\n",
        "                           transforms.Normalize((0.1307,), (0.3081,))\n",
        "                       ])),\n",
        "        batch_size=300, shuffle=True)\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        torchvision.datasets.FashionMNIST(path, train=False, transform=transforms.Compose([\n",
        "                           transforms.ToTensor(),\n",
        "                           transforms.Normalize((0.1307,), (0.3081,))\n",
        "                       ])),\n",
        "        batch_size=4, shuffle=False)\n",
        "    val_sample = torch.utils.data.SubsetRandomSampler(range(10000))\n",
        "    val_loader = torch.utils.data.DataLoader(\n",
        "        torchvision.datasets.FashionMNIST(path, train=True, download=True,\n",
        "                       transform=transforms.Compose([\n",
        "                           transforms.ToTensor(),\n",
        "                           transforms.Normalize((0.1307,), (0.3081,))\n",
        "                       ])),\n",
        "        batch_size=4, shuffle=False, sampler=val_sample)\n",
        "    # print(next(iter(val_loader)))\n",
        "    return train_loader, val_loader, test_loader\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shehjJxNXxoX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(model, self).__init__()\n",
        "        # images are 28x28 px\n",
        "        self.fc1 = nn.Linear(28*28, 300)\n",
        "        self.fc2 = nn.Linear(300, 100)\n",
        "        self.fc3 = nn.Linear(100,10)\n",
        "    \n",
        "    def forward(self,x):\n",
        "        x = x.view(-1,28*28)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ozHmtTWlG7M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_epoch(model, device, criterion, epoch, train_loader, optimizer):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        print(output)\n",
        "        print(target)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # if batch_idx % 10 == 0:\n",
        "        #     print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "        #         epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "        #         100. * batch_idx / len(train_loader), loss.item()))\n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCXWxTcqoaMj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, device, optimizer,num_epochs, train_loader, val_loader, test_loader, criterion): \n",
        "  best_measure = 0\n",
        "  best_epoch =-1\n",
        "  metrics = {}\n",
        "  interm_metrics = {}\n",
        "  for epoch in range(num_epochs):\n",
        "    print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "    print('-' * 10)\n",
        " \n",
        "    model.train(True)\n",
        "    losses = train_epoch(model, device, criterion, epoch, train_loader, optimizer)\n",
        "    model.train(False)\n",
        "    acc_val, b_loss_val   = validate(model, device, val_loader, criterion)\n",
        "    measure, b_loss_test = validate(model, device, test_loader, criterion)\n",
        "    acc_train, b_loss_train = validate(model, device, train_loader, criterion)\n",
        "    interm_metrics = {\"acc_train\":acc_train,\"acc_val\":acc_val,\"acc_test\":measure,\"val_loss\":b_loss_val,\"test_loss\":b_loss_test,\"train_loss\":b_loss_train}\n",
        "    metrics[epoch] = interm_metrics\n",
        "    print(' perfmeasure', measure)\n",
        " \n",
        "    if measure > best_measure:\n",
        "      bestweights= model.state_dict()\n",
        "      best_measure = measure\n",
        "      best_epoch = epoch\n",
        "      print('current best', measure, ' at epoch ', best_epoch)\n",
        "    break\n",
        "#   print(metrics)\n",
        " \n",
        "  return best_epoch, best_measure, bestweights, metrics\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDJhGOnOtEFL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validate(model, device, val_loader, criterion):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    cumul_loss = {}\n",
        "    with torch.no_grad():\n",
        "        for i_batch, (data,target) in enumerate(val_loader):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            cumul_loss[i_batch] = loss.item()\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            total += data.size(0)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "    return correct/total, np.round(np.array(list(cumul_loss.values())).mean(),3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_urI0v_3vkdm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run():\n",
        "    trainloader, valloader, testloader = data_sampler()\n",
        "    device=torch.device('cpu')\n",
        "    nn_model = model().to(device)\n",
        "    optimizer = optim.SGD(nn_model.parameters(), lr=0.01)\n",
        "    num_epochs = 8\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    _,best_measure, bestweights, metrics = train_model(nn_model,device, optimizer, num_epochs,trainloader, valloader, testloader, criterion)\n",
        "    # print(metrics)\n",
        "    nn_model.load_state_dict(bestweights)\n",
        "    test_accuracy, _ = validate(nn_model, device, testloader,criterion)\n",
        "    print('validation accuracy',best_measure, 'test accuracy',test_accuracy)\n",
        "    listed = list(metrics.values())\n",
        "    df = pandas.DataFrame(data = listed)\n",
        "    df.plot(y=['acc_train','acc_val','acc_test'])\n",
        "    df.plot(y=['train_loss','val_loss','test_loss'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_eo9m5OsfseZ",
        "colab_type": "code",
        "outputId": "71eb0312-f5fa-456f-b21b-4f9a7eeaba3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "    run()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/7\n",
            "----------\n",
            "tensor([[-0.2759,  0.0383, -0.0966,  ...,  0.0738,  0.1358, -0.2063],\n",
            "        [-0.2433,  0.0706,  0.0633,  ...,  0.0382, -0.0747,  0.0694],\n",
            "        [-0.2446, -0.0206,  0.0472,  ...,  0.0095,  0.0687, -0.0239],\n",
            "        ...,\n",
            "        [-0.1345,  0.0316,  0.0032,  ..., -0.0314,  0.0805,  0.1030],\n",
            "        [-0.3273,  0.0156,  0.1589,  ...,  0.0767, -0.0583,  0.0328],\n",
            "        [-0.2352,  0.1358, -0.0457,  ...,  0.1782,  0.0434, -0.0203]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([9, 6, 8, 5, 4, 4, 9, 6, 2, 4, 4, 1, 0, 9, 1, 6, 5, 9, 3, 8, 9, 0, 3, 3,\n",
            "        3, 0, 4, 2, 6, 4, 6, 5, 6, 9, 1, 3, 6, 6, 8, 2, 7, 5, 9, 2, 3, 7, 5, 3,\n",
            "        6, 0, 0, 6, 6, 3, 3, 8, 9, 8, 9, 0, 5, 0, 9, 0, 2, 1, 1, 2, 2, 9, 7, 0,\n",
            "        6, 5, 4, 9, 1, 5, 3, 2, 4, 6, 5, 1, 7, 2, 7, 8, 7, 5, 9, 4, 3, 2, 8, 1,\n",
            "        9, 3, 3, 2, 8, 9, 4, 4, 2, 1, 4, 2, 6, 8, 1, 4, 1, 9, 1, 1, 2, 4, 1, 5,\n",
            "        8, 6, 2, 5, 8, 4, 5, 1, 8, 4, 6, 5, 5, 7, 5, 7, 6, 3, 9, 6, 5, 1, 4, 5,\n",
            "        3, 8, 7, 2, 0, 3, 9, 8, 8, 4, 6, 3, 2, 2, 2, 3, 0, 6, 8, 0, 8, 2, 9, 6,\n",
            "        4, 1, 4, 0, 7, 4, 5, 3, 3, 4, 2, 9, 4, 2, 3, 8, 7, 0, 0, 0, 8, 0, 7, 1,\n",
            "        5, 1, 1, 1, 4, 7, 2, 1, 4, 5, 8, 6, 1, 0, 8, 1, 2, 4, 8, 5, 5, 1, 3, 0,\n",
            "        8, 8, 9, 5, 2, 6, 8, 8, 6, 6, 6, 6, 0, 9, 9, 8, 5, 1, 8, 5, 7, 2, 9, 8,\n",
            "        6, 4, 9, 3, 8, 6, 9, 6, 9, 9, 4, 0, 4, 4, 3, 0, 9, 1, 9, 5, 7, 7, 4, 4,\n",
            "        0, 3, 5, 1, 5, 8, 8, 7, 9, 3, 8, 8, 3, 1, 6, 2, 9, 8, 8, 6, 0, 8, 9, 8,\n",
            "        3, 4, 6, 9, 7, 8, 1, 3, 2, 6, 3, 9])\n",
            "tensor([[-0.2074,  0.1008, -0.0134,  ...,  0.0438,  0.1179, -0.0648],\n",
            "        [-0.3176,  0.0107,  0.1534,  ...,  0.0944, -0.0042,  0.0219],\n",
            "        [-0.1561,  0.2098, -0.0240,  ...,  0.1390,  0.0338,  0.0988],\n",
            "        ...,\n",
            "        [-0.2948,  0.0507,  0.0932,  ...,  0.0412,  0.1337,  0.0772],\n",
            "        [-0.2955, -0.0061,  0.0672,  ...,  0.1497, -0.1177,  0.0767],\n",
            "        [-0.2880,  0.0723,  0.2330,  ...,  0.1230,  0.0030,  0.0538]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([9, 4, 7, 3, 8, 4, 7, 7, 4, 1, 8, 7, 8, 3, 0, 2, 5, 2, 2, 9, 6, 3, 0, 8,\n",
            "        4, 2, 2, 5, 8, 1, 9, 9, 3, 8, 1, 7, 3, 5, 3, 9, 0, 4, 1, 5, 5, 7, 6, 5,\n",
            "        7, 2, 9, 3, 2, 4, 6, 7, 2, 2, 4, 2, 0, 3, 2, 8, 5, 8, 1, 9, 9, 8, 4, 7,\n",
            "        4, 1, 8, 9, 0, 6, 0, 5, 8, 4, 4, 2, 3, 1, 7, 0, 3, 8, 2, 2, 1, 9, 4, 6,\n",
            "        6, 8, 8, 7, 7, 2, 6, 8, 6, 8, 5, 1, 9, 0, 3, 9, 5, 5, 3, 8, 0, 7, 5, 7,\n",
            "        8, 3, 5, 8, 6, 9, 3, 5, 9, 1, 7, 5, 1, 6, 2, 2, 1, 0, 5, 4, 2, 1, 3, 2,\n",
            "        2, 5, 2, 4, 8, 4, 0, 8, 4, 7, 4, 6, 5, 3, 7, 4, 6, 7, 5, 7, 2, 5, 3, 8,\n",
            "        6, 0, 1, 2, 2, 6, 8, 6, 5, 8, 4, 9, 7, 0, 5, 2, 9, 7, 9, 1, 0, 5, 7, 1,\n",
            "        8, 4, 8, 4, 4, 3, 3, 8, 1, 7, 5, 9, 2, 7, 6, 4, 4, 9, 7, 2, 5, 0, 8, 6,\n",
            "        2, 0, 3, 8, 9, 1, 2, 9, 6, 9, 1, 1, 5, 2, 4, 3, 2, 2, 1, 1, 3, 0, 9, 4,\n",
            "        5, 2, 5, 9, 6, 8, 7, 2, 2, 0, 8, 1, 6, 0, 0, 6, 6, 0, 9, 4, 0, 8, 1, 2,\n",
            "        1, 3, 0, 4, 2, 6, 8, 8, 9, 8, 3, 7, 2, 1, 8, 8, 9, 2, 0, 3, 7, 0, 5, 7,\n",
            "        7, 4, 4, 9, 3, 8, 3, 3, 9, 2, 0, 1])\n",
            "tensor([[-2.0212e-01,  1.0855e-01, -2.0840e-02,  ...,  9.7882e-02,\n",
            "          1.3782e-01,  2.4624e-02],\n",
            "        [-1.8683e-01, -6.9674e-02,  1.8177e-02,  ...,  4.7226e-02,\n",
            "         -6.6245e-02, -3.3452e-02],\n",
            "        [-3.8700e-01,  2.6354e-02,  1.0747e-01,  ...,  2.7593e-02,\n",
            "          1.0805e-02, -5.4546e-02],\n",
            "        ...,\n",
            "        [-3.5965e-01,  4.4084e-02,  1.6310e-01,  ...,  6.0449e-02,\n",
            "         -4.0783e-02, -8.7045e-05],\n",
            "        [-4.7414e-01,  2.0178e-02,  2.1303e-01,  ...,  2.1963e-02,\n",
            "         -9.7623e-02, -7.0260e-02],\n",
            "        [-1.6516e-01,  9.9271e-02,  7.4168e-02,  ...,  8.4190e-02,\n",
            "          5.7771e-02,  1.1180e-02]], grad_fn=<AddmmBackward>)\n",
            "tensor([5, 8, 2, 8, 4, 7, 3, 6, 6, 2, 2, 8, 8, 3, 7, 5, 0, 4, 7, 7, 7, 0, 2, 3,\n",
            "        9, 1, 0, 7, 8, 0, 5, 6, 8, 5, 8, 8, 7, 0, 9, 9, 8, 5, 1, 3, 7, 4, 1, 8,\n",
            "        9, 0, 9, 6, 1, 1, 7, 9, 0, 3, 2, 2, 9, 4, 5, 2, 3, 3, 3, 9, 0, 6, 8, 8,\n",
            "        1, 4, 4, 3, 1, 3, 4, 3, 8, 3, 1, 4, 9, 3, 5, 5, 7, 8, 0, 4, 8, 0, 5, 2,\n",
            "        0, 6, 5, 1, 5, 0, 7, 1, 8, 9, 9, 6, 1, 4, 0, 5, 6, 5, 9, 3, 3, 4, 5, 3,\n",
            "        3, 5, 5, 2, 0, 6, 1, 7, 0, 6, 1, 2, 7, 8, 4, 1, 2, 9, 1, 5, 0, 3, 1, 8,\n",
            "        5, 8, 5, 1, 0, 1, 3, 7, 5, 0, 9, 8, 4, 5, 3, 9, 3, 9, 2, 3, 2, 2, 5, 6,\n",
            "        0, 6, 3, 8, 3, 6, 2, 1, 6, 5, 2, 2, 0, 6, 5, 8, 7, 9, 2, 0, 5, 7, 6, 7,\n",
            "        4, 4, 5, 7, 4, 9, 2, 1, 1, 3, 2, 5, 2, 2, 3, 3, 3, 9, 4, 4, 3, 8, 3, 4,\n",
            "        4, 4, 2, 9, 0, 1, 7, 9, 9, 9, 6, 8, 0, 0, 1, 9, 6, 3, 4, 0, 5, 2, 6, 3,\n",
            "        4, 1, 6, 8, 9, 4, 8, 2, 8, 2, 2, 7, 9, 4, 4, 5, 4, 0, 3, 4, 0, 5, 0, 4,\n",
            "        9, 3, 0, 9, 3, 9, 3, 7, 7, 1, 2, 4, 5, 9, 9, 8, 6, 5, 8, 9, 0, 5, 2, 3,\n",
            "        1, 7, 1, 1, 4, 1, 5, 4, 8, 3, 6, 3])\n",
            "tensor([[-0.2403, -0.1071,  0.0798,  ...,  0.0005,  0.0569, -0.0151],\n",
            "        [-0.2472,  0.0554,  0.1647,  ..., -0.0942,  0.0148,  0.0476],\n",
            "        [-0.1555,  0.0763,  0.0023,  ..., -0.0832,  0.0207,  0.0751],\n",
            "        ...,\n",
            "        [-0.2714, -0.0332,  0.3311,  ..., -0.1184, -0.0359,  0.0643],\n",
            "        [-0.2667,  0.0827,  0.1871,  ...,  0.0395,  0.0159,  0.0034],\n",
            "        [-0.2350, -0.0260, -0.0710,  ...,  0.0142,  0.0515, -0.1023]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([8, 4, 2, 0, 6, 3, 0, 5, 1, 3, 0, 9, 2, 9, 8, 4, 3, 8, 9, 9, 8, 7, 2, 5,\n",
            "        8, 6, 8, 1, 6, 6, 8, 9, 5, 5, 3, 7, 0, 4, 2, 0, 9, 2, 0, 5, 3, 0, 5, 8,\n",
            "        7, 6, 6, 1, 2, 9, 2, 2, 7, 0, 5, 9, 7, 4, 5, 6, 1, 7, 3, 8, 4, 8, 8, 3,\n",
            "        0, 1, 3, 0, 7, 7, 3, 1, 8, 1, 3, 1, 2, 3, 8, 7, 2, 8, 1, 8, 4, 5, 9, 6,\n",
            "        6, 7, 1, 5, 7, 2, 2, 0, 4, 7, 3, 0, 3, 7, 4, 1, 4, 6, 3, 0, 7, 7, 0, 2,\n",
            "        9, 9, 8, 8, 7, 3, 9, 1, 9, 8, 0, 4, 9, 0, 0, 2, 0, 5, 4, 2, 0, 5, 4, 9,\n",
            "        1, 3, 1, 1, 4, 0, 4, 5, 3, 8, 6, 6, 9, 7, 6, 5, 0, 5, 8, 9, 5, 1, 8, 5,\n",
            "        4, 9, 0, 5, 4, 7, 7, 6, 7, 1, 6, 1, 2, 1, 6, 5, 0, 3, 4, 5, 0, 3, 1, 0,\n",
            "        8, 7, 9, 9, 5, 2, 5, 4, 5, 4, 0, 6, 2, 3, 1, 2, 6, 1, 2, 8, 9, 8, 0, 6,\n",
            "        7, 3, 8, 4, 8, 5, 9, 4, 0, 6, 2, 7, 3, 6, 4, 9, 9, 2, 3, 7, 4, 0, 2, 0,\n",
            "        6, 3, 7, 5, 6, 1, 9, 4, 8, 5, 1, 1, 9, 4, 1, 7, 2, 1, 9, 5, 8, 5, 0, 3,\n",
            "        3, 5, 0, 5, 6, 7, 3, 5, 1, 7, 1, 5, 3, 5, 0, 7, 3, 2, 0, 5, 2, 4, 2, 8,\n",
            "        6, 2, 9, 0, 9, 0, 8, 2, 7, 4, 3, 9])\n",
            "tensor([[-0.1746,  0.0891, -0.0242,  ..., -0.0189,  0.0291,  0.0587],\n",
            "        [-0.1653,  0.0970, -0.0093,  ...,  0.0041,  0.0251,  0.0353],\n",
            "        [-0.1862,  0.0365,  0.1688,  ..., -0.0439, -0.0039, -0.0139],\n",
            "        ...,\n",
            "        [-0.2825,  0.1353,  0.2294,  ..., -0.2097,  0.0174,  0.0145],\n",
            "        [-0.2078,  0.0171,  0.1047,  ...,  0.0509, -0.0999, -0.0389],\n",
            "        [-0.2378, -0.0231, -0.0458,  ...,  0.0074,  0.0984, -0.0230]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([7, 5, 2, 8, 2, 8, 5, 8, 3, 1, 6, 1, 0, 8, 5, 3, 7, 2, 7, 4, 4, 5, 5, 7,\n",
            "        4, 3, 6, 7, 2, 1, 4, 8, 2, 6, 9, 9, 0, 9, 4, 8, 4, 6, 2, 0, 7, 3, 1, 0,\n",
            "        3, 3, 1, 7, 1, 9, 1, 0, 2, 0, 2, 4, 4, 8, 4, 1, 1, 7, 7, 7, 2, 7, 7, 3,\n",
            "        3, 7, 1, 8, 4, 9, 8, 3, 4, 9, 2, 8, 3, 6, 8, 6, 3, 0, 2, 9, 7, 0, 1, 1,\n",
            "        5, 2, 6, 1, 9, 2, 2, 0, 1, 8, 6, 4, 1, 9, 0, 6, 8, 1, 5, 2, 2, 9, 6, 5,\n",
            "        8, 7, 3, 3, 2, 4, 6, 6, 7, 6, 4, 8, 1, 9, 5, 2, 9, 4, 9, 1, 3, 8, 7, 3,\n",
            "        3, 8, 1, 3, 0, 5, 2, 2, 0, 0, 6, 5, 7, 7, 7, 3, 9, 5, 7, 8, 0, 5, 7, 1,\n",
            "        8, 2, 6, 0, 4, 9, 8, 4, 7, 4, 7, 1, 2, 1, 6, 7, 4, 1, 2, 1, 6, 5, 9, 6,\n",
            "        7, 7, 9, 9, 4, 4, 7, 7, 9, 8, 9, 9, 8, 4, 3, 3, 6, 1, 6, 9, 4, 7, 0, 8,\n",
            "        5, 5, 8, 3, 8, 6, 0, 9, 4, 2, 5, 9, 5, 9, 4, 5, 0, 2, 7, 7, 9, 6, 7, 1,\n",
            "        5, 0, 3, 5, 9, 0, 0, 2, 7, 0, 5, 1, 1, 7, 5, 5, 9, 3, 7, 1, 0, 9, 0, 9,\n",
            "        7, 8, 7, 0, 5, 5, 5, 5, 4, 0, 0, 8, 3, 8, 8, 3, 4, 7, 8, 6, 7, 2, 3, 4,\n",
            "        9, 7, 0, 1, 3, 5, 6, 5, 8, 6, 3, 9])\n",
            "tensor([[-1.7112e-01, -4.2104e-03,  2.0809e-01,  ..., -1.2378e-01,\n",
            "         -4.4399e-02,  5.4547e-02],\n",
            "        [-2.3772e-01,  1.5509e-01, -1.1202e-01,  ...,  2.8498e-01,\n",
            "          9.7173e-02,  1.2732e-01],\n",
            "        [-2.0440e-01,  1.2492e-03, -9.9039e-02,  ...,  1.1104e-01,\n",
            "          1.2289e-01, -8.4558e-02],\n",
            "        ...,\n",
            "        [-2.0070e-01,  7.3200e-02, -2.3427e-02,  ..., -3.6738e-04,\n",
            "          7.7196e-02,  5.6849e-02],\n",
            "        [-2.3859e-01,  2.0735e-04, -1.2711e-02,  ..., -1.9032e-03,\n",
            "          8.0036e-02, -6.4602e-02],\n",
            "        [-2.3714e-01, -2.9191e-02,  1.4554e-01,  ..., -1.5333e-02,\n",
            "         -1.0979e-02,  5.5176e-02]], grad_fn=<AddmmBackward>)\n",
            "tensor([6, 7, 9, 0, 8, 6, 0, 2, 4, 1, 6, 1, 5, 8, 6, 8, 3, 4, 1, 3, 3, 3, 7, 6,\n",
            "        5, 6, 4, 1, 2, 4, 1, 3, 1, 1, 3, 4, 7, 2, 0, 0, 7, 8, 4, 5, 7, 5, 6, 8,\n",
            "        9, 6, 2, 8, 7, 4, 9, 1, 7, 6, 4, 6, 5, 4, 0, 5, 2, 5, 7, 3, 4, 4, 8, 3,\n",
            "        8, 7, 3, 5, 1, 1, 5, 5, 1, 2, 8, 2, 1, 2, 5, 3, 0, 5, 9, 7, 7, 3, 7, 8,\n",
            "        8, 5, 0, 7, 3, 6, 8, 2, 9, 9, 5, 9, 6, 0, 9, 9, 7, 9, 0, 4, 1, 3, 9, 1,\n",
            "        3, 5, 3, 2, 0, 5, 2, 0, 4, 8, 2, 5, 2, 6, 9, 6, 6, 9, 9, 2, 0, 7, 1, 1,\n",
            "        3, 8, 0, 7, 0, 1, 6, 7, 2, 6, 4, 2, 7, 6, 6, 4, 5, 4, 9, 0, 3, 9, 9, 5,\n",
            "        5, 5, 5, 4, 7, 2, 6, 8, 8, 7, 9, 3, 8, 4, 0, 1, 4, 0, 6, 7, 9, 2, 8, 4,\n",
            "        5, 5, 7, 9, 0, 3, 4, 7, 4, 1, 3, 9, 4, 3, 4, 4, 4, 2, 8, 9, 4, 5, 3, 1,\n",
            "        9, 2, 1, 5, 5, 6, 0, 2, 4, 2, 7, 0, 4, 8, 3, 1, 1, 5, 4, 7, 6, 7, 3, 7,\n",
            "        7, 9, 9, 5, 9, 7, 7, 2, 1, 5, 8, 0, 5, 1, 8, 2, 7, 4, 3, 6, 2, 8, 0, 4,\n",
            "        3, 1, 4, 5, 2, 6, 4, 4, 1, 6, 5, 3, 8, 9, 8, 5, 0, 2, 8, 1, 4, 4, 6, 2,\n",
            "        1, 2, 0, 6, 2, 4, 2, 4, 6, 5, 5, 3])\n",
            "tensor([[-0.2482,  0.1125,  0.1242,  ..., -0.0497,  0.1779, -0.0784],\n",
            "        [-0.2375,  0.0856, -0.0202,  ...,  0.1473,  0.1980, -0.0107],\n",
            "        [-0.1652,  0.0694,  0.0402,  ...,  0.1845,  0.1565,  0.0490],\n",
            "        ...,\n",
            "        [-0.0559, -0.0038,  0.1735,  ..., -0.1377, -0.0886,  0.0647],\n",
            "        [-0.2655,  0.0751, -0.0491,  ...,  0.0758,  0.1324,  0.0081],\n",
            "        [-0.2271, -0.0442,  0.1705,  ...,  0.0631, -0.1022,  0.0240]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([8, 7, 7, 0, 1, 6, 7, 6, 3, 1, 3, 5, 7, 4, 9, 9, 6, 6, 4, 0, 9, 5, 5, 4,\n",
            "        2, 4, 5, 5, 2, 6, 3, 6, 2, 2, 8, 3, 4, 7, 1, 4, 8, 7, 5, 5, 8, 0, 6, 1,\n",
            "        1, 5, 5, 3, 9, 3, 5, 7, 1, 3, 6, 5, 2, 8, 4, 8, 3, 4, 2, 1, 1, 1, 3, 2,\n",
            "        6, 9, 3, 5, 8, 2, 2, 3, 2, 4, 8, 8, 8, 0, 9, 4, 4, 5, 5, 4, 0, 0, 9, 4,\n",
            "        7, 0, 9, 1, 5, 6, 6, 4, 3, 8, 3, 9, 6, 9, 5, 6, 9, 0, 8, 4, 3, 0, 1, 5,\n",
            "        4, 0, 7, 5, 7, 6, 4, 2, 3, 0, 9, 4, 4, 4, 3, 5, 1, 0, 5, 0, 1, 4, 8, 9,\n",
            "        0, 7, 8, 1, 7, 6, 3, 0, 8, 2, 2, 2, 1, 4, 2, 2, 8, 6, 7, 3, 6, 2, 7, 3,\n",
            "        7, 1, 7, 9, 6, 5, 0, 7, 7, 6, 1, 8, 9, 6, 7, 2, 1, 7, 0, 9, 3, 6, 4, 3,\n",
            "        9, 2, 2, 7, 3, 1, 2, 1, 1, 0, 8, 5, 5, 0, 5, 8, 7, 8, 0, 8, 8, 6, 7, 4,\n",
            "        5, 1, 4, 5, 7, 9, 7, 9, 9, 3, 8, 3, 2, 3, 7, 2, 9, 3, 1, 4, 7, 8, 5, 7,\n",
            "        1, 5, 6, 6, 1, 7, 7, 5, 4, 5, 0, 3, 9, 2, 9, 3, 0, 6, 4, 1, 0, 9, 6, 9,\n",
            "        7, 6, 4, 0, 8, 9, 9, 2, 0, 3, 4, 2, 3, 0, 7, 7, 4, 1, 2, 6, 0, 0, 6, 1,\n",
            "        6, 5, 0, 8, 8, 6, 4, 5, 7, 6, 5, 0])\n",
            "tensor([[-0.1831,  0.0533,  0.1444,  ..., -0.1392, -0.1047, -0.0359],\n",
            "        [-0.1200, -0.2270,  0.3183,  ..., -0.3075, -0.2143,  0.0009],\n",
            "        [-0.1907,  0.1163, -0.1011,  ...,  0.0426,  0.0544,  0.0536],\n",
            "        ...,\n",
            "        [-0.1097,  0.0509,  0.0179,  ...,  0.1071,  0.1066,  0.0705],\n",
            "        [-0.1110,  0.0792,  0.1574,  ..., -0.1235,  0.0359,  0.0518],\n",
            "        [-0.0594,  0.0366, -0.0049,  ..., -0.0627,  0.0273,  0.0566]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([6, 4, 7, 5, 7, 9, 4, 3, 3, 4, 9, 2, 3, 4, 2, 1, 8, 4, 2, 0, 3, 6, 8, 9,\n",
            "        5, 4, 9, 9, 2, 5, 9, 1, 2, 3, 1, 8, 7, 2, 4, 1, 0, 4, 2, 4, 7, 2, 9, 5,\n",
            "        1, 4, 2, 0, 5, 4, 3, 7, 7, 6, 6, 7, 0, 8, 2, 6, 7, 4, 4, 8, 0, 4, 5, 4,\n",
            "        4, 5, 9, 9, 4, 8, 7, 7, 5, 0, 8, 8, 1, 2, 5, 4, 5, 4, 0, 7, 4, 4, 0, 9,\n",
            "        9, 9, 6, 4, 8, 8, 1, 7, 4, 0, 4, 6, 3, 5, 8, 8, 4, 9, 5, 8, 2, 8, 4, 1,\n",
            "        8, 2, 7, 8, 1, 1, 4, 3, 1, 4, 1, 6, 3, 2, 7, 2, 5, 5, 7, 1, 7, 0, 4, 1,\n",
            "        0, 8, 2, 8, 7, 7, 1, 1, 6, 4, 7, 3, 8, 3, 2, 3, 0, 8, 8, 6, 7, 8, 6, 0,\n",
            "        1, 2, 7, 6, 6, 7, 3, 3, 1, 7, 1, 8, 0, 8, 3, 2, 0, 1, 4, 6, 5, 3, 0, 0,\n",
            "        7, 4, 5, 4, 3, 4, 0, 1, 6, 2, 1, 5, 7, 2, 5, 2, 5, 6, 8, 8, 1, 6, 9, 7,\n",
            "        9, 5, 1, 4, 8, 5, 2, 2, 5, 1, 9, 9, 9, 2, 6, 0, 9, 8, 5, 5, 2, 2, 6, 6,\n",
            "        9, 8, 9, 7, 4, 7, 4, 9, 7, 7, 3, 9, 6, 5, 5, 9, 9, 0, 3, 8, 7, 5, 0, 6,\n",
            "        4, 5, 5, 7, 8, 9, 7, 0, 1, 2, 5, 3, 8, 1, 5, 4, 3, 0, 7, 8, 4, 8, 8, 3,\n",
            "        5, 9, 0, 0, 8, 2, 5, 5, 8, 7, 2, 6])\n",
            "tensor([[-0.1961, -0.0624,  0.1036,  ...,  0.0187,  0.1417,  0.0582],\n",
            "        [-0.2231,  0.0128,  0.2270,  ..., -0.2187,  0.0109, -0.0023],\n",
            "        [-0.1340,  0.0657, -0.0256,  ..., -0.0513,  0.0555,  0.0703],\n",
            "        ...,\n",
            "        [-0.1158, -0.0072,  0.1246,  ..., -0.1357, -0.0282,  0.1034],\n",
            "        [-0.2370,  0.2332,  0.0726,  ...,  0.0107,  0.1007,  0.0412],\n",
            "        [-0.0995,  0.1336,  0.2422,  ...,  0.0287,  0.0627, -0.0176]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([8, 2, 2, 1, 5, 0, 9, 9, 1, 2, 8, 3, 2, 6, 1, 0, 8, 3, 5, 3, 0, 1, 6, 1,\n",
            "        0, 2, 4, 9, 2, 0, 0, 8, 8, 2, 1, 7, 7, 1, 2, 9, 8, 8, 5, 1, 4, 3, 6, 1,\n",
            "        2, 7, 4, 8, 4, 9, 9, 1, 0, 5, 8, 9, 9, 7, 9, 5, 5, 1, 5, 2, 5, 0, 5, 5,\n",
            "        6, 4, 5, 3, 5, 1, 9, 2, 7, 5, 2, 1, 4, 2, 8, 2, 1, 0, 8, 7, 0, 0, 6, 6,\n",
            "        0, 6, 9, 5, 8, 7, 6, 6, 8, 3, 5, 2, 8, 1, 2, 9, 4, 7, 6, 0, 7, 4, 9, 1,\n",
            "        9, 6, 9, 3, 6, 8, 9, 0, 5, 0, 1, 0, 1, 7, 1, 6, 5, 1, 1, 6, 8, 6, 2, 2,\n",
            "        1, 3, 7, 3, 9, 2, 8, 2, 0, 9, 3, 5, 9, 9, 4, 9, 3, 5, 0, 7, 5, 5, 2, 1,\n",
            "        1, 3, 3, 9, 9, 8, 5, 8, 3, 7, 3, 0, 9, 3, 8, 0, 7, 0, 4, 0, 5, 9, 2, 3,\n",
            "        5, 1, 0, 8, 7, 6, 5, 8, 8, 4, 9, 1, 2, 9, 8, 6, 4, 4, 0, 9, 5, 9, 2, 8,\n",
            "        6, 2, 9, 0, 5, 5, 1, 4, 1, 4, 3, 6, 7, 0, 2, 8, 0, 6, 6, 0, 5, 8, 9, 9,\n",
            "        7, 1, 0, 9, 0, 7, 7, 9, 7, 9, 5, 4, 4, 6, 7, 5, 4, 5, 3, 1, 5, 3, 8, 3,\n",
            "        4, 3, 5, 9, 1, 4, 2, 0, 0, 0, 7, 3, 0, 6, 3, 3, 6, 2, 4, 4, 0, 9, 5, 7,\n",
            "        2, 1, 8, 8, 9, 3, 6, 0, 7, 8, 2, 3])\n",
            "tensor([[-0.1756,  0.0638,  0.0383,  ..., -0.0374, -0.0072,  0.0392],\n",
            "        [-0.2380, -0.0639,  0.1493,  ..., -0.1620, -0.1072, -0.0490],\n",
            "        [-0.1825,  0.1768,  0.2796,  ..., -0.0229,  0.0144,  0.0301],\n",
            "        ...,\n",
            "        [-0.1235,  0.0608,  0.1041,  ..., -0.1521,  0.0424,  0.0772],\n",
            "        [-0.2552,  0.0748, -0.0117,  ...,  0.2890,  0.1832,  0.1408],\n",
            "        [-0.2605,  0.0653,  0.2861,  ..., -0.1025, -0.0657, -0.0460]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([3, 0, 4, 6, 8, 1, 7, 7, 7, 1, 3, 7, 2, 8, 8, 7, 4, 2, 2, 7, 1, 1, 8, 7,\n",
            "        4, 7, 5, 7, 2, 3, 2, 9, 5, 8, 3, 5, 2, 3, 1, 4, 9, 1, 1, 9, 4, 9, 8, 4,\n",
            "        5, 7, 9, 8, 6, 0, 2, 9, 9, 7, 2, 4, 1, 9, 0, 9, 1, 0, 9, 8, 3, 3, 9, 9,\n",
            "        6, 9, 7, 9, 1, 6, 7, 1, 6, 0, 2, 7, 7, 5, 5, 9, 4, 9, 2, 1, 8, 5, 3, 9,\n",
            "        4, 5, 4, 0, 3, 5, 8, 1, 4, 7, 7, 7, 3, 5, 9, 4, 9, 0, 5, 8, 6, 3, 9, 5,\n",
            "        0, 8, 8, 6, 7, 7, 4, 9, 8, 3, 5, 3, 8, 1, 6, 1, 4, 7, 4, 7, 0, 3, 6, 9,\n",
            "        0, 1, 6, 7, 7, 2, 9, 4, 6, 0, 4, 2, 1, 8, 9, 8, 3, 8, 9, 2, 0, 7, 8, 2,\n",
            "        9, 8, 8, 4, 5, 9, 3, 1, 7, 0, 5, 3, 7, 0, 2, 4, 3, 6, 7, 5, 3, 5, 4, 6,\n",
            "        1, 9, 4, 7, 3, 1, 9, 5, 0, 7, 1, 1, 0, 1, 2, 8, 9, 1, 4, 3, 6, 5, 7, 4,\n",
            "        4, 6, 7, 9, 5, 3, 9, 9, 1, 3, 8, 9, 6, 9, 9, 5, 5, 3, 6, 0, 2, 9, 1, 4,\n",
            "        7, 1, 1, 6, 7, 6, 7, 4, 7, 0, 8, 4, 1, 8, 0, 5, 0, 3, 6, 6, 1, 5, 4, 0,\n",
            "        7, 3, 5, 2, 4, 6, 6, 9, 7, 0, 7, 7, 5, 2, 6, 9, 3, 5, 7, 1, 5, 4, 2, 4,\n",
            "        2, 1, 3, 8, 1, 1, 5, 3, 6, 4, 7, 3])\n",
            "tensor([[-0.1511,  0.1569,  0.1324,  ..., -0.0197,  0.0237, -0.0402],\n",
            "        [-0.2014,  0.0053, -0.0320,  ..., -0.0261,  0.2431, -0.0044],\n",
            "        [-0.1520,  0.0824, -0.0142,  ...,  0.0819,  0.1053,  0.1996],\n",
            "        ...,\n",
            "        [-0.2101,  0.0514, -0.0074,  ...,  0.0274,  0.0087,  0.1035],\n",
            "        [-0.1691,  0.0651, -0.0726,  ..., -0.0161,  0.0148,  0.0279],\n",
            "        [-0.3094, -0.0405, -0.0635,  ...,  0.0548, -0.0923,  0.0325]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([1, 5, 5, 5, 1, 0, 3, 6, 7, 9, 6, 6, 3, 1, 1, 4, 1, 7, 6, 2, 6, 9, 3, 1,\n",
            "        1, 2, 6, 4, 5, 5, 8, 5, 7, 9, 8, 8, 1, 6, 5, 4, 5, 7, 8, 0, 6, 1, 4, 1,\n",
            "        8, 8, 6, 7, 6, 6, 3, 1, 1, 6, 1, 5, 7, 0, 4, 4, 3, 7, 2, 1, 0, 8, 7, 9,\n",
            "        1, 8, 5, 7, 2, 8, 2, 5, 3, 1, 2, 3, 0, 3, 5, 8, 0, 8, 2, 4, 9, 3, 3, 3,\n",
            "        7, 6, 2, 2, 4, 7, 8, 5, 1, 6, 3, 1, 0, 5, 3, 1, 1, 0, 2, 9, 8, 9, 8, 9,\n",
            "        4, 6, 2, 9, 2, 2, 9, 3, 5, 2, 1, 5, 2, 7, 4, 6, 2, 4, 5, 3, 2, 7, 1, 1,\n",
            "        1, 1, 3, 8, 2, 9, 4, 9, 4, 1, 5, 7, 0, 7, 6, 3, 0, 4, 0, 9, 0, 8, 2, 3,\n",
            "        0, 9, 4, 8, 3, 8, 1, 5, 9, 5, 9, 6, 6, 2, 6, 2, 4, 9, 6, 8, 5, 9, 1, 5,\n",
            "        7, 7, 5, 3, 9, 1, 0, 1, 6, 2, 3, 2, 6, 8, 8, 6, 2, 9, 2, 8, 6, 1, 9, 3,\n",
            "        2, 5, 2, 3, 6, 3, 3, 6, 1, 1, 8, 5, 0, 9, 2, 4, 7, 2, 8, 9, 7, 9, 0, 9,\n",
            "        5, 4, 1, 5, 3, 2, 3, 3, 7, 3, 5, 7, 8, 6, 5, 3, 9, 2, 1, 6, 0, 7, 3, 8,\n",
            "        5, 7, 7, 4, 5, 2, 6, 0, 6, 9, 0, 5, 6, 2, 2, 0, 0, 5, 3, 8, 8, 9, 6, 3,\n",
            "        5, 5, 2, 7, 4, 5, 2, 2, 0, 5, 7, 9])\n",
            "tensor([[-0.1479, -0.0277,  0.1895,  ..., -0.0814, -0.0440,  0.0726],\n",
            "        [-0.0901,  0.0837,  0.0075,  ...,  0.0609,  0.0173,  0.0438],\n",
            "        [-0.1588,  0.0225,  0.1282,  ..., -0.1140, -0.0072,  0.0285],\n",
            "        ...,\n",
            "        [-0.1973, -0.1174,  0.2841,  ..., -0.2508, -0.0052,  0.0376],\n",
            "        [-0.2812, -0.1284,  0.4065,  ..., -0.3445, -0.2194, -0.0547],\n",
            "        [-0.1576,  0.1661, -0.0270,  ...,  0.0441,  0.0744,  0.0564]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([6, 5, 3, 4, 1, 3, 7, 5, 1, 9, 7, 0, 8, 0, 1, 9, 0, 5, 7, 0, 0, 3, 6, 8,\n",
            "        8, 6, 6, 4, 4, 0, 3, 2, 8, 9, 4, 9, 4, 6, 4, 2, 5, 5, 6, 6, 5, 8, 5, 5,\n",
            "        9, 2, 8, 2, 9, 2, 7, 6, 6, 0, 4, 7, 5, 3, 7, 7, 1, 7, 9, 7, 8, 0, 9, 4,\n",
            "        5, 4, 1, 0, 4, 2, 3, 1, 5, 9, 6, 3, 4, 7, 7, 1, 6, 4, 6, 0, 4, 1, 2, 2,\n",
            "        3, 8, 9, 5, 8, 8, 8, 0, 2, 1, 4, 5, 7, 4, 5, 1, 0, 9, 4, 2, 5, 1, 2, 2,\n",
            "        0, 0, 3, 0, 7, 2, 1, 7, 6, 1, 1, 4, 8, 5, 7, 8, 0, 7, 5, 4, 1, 5, 2, 1,\n",
            "        5, 4, 8, 4, 2, 2, 2, 2, 3, 9, 0, 8, 9, 2, 2, 6, 1, 0, 6, 4, 8, 7, 2, 0,\n",
            "        4, 8, 8, 8, 6, 3, 0, 5, 5, 1, 7, 6, 0, 3, 1, 0, 3, 1, 7, 2, 8, 3, 5, 6,\n",
            "        4, 2, 6, 4, 8, 9, 2, 4, 4, 5, 1, 7, 9, 3, 3, 5, 9, 3, 7, 9, 2, 7, 9, 9,\n",
            "        2, 3, 0, 0, 3, 0, 3, 1, 8, 5, 9, 5, 1, 2, 3, 0, 4, 8, 6, 9, 3, 1, 9, 6,\n",
            "        7, 5, 5, 1, 8, 8, 3, 8, 8, 0, 3, 8, 8, 3, 8, 7, 1, 6, 3, 4, 5, 9, 2, 7,\n",
            "        3, 0, 4, 7, 5, 3, 7, 4, 3, 0, 3, 4, 3, 8, 1, 9, 6, 7, 5, 4, 4, 5, 6, 6,\n",
            "        9, 3, 7, 9, 8, 7, 0, 9, 3, 8, 2, 6])\n",
            "tensor([[-0.1483, -0.0520,  0.3645,  ..., -0.3705, -0.0231,  0.0083],\n",
            "        [-0.1591, -0.1650,  0.2485,  ..., -0.2654, -0.1476, -0.0688],\n",
            "        [-0.1471,  0.0282,  0.1094,  ..., -0.0137,  0.0607,  0.1547],\n",
            "        ...,\n",
            "        [-0.1201, -0.0943,  0.1498,  ...,  0.0524,  0.2099,  0.0970],\n",
            "        [-0.1559,  0.3027,  0.2934,  ..., -0.1218, -0.0258,  0.0672],\n",
            "        [-0.1122, -0.1268,  0.4440,  ..., -0.3853, -0.1562,  0.0238]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([4, 8, 8, 9, 3, 1, 2, 2, 2, 3, 2, 1, 0, 4, 2, 5, 4, 9, 4, 6, 4, 7, 6, 0,\n",
            "        2, 2, 6, 0, 2, 4, 9, 9, 6, 0, 2, 1, 3, 4, 9, 2, 9, 3, 1, 4, 0, 4, 7, 3,\n",
            "        7, 6, 5, 2, 7, 1, 1, 6, 9, 7, 0, 6, 7, 7, 0, 9, 0, 7, 4, 2, 4, 2, 8, 6,\n",
            "        8, 9, 9, 0, 6, 7, 0, 9, 9, 6, 3, 3, 3, 0, 8, 6, 5, 1, 8, 5, 5, 0, 4, 0,\n",
            "        7, 1, 2, 9, 7, 3, 4, 8, 7, 7, 7, 8, 9, 4, 1, 8, 8, 1, 4, 3, 2, 5, 3, 2,\n",
            "        4, 1, 5, 3, 1, 6, 4, 7, 2, 4, 3, 3, 9, 1, 5, 4, 0, 1, 2, 0, 0, 1, 4, 3,\n",
            "        9, 7, 1, 5, 9, 3, 8, 9, 7, 7, 9, 7, 3, 9, 2, 6, 5, 0, 1, 1, 6, 2, 7, 2,\n",
            "        7, 1, 1, 9, 4, 1, 1, 0, 7, 3, 7, 3, 1, 5, 9, 0, 3, 1, 2, 5, 8, 1, 0, 3,\n",
            "        3, 7, 0, 0, 9, 3, 9, 5, 0, 4, 0, 5, 7, 4, 8, 1, 4, 7, 6, 7, 3, 5, 7, 3,\n",
            "        8, 6, 2, 3, 4, 1, 5, 4, 0, 9, 0, 1, 7, 5, 9, 3, 5, 7, 6, 5, 9, 3, 8, 9,\n",
            "        2, 1, 2, 1, 7, 0, 8, 9, 8, 3, 2, 0, 5, 3, 1, 2, 0, 3, 7, 5, 6, 6, 4, 0,\n",
            "        1, 4, 8, 8, 0, 8, 0, 4, 1, 5, 6, 1, 7, 2, 6, 6, 5, 4, 0, 4, 8, 5, 4, 8,\n",
            "        2, 5, 8, 5, 4, 3, 8, 8, 5, 8, 1, 6])\n",
            "tensor([[-0.0649, -0.0117,  0.1180,  ..., -0.0914, -0.0438,  0.0123],\n",
            "        [-0.1683,  0.2139,  0.1471,  ..., -0.0510,  0.0467,  0.0423],\n",
            "        [-0.0604, -0.0789,  0.2358,  ..., -0.1902, -0.2241,  0.0256],\n",
            "        ...,\n",
            "        [-0.1187, -0.1076,  0.1757,  ..., -0.1411, -0.1320,  0.0032],\n",
            "        [-0.2857, -0.2302,  0.4909,  ..., -0.4386, -0.1592, -0.0047],\n",
            "        [-0.1612,  0.0612, -0.0123,  ...,  0.0578,  0.1181,  0.0964]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([0, 1, 6, 1, 9, 8, 6, 4, 3, 5, 4, 3, 0, 1, 1, 1, 0, 0, 4, 3, 1, 5, 6, 5,\n",
            "        5, 1, 5, 7, 6, 0, 0, 5, 8, 6, 4, 3, 1, 7, 8, 3, 5, 7, 1, 6, 0, 1, 2, 3,\n",
            "        4, 5, 1, 0, 3, 0, 7, 2, 7, 2, 8, 4, 8, 9, 4, 7, 9, 8, 0, 4, 0, 3, 2, 6,\n",
            "        4, 2, 7, 5, 6, 6, 7, 6, 9, 8, 6, 7, 7, 9, 3, 5, 1, 5, 5, 2, 7, 9, 7, 4,\n",
            "        1, 5, 5, 0, 5, 4, 9, 2, 0, 1, 2, 7, 7, 3, 9, 4, 0, 2, 8, 0, 4, 2, 6, 2,\n",
            "        3, 0, 5, 7, 9, 3, 4, 4, 9, 7, 5, 1, 3, 0, 0, 3, 7, 1, 5, 5, 1, 8, 7, 8,\n",
            "        4, 0, 3, 7, 8, 0, 0, 2, 6, 4, 6, 5, 3, 8, 8, 5, 4, 9, 7, 8, 0, 0, 1, 9,\n",
            "        1, 8, 3, 5, 8, 0, 4, 9, 2, 9, 0, 4, 1, 2, 3, 8, 4, 5, 0, 4, 8, 8, 2, 1,\n",
            "        2, 5, 8, 5, 0, 6, 5, 8, 7, 5, 4, 9, 1, 3, 0, 2, 9, 5, 8, 3, 7, 8, 0, 5,\n",
            "        5, 2, 3, 2, 3, 8, 3, 5, 2, 5, 4, 7, 3, 0, 4, 4, 6, 4, 4, 4, 9, 5, 2, 6,\n",
            "        7, 7, 7, 2, 6, 3, 6, 7, 7, 0, 5, 9, 1, 9, 3, 1, 7, 8, 2, 7, 4, 0, 8, 1,\n",
            "        6, 5, 2, 4, 4, 1, 2, 7, 5, 5, 5, 2, 0, 3, 7, 2, 9, 4, 8, 4, 9, 3, 9, 8,\n",
            "        8, 9, 0, 2, 6, 6, 1, 9, 4, 6, 2, 7])\n",
            "tensor([[-0.0580,  0.0122,  0.3053,  ..., -0.3010,  0.1712,  0.0499],\n",
            "        [-0.1397,  0.0640, -0.0240,  ...,  0.1966,  0.0944,  0.1534],\n",
            "        [-0.0650, -0.0347,  0.2400,  ..., -0.2549, -0.0482,  0.0232],\n",
            "        ...,\n",
            "        [-0.1997,  0.0391, -0.0873,  ...,  0.0263, -0.0111,  0.0530],\n",
            "        [-0.1298,  0.0662,  0.2806,  ..., -0.0715,  0.0200, -0.0276],\n",
            "        [-0.1822,  0.0418,  0.0497,  ..., -0.0341,  0.0240,  0.2196]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([8, 7, 6, 9, 6, 8, 3, 7, 1, 9, 5, 9, 4, 4, 3, 3, 8, 8, 6, 4, 0, 2, 3, 2,\n",
            "        8, 2, 7, 5, 8, 8, 5, 9, 3, 7, 4, 2, 4, 0, 8, 7, 9, 0, 1, 6, 6, 2, 7, 0,\n",
            "        7, 2, 0, 6, 2, 3, 2, 7, 6, 8, 8, 9, 1, 0, 7, 8, 3, 8, 2, 9, 1, 6, 1, 9,\n",
            "        1, 7, 8, 5, 0, 8, 7, 7, 4, 2, 2, 3, 3, 6, 3, 1, 5, 9, 1, 6, 7, 4, 9, 1,\n",
            "        1, 3, 0, 7, 2, 9, 5, 7, 3, 0, 2, 2, 1, 5, 2, 2, 2, 0, 8, 0, 8, 5, 7, 3,\n",
            "        2, 5, 7, 4, 0, 2, 9, 8, 7, 9, 1, 4, 5, 4, 4, 9, 0, 3, 5, 8, 1, 4, 3, 2,\n",
            "        7, 4, 0, 7, 1, 3, 5, 2, 2, 4, 4, 9, 2, 4, 7, 7, 5, 7, 7, 2, 0, 8, 3, 8,\n",
            "        7, 5, 6, 0, 9, 9, 1, 6, 1, 0, 3, 7, 0, 6, 5, 5, 6, 2, 4, 3, 2, 0, 5, 1,\n",
            "        5, 6, 9, 2, 5, 6, 1, 5, 8, 5, 1, 5, 9, 4, 6, 4, 4, 4, 0, 4, 1, 1, 2, 6,\n",
            "        4, 6, 8, 2, 6, 5, 6, 7, 6, 4, 6, 2, 5, 7, 3, 1, 7, 0, 3, 5, 0, 6, 3, 7,\n",
            "        1, 6, 6, 5, 7, 9, 1, 0, 6, 9, 0, 8, 7, 8, 5, 9, 3, 0, 7, 1, 3, 5, 1, 1,\n",
            "        6, 8, 2, 8, 0, 5, 7, 2, 1, 0, 9, 9, 0, 2, 9, 5, 2, 5, 9, 2, 3, 1, 9, 3,\n",
            "        2, 5, 9, 2, 3, 5, 0, 9, 2, 9, 0, 9])\n",
            "tensor([[-0.2371, -0.0570, -0.0297,  ..., -0.0701,  0.1055,  0.1453],\n",
            "        [-0.1450,  0.0442,  0.1803,  ..., -0.2189, -0.0160, -0.0247],\n",
            "        [-0.1551,  0.0997, -0.0647,  ...,  0.0792,  0.1025,  0.1195],\n",
            "        ...,\n",
            "        [-0.1881,  0.1271, -0.1188,  ...,  0.1656,  0.0584,  0.1105],\n",
            "        [-0.2391,  0.0884, -0.1120,  ...,  0.0087,  0.0330,  0.0462],\n",
            "        [-0.1342,  0.2229,  0.1547,  ..., -0.1239, -0.0288,  0.0476]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([9, 2, 5, 4, 2, 7, 9, 1, 4, 4, 7, 7, 2, 7, 1, 3, 8, 0, 2, 2, 0, 9, 7, 0,\n",
            "        8, 5, 9, 7, 5, 0, 5, 0, 8, 8, 5, 5, 2, 9, 7, 9, 4, 5, 1, 9, 6, 3, 2, 2,\n",
            "        2, 1, 6, 4, 1, 3, 6, 0, 7, 6, 0, 3, 2, 2, 5, 6, 3, 5, 7, 2, 5, 4, 6, 2,\n",
            "        1, 3, 3, 1, 1, 0, 3, 5, 8, 5, 6, 3, 1, 5, 8, 6, 6, 4, 1, 8, 8, 9, 5, 4,\n",
            "        8, 9, 5, 1, 6, 5, 1, 5, 8, 5, 4, 4, 5, 6, 6, 3, 2, 4, 1, 2, 3, 9, 8, 2,\n",
            "        8, 6, 0, 4, 3, 8, 2, 6, 7, 3, 3, 3, 8, 7, 4, 9, 4, 3, 6, 4, 3, 1, 1, 5,\n",
            "        8, 1, 9, 8, 0, 0, 1, 0, 7, 8, 3, 7, 2, 5, 4, 2, 8, 3, 7, 2, 7, 6, 4, 8,\n",
            "        4, 6, 8, 0, 2, 9, 7, 5, 0, 5, 3, 7, 6, 0, 7, 7, 2, 9, 5, 6, 3, 4, 7, 3,\n",
            "        0, 4, 1, 9, 3, 9, 0, 1, 3, 5, 3, 0, 4, 2, 4, 3, 7, 6, 3, 2, 5, 6, 7, 2,\n",
            "        7, 4, 1, 7, 8, 7, 2, 9, 1, 4, 7, 2, 7, 7, 8, 7, 7, 0, 2, 5, 7, 2, 9, 8,\n",
            "        8, 5, 4, 7, 7, 3, 4, 6, 5, 2, 6, 7, 1, 7, 9, 9, 7, 2, 1, 9, 5, 3, 5, 3,\n",
            "        2, 0, 8, 3, 3, 1, 9, 1, 9, 1, 3, 1, 0, 1, 6, 4, 1, 5, 7, 7, 4, 1, 0, 0,\n",
            "        4, 4, 7, 4, 9, 5, 4, 0, 8, 7, 7, 1])\n",
            "tensor([[-0.2348,  0.0361,  0.2556,  ..., -0.1954, -0.0890,  0.1012],\n",
            "        [-0.3212,  0.0546, -0.0921,  ...,  0.2833,  0.3074,  0.1313],\n",
            "        [-0.1860,  0.3133,  0.2048,  ..., -0.0257,  0.1020, -0.0020],\n",
            "        ...,\n",
            "        [-0.0361,  0.0575,  0.1298,  ..., -0.1477, -0.0787,  0.0724],\n",
            "        [-0.3318,  0.0188, -0.1718,  ...,  0.3147,  0.3437,  0.1757],\n",
            "        [-0.2264,  0.0731, -0.1602,  ...,  0.1149,  0.2446,  0.2120]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([2, 9, 1, 9, 0, 7, 8, 3, 0, 9, 3, 1, 5, 4, 3, 2, 7, 8, 5, 4, 1, 0, 0, 7,\n",
            "        7, 1, 7, 5, 7, 5, 0, 0, 6, 4, 7, 6, 1, 7, 9, 8, 7, 4, 4, 9, 1, 6, 0, 7,\n",
            "        8, 3, 0, 4, 4, 5, 5, 0, 5, 5, 8, 6, 1, 0, 5, 3, 2, 4, 3, 9, 3, 3, 5, 6,\n",
            "        6, 8, 7, 9, 1, 0, 0, 1, 4, 0, 9, 4, 1, 5, 6, 3, 5, 6, 9, 6, 0, 7, 2, 9,\n",
            "        1, 0, 3, 0, 1, 6, 1, 7, 3, 9, 1, 3, 4, 0, 9, 1, 1, 4, 0, 4, 6, 3, 7, 5,\n",
            "        9, 6, 4, 3, 0, 7, 7, 1, 8, 6, 9, 7, 6, 7, 6, 2, 6, 2, 0, 5, 1, 1, 6, 6,\n",
            "        2, 5, 5, 9, 5, 6, 3, 4, 5, 0, 4, 8, 0, 7, 7, 0, 5, 2, 2, 0, 4, 1, 1, 4,\n",
            "        2, 3, 7, 6, 1, 3, 6, 1, 2, 1, 6, 8, 1, 5, 3, 1, 1, 5, 8, 7, 2, 6, 7, 3,\n",
            "        3, 8, 6, 6, 8, 9, 6, 9, 3, 6, 6, 1, 3, 4, 0, 8, 3, 3, 8, 3, 8, 7, 5, 4,\n",
            "        4, 8, 6, 0, 3, 3, 4, 8, 8, 4, 2, 7, 8, 2, 6, 5, 1, 9, 0, 5, 4, 2, 2, 6,\n",
            "        7, 6, 0, 8, 0, 7, 4, 3, 6, 0, 0, 2, 3, 8, 0, 8, 3, 6, 6, 1, 4, 3, 0, 2,\n",
            "        9, 9, 3, 0, 9, 5, 5, 5, 3, 1, 3, 0, 5, 5, 3, 4, 0, 8, 0, 7, 7, 3, 9, 4,\n",
            "        2, 5, 0, 3, 3, 2, 3, 6, 7, 0, 9, 5])\n",
            "tensor([[-0.0305,  0.0246,  0.0667,  ..., -0.1609, -0.0135,  0.0303],\n",
            "        [-0.0338,  0.0099,  0.2750,  ..., -0.1361,  0.1008,  0.0976],\n",
            "        [-0.2370,  0.1108, -0.1333,  ...,  0.3793,  0.2850,  0.1704],\n",
            "        ...,\n",
            "        [-0.0792, -0.1806,  0.5775,  ..., -0.5267, -0.1729, -0.0543],\n",
            "        [-0.1592,  0.0631,  0.0846,  ..., -0.1043,  0.0602,  0.1148],\n",
            "        [-0.1235,  0.4267,  0.2803,  ..., -0.0313,  0.0543,  0.0502]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([6, 2, 9, 7, 7, 3, 2, 5, 1, 6, 3, 5, 5, 2, 1, 0, 3, 2, 6, 2, 3, 8, 8, 9,\n",
            "        1, 0, 4, 8, 5, 0, 8, 1, 2, 7, 7, 5, 0, 5, 7, 9, 4, 4, 0, 2, 6, 0, 5, 1,\n",
            "        0, 3, 3, 8, 0, 3, 6, 6, 8, 0, 0, 6, 7, 7, 9, 5, 1, 1, 1, 1, 0, 3, 8, 1,\n",
            "        5, 6, 0, 4, 9, 1, 6, 4, 1, 3, 7, 7, 9, 8, 4, 0, 1, 3, 5, 9, 0, 2, 8, 5,\n",
            "        8, 2, 9, 4, 9, 0, 3, 9, 1, 3, 2, 4, 3, 1, 7, 1, 0, 7, 4, 0, 4, 2, 4, 8,\n",
            "        0, 2, 6, 9, 5, 1, 5, 3, 5, 0, 3, 7, 7, 1, 7, 8, 1, 0, 0, 3, 7, 9, 7, 0,\n",
            "        8, 4, 2, 4, 1, 4, 3, 0, 8, 4, 6, 9, 9, 5, 3, 8, 4, 4, 0, 8, 3, 8, 0, 1,\n",
            "        7, 6, 1, 1, 1, 2, 8, 4, 7, 1, 1, 1, 2, 0, 0, 5, 5, 7, 2, 9, 6, 6, 5, 4,\n",
            "        2, 7, 9, 2, 4, 9, 6, 4, 3, 8, 9, 3, 6, 6, 3, 8, 2, 1, 9, 7, 9, 6, 5, 4,\n",
            "        2, 0, 3, 9, 6, 0, 1, 7, 6, 1, 4, 9, 7, 4, 2, 0, 2, 0, 6, 4, 0, 8, 6, 5,\n",
            "        4, 7, 9, 3, 9, 5, 4, 6, 7, 8, 8, 8, 3, 8, 2, 3, 6, 7, 3, 7, 5, 6, 0, 3,\n",
            "        3, 9, 8, 9, 4, 5, 2, 4, 9, 2, 6, 1, 4, 3, 7, 5, 1, 4, 3, 7, 3, 1, 0, 0,\n",
            "        3, 1, 2, 8, 0, 0, 0, 2, 9, 2, 4, 1])\n",
            "tensor([[-2.1332e-01,  3.8584e-03,  2.4112e-04,  ...,  1.4944e-01,\n",
            "          6.0060e-02,  9.1983e-02],\n",
            "        [-3.2334e-02,  7.0338e-02,  2.2760e-01,  ..., -1.9540e-01,\n",
            "         -9.6330e-02,  5.0340e-03],\n",
            "        [-3.7071e-02,  2.2534e-02,  4.1054e-01,  ..., -3.3360e-01,\n",
            "         -1.8315e-01, -4.5339e-02],\n",
            "        ...,\n",
            "        [ 4.1219e-02, -1.2787e-01,  3.6094e-01,  ..., -3.2703e-01,\n",
            "         -1.0244e-01,  3.9878e-02],\n",
            "        [-5.5695e-02,  6.7880e-02,  2.6014e-02,  ..., -8.9628e-02,\n",
            "          2.0129e-02,  5.8053e-02],\n",
            "        [-2.1666e-01,  1.6131e-01, -8.3100e-02,  ...,  6.5138e-02,\n",
            "          6.5758e-02,  5.9234e-02]], grad_fn=<AddmmBackward>)\n",
            "tensor([5, 0, 6, 7, 5, 8, 3, 9, 9, 8, 1, 3, 3, 5, 9, 6, 5, 2, 0, 5, 9, 3, 5, 0,\n",
            "        2, 0, 0, 8, 1, 1, 6, 7, 0, 8, 4, 6, 2, 6, 4, 9, 4, 7, 2, 9, 1, 2, 3, 9,\n",
            "        9, 7, 0, 7, 6, 4, 2, 5, 8, 0, 1, 7, 2, 2, 6, 5, 1, 8, 3, 0, 2, 8, 1, 4,\n",
            "        3, 0, 0, 9, 0, 6, 7, 8, 8, 6, 4, 3, 0, 0, 2, 1, 3, 3, 4, 0, 1, 2, 1, 5,\n",
            "        6, 4, 2, 2, 1, 1, 6, 0, 6, 6, 9, 7, 6, 7, 8, 0, 1, 6, 2, 7, 6, 3, 0, 9,\n",
            "        0, 7, 4, 1, 7, 4, 3, 4, 6, 6, 5, 8, 4, 6, 8, 5, 0, 5, 4, 5, 2, 5, 7, 4,\n",
            "        3, 5, 3, 4, 3, 9, 3, 7, 5, 3, 3, 7, 0, 7, 5, 5, 3, 6, 4, 7, 0, 2, 9, 8,\n",
            "        3, 8, 9, 6, 2, 0, 9, 1, 9, 1, 1, 6, 9, 8, 8, 2, 9, 5, 4, 3, 9, 9, 8, 4,\n",
            "        9, 9, 0, 3, 8, 9, 1, 9, 6, 7, 7, 6, 1, 7, 3, 6, 6, 9, 7, 5, 3, 7, 3, 4,\n",
            "        7, 2, 0, 8, 9, 8, 2, 5, 3, 6, 9, 0, 7, 0, 6, 8, 0, 9, 9, 7, 8, 1, 5, 8,\n",
            "        1, 9, 8, 5, 2, 3, 9, 0, 0, 9, 5, 0, 0, 0, 6, 0, 6, 5, 7, 9, 6, 5, 5, 9,\n",
            "        5, 5, 4, 9, 4, 1, 9, 3, 8, 7, 2, 1, 4, 6, 2, 8, 5, 5, 1, 3, 7, 1, 4, 8,\n",
            "        9, 5, 0, 4, 2, 3, 4, 6, 5, 0, 2, 7])\n",
            "tensor([[-0.1791,  0.1491, -0.1442,  ...,  0.2369, -0.0143,  0.1589],\n",
            "        [ 0.0080, -0.1768,  0.6507,  ..., -0.6272, -0.1678, -0.0540],\n",
            "        [ 0.0040, -0.0236,  0.3291,  ..., -0.3247, -0.0130,  0.1010],\n",
            "        ...,\n",
            "        [-0.2761,  0.0512, -0.0487,  ...,  0.1717,  0.3529,  0.2314],\n",
            "        [-0.1146,  0.1274,  0.1874,  ..., -0.0967,  0.0863,  0.0739],\n",
            "        [ 0.0551, -0.0567,  0.5802,  ..., -0.5619, -0.1648, -0.0280]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([7, 6, 6, 7, 2, 3, 8, 7, 9, 1, 3, 3, 3, 9, 5, 9, 8, 0, 5, 4, 9, 5, 2, 5,\n",
            "        8, 4, 8, 7, 7, 1, 6, 2, 9, 5, 1, 6, 5, 6, 3, 6, 3, 3, 1, 3, 8, 8, 0, 2,\n",
            "        5, 3, 1, 0, 9, 4, 5, 3, 4, 0, 3, 5, 7, 4, 1, 2, 3, 0, 8, 7, 4, 4, 0, 6,\n",
            "        4, 6, 5, 6, 3, 1, 2, 4, 4, 0, 7, 3, 9, 7, 6, 1, 0, 8, 0, 6, 1, 1, 6, 5,\n",
            "        3, 8, 2, 4, 5, 3, 7, 9, 0, 0, 6, 9, 3, 4, 6, 9, 9, 6, 0, 7, 4, 8, 4, 6,\n",
            "        4, 3, 3, 6, 9, 0, 5, 5, 4, 3, 5, 8, 8, 6, 4, 0, 2, 4, 9, 0, 6, 6, 2, 2,\n",
            "        2, 4, 5, 9, 1, 6, 1, 2, 8, 0, 6, 0, 3, 4, 2, 8, 4, 3, 7, 2, 6, 6, 1, 7,\n",
            "        7, 5, 9, 9, 2, 9, 9, 6, 2, 9, 0, 9, 4, 6, 5, 1, 6, 2, 5, 5, 0, 2, 9, 5,\n",
            "        5, 9, 9, 2, 4, 2, 1, 7, 0, 1, 6, 7, 2, 2, 8, 6, 5, 4, 8, 8, 9, 3, 5, 9,\n",
            "        0, 8, 0, 5, 4, 6, 1, 5, 1, 2, 6, 3, 5, 9, 2, 6, 6, 3, 5, 9, 4, 9, 1, 4,\n",
            "        5, 2, 7, 5, 3, 9, 2, 5, 4, 8, 0, 1, 2, 6, 0, 5, 8, 1, 6, 9, 5, 6, 2, 0,\n",
            "        6, 4, 0, 1, 6, 0, 4, 5, 9, 7, 3, 4, 9, 7, 0, 7, 6, 8, 6, 2, 2, 3, 0, 8,\n",
            "        3, 8, 9, 2, 6, 6, 4, 9, 3, 9, 4, 2])\n",
            "tensor([[-0.1099,  0.1590,  0.3985,  ..., -0.2998, -0.1726, -0.0318],\n",
            "        [-0.2200,  0.0934, -0.0331,  ...,  0.2291,  0.1541,  0.1705],\n",
            "        [-0.0548, -0.2304,  0.2948,  ..., -0.1458,  0.2766,  0.2455],\n",
            "        ...,\n",
            "        [-0.0731,  0.1692,  0.2133,  ..., -0.1857,  0.0086,  0.1031],\n",
            "        [-0.0167,  0.0415,  0.1724,  ..., -0.2332, -0.0373,  0.0140],\n",
            "        [-0.0417, -0.0072,  0.4787,  ..., -0.4991, -0.1697, -0.0112]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([3, 7, 8, 4, 9, 9, 7, 6, 1, 3, 9, 3, 7, 8, 9, 8, 1, 8, 4, 8, 9, 4, 3, 8,\n",
            "        9, 0, 3, 1, 9, 0, 9, 7, 3, 8, 3, 5, 3, 8, 3, 5, 9, 6, 8, 5, 6, 9, 1, 6,\n",
            "        7, 2, 8, 0, 6, 3, 8, 1, 7, 0, 6, 2, 9, 8, 2, 9, 4, 5, 4, 1, 8, 3, 5, 7,\n",
            "        0, 1, 9, 4, 5, 3, 1, 8, 5, 8, 2, 3, 0, 5, 4, 9, 3, 7, 2, 6, 0, 5, 6, 5,\n",
            "        9, 8, 0, 9, 7, 2, 3, 5, 1, 2, 2, 4, 6, 0, 3, 2, 7, 2, 0, 1, 1, 5, 4, 2,\n",
            "        9, 9, 6, 1, 2, 1, 7, 9, 1, 6, 3, 2, 3, 4, 0, 4, 9, 3, 5, 4, 2, 4, 6, 5,\n",
            "        9, 5, 1, 4, 7, 4, 6, 6, 4, 0, 1, 5, 6, 8, 6, 5, 7, 0, 3, 6, 9, 6, 2, 8,\n",
            "        5, 3, 6, 1, 4, 6, 3, 4, 5, 3, 1, 3, 6, 7, 3, 4, 3, 9, 4, 8, 4, 0, 3, 0,\n",
            "        9, 7, 4, 2, 7, 7, 0, 7, 4, 4, 6, 2, 1, 8, 3, 8, 9, 7, 6, 2, 5, 4, 8, 3,\n",
            "        9, 7, 4, 0, 6, 1, 7, 7, 1, 5, 9, 1, 9, 5, 8, 8, 9, 6, 1, 1, 5, 3, 5, 3,\n",
            "        9, 1, 9, 7, 3, 0, 1, 8, 6, 5, 5, 4, 9, 2, 7, 7, 1, 5, 6, 4, 1, 2, 2, 6,\n",
            "        6, 8, 0, 5, 4, 5, 2, 3, 0, 3, 4, 3, 8, 3, 3, 1, 4, 8, 3, 1, 0, 2, 0, 1,\n",
            "        4, 7, 0, 0, 9, 0, 7, 2, 4, 4, 6, 4])\n",
            "tensor([[ 0.0105, -0.3183,  0.6546,  ..., -0.6724, -0.1572, -0.0143],\n",
            "        [-0.0181, -0.0968,  0.5827,  ..., -0.5178, -0.1057, -0.0534],\n",
            "        [ 0.0314, -0.1610,  0.5154,  ..., -0.5656, -0.1925, -0.0538],\n",
            "        ...,\n",
            "        [-0.0484, -0.2668,  0.5752,  ..., -0.6079, -0.1916, -0.0644],\n",
            "        [-0.0724,  0.3729,  0.3058,  ..., -0.1131, -0.0030, -0.0626],\n",
            "        [-0.2130,  0.0703, -0.1093,  ...,  0.0401,  0.0937,  0.0785]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([6, 2, 2, 7, 9, 7, 9, 6, 5, 5, 0, 4, 5, 0, 0, 9, 2, 2, 5, 6, 7, 8, 9, 0,\n",
            "        4, 3, 9, 6, 6, 2, 4, 4, 2, 7, 2, 4, 9, 5, 1, 0, 7, 6, 2, 5, 5, 5, 6, 2,\n",
            "        9, 7, 1, 5, 6, 0, 3, 3, 9, 0, 9, 2, 1, 7, 5, 1, 4, 4, 5, 3, 0, 5, 1, 3,\n",
            "        2, 8, 2, 0, 1, 7, 6, 2, 8, 8, 8, 4, 7, 1, 5, 0, 1, 0, 9, 8, 6, 1, 1, 2,\n",
            "        5, 6, 0, 6, 2, 0, 0, 6, 1, 7, 8, 0, 1, 5, 8, 4, 9, 8, 5, 7, 8, 4, 7, 8,\n",
            "        6, 6, 6, 2, 0, 0, 1, 7, 7, 3, 7, 7, 1, 6, 4, 3, 4, 6, 3, 9, 3, 1, 8, 9,\n",
            "        8, 2, 2, 1, 6, 7, 5, 0, 9, 3, 4, 4, 5, 5, 8, 2, 3, 1, 6, 9, 2, 3, 6, 4,\n",
            "        6, 9, 9, 5, 4, 4, 9, 0, 0, 3, 8, 0, 0, 4, 4, 6, 6, 7, 1, 1, 9, 5, 6, 3,\n",
            "        8, 9, 7, 3, 1, 4, 3, 8, 3, 1, 5, 2, 7, 0, 9, 8, 5, 9, 1, 2, 7, 5, 3, 1,\n",
            "        0, 8, 7, 0, 4, 3, 8, 7, 4, 5, 7, 2, 0, 3, 1, 3, 1, 0, 7, 8, 5, 6, 8, 3,\n",
            "        5, 9, 9, 1, 4, 5, 7, 3, 7, 5, 7, 9, 5, 5, 6, 9, 6, 8, 6, 3, 3, 7, 4, 2,\n",
            "        0, 0, 8, 1, 6, 5, 6, 7, 0, 7, 3, 9, 0, 1, 8, 0, 8, 4, 1, 1, 3, 2, 2, 5,\n",
            "        0, 2, 8, 2, 3, 2, 1, 2, 7, 4, 1, 5])\n",
            "tensor([[-0.2403,  0.0377, -0.1576,  ...,  0.0728,  0.2650,  0.2523],\n",
            "        [-0.0492, -0.1338,  0.3932,  ..., -0.4533, -0.0242,  0.0322],\n",
            "        [ 0.1313, -0.0864,  0.4365,  ..., -0.3963, -0.2770,  0.0357],\n",
            "        ...,\n",
            "        [-0.1893,  0.0574,  0.0239,  ..., -0.0141,  0.0009,  0.0619],\n",
            "        [-0.0651,  0.3299,  0.3076,  ..., -0.1308, -0.0799, -0.0274],\n",
            "        [-0.2986,  0.0891, -0.1071,  ...,  0.4272,  0.3691,  0.2360]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([9, 4, 0, 6, 8, 8, 8, 0, 0, 3, 2, 7, 1, 1, 9, 9, 9, 2, 4, 2, 2, 5, 6, 8,\n",
            "        6, 5, 9, 8, 7, 3, 6, 9, 3, 9, 1, 9, 7, 5, 5, 4, 9, 4, 0, 1, 6, 1, 2, 6,\n",
            "        1, 9, 1, 6, 2, 2, 5, 1, 4, 4, 1, 5, 6, 3, 9, 1, 1, 6, 2, 6, 6, 9, 6, 6,\n",
            "        0, 0, 8, 9, 0, 1, 1, 2, 2, 8, 8, 9, 0, 0, 3, 0, 9, 5, 7, 1, 0, 9, 3, 9,\n",
            "        7, 2, 4, 7, 2, 1, 4, 9, 7, 8, 3, 1, 7, 5, 0, 0, 6, 0, 3, 5, 6, 5, 4, 9,\n",
            "        2, 3, 3, 6, 9, 0, 4, 1, 1, 3, 8, 8, 9, 5, 1, 1, 8, 4, 8, 9, 4, 6, 4, 2,\n",
            "        7, 7, 9, 2, 9, 1, 3, 4, 7, 1, 1, 1, 1, 4, 4, 1, 1, 6, 0, 4, 9, 6, 2, 9,\n",
            "        5, 2, 9, 2, 5, 0, 2, 8, 5, 4, 9, 2, 1, 3, 1, 0, 3, 6, 2, 3, 4, 7, 5, 1,\n",
            "        6, 9, 4, 5, 3, 0, 5, 2, 8, 4, 6, 3, 9, 0, 1, 7, 9, 1, 2, 3, 3, 3, 4, 7,\n",
            "        2, 0, 2, 9, 3, 8, 7, 7, 0, 5, 0, 1, 6, 5, 0, 1, 0, 6, 4, 1, 3, 8, 1, 2,\n",
            "        5, 9, 7, 5, 6, 3, 8, 2, 6, 5, 6, 2, 2, 9, 4, 3, 4, 6, 3, 8, 6, 2, 4, 4,\n",
            "        2, 6, 9, 1, 2, 7, 3, 3, 1, 1, 6, 1, 3, 8, 1, 2, 2, 5, 1, 3, 7, 5, 8, 1,\n",
            "        9, 7, 4, 8, 1, 3, 9, 5, 7, 5, 1, 9])\n",
            "tensor([[-0.1055, -0.2563,  0.3038,  ..., -0.1386,  0.3730,  0.3131],\n",
            "        [ 0.0380, -0.1863,  0.5972,  ..., -0.5767, -0.2210, -0.0607],\n",
            "        [-0.1587,  0.1014,  0.1560,  ..., -0.1261, -0.0891, -0.0120],\n",
            "        ...,\n",
            "        [ 0.2005, -0.1052,  0.3403,  ..., -0.4161, -0.1560,  0.0728],\n",
            "        [ 0.0286, -0.0475,  0.6319,  ..., -0.5749, -0.1041,  0.0530],\n",
            "        [-0.0858, -0.0806,  0.5717,  ..., -0.5961, -0.1197,  0.0271]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([8, 4, 3, 2, 2, 0, 6, 9, 5, 9, 2, 6, 0, 9, 9, 4, 2, 9, 1, 3, 3, 2, 9, 5,\n",
            "        6, 4, 1, 4, 6, 1, 1, 1, 6, 6, 2, 1, 5, 0, 8, 4, 6, 3, 8, 0, 7, 6, 4, 7,\n",
            "        9, 2, 1, 5, 7, 6, 6, 9, 5, 5, 4, 0, 2, 2, 7, 3, 8, 3, 8, 1, 2, 4, 8, 4,\n",
            "        4, 9, 9, 7, 1, 8, 4, 1, 1, 5, 0, 3, 9, 3, 6, 8, 0, 0, 1, 7, 2, 3, 6, 7,\n",
            "        0, 4, 4, 6, 9, 1, 4, 2, 2, 5, 6, 9, 6, 6, 5, 3, 8, 2, 7, 2, 8, 5, 7, 0,\n",
            "        6, 9, 4, 0, 5, 7, 8, 4, 0, 8, 8, 3, 0, 8, 0, 0, 5, 7, 1, 9, 8, 7, 7, 9,\n",
            "        5, 2, 7, 4, 2, 0, 8, 7, 6, 4, 5, 7, 8, 8, 9, 0, 8, 6, 1, 6, 6, 4, 9, 8,\n",
            "        8, 6, 8, 3, 5, 6, 0, 9, 2, 8, 2, 2, 0, 7, 1, 2, 4, 1, 3, 4, 0, 1, 7, 9,\n",
            "        9, 4, 1, 5, 1, 4, 2, 4, 0, 6, 9, 5, 1, 8, 5, 8, 7, 1, 2, 6, 3, 3, 3, 7,\n",
            "        1, 1, 7, 1, 3, 8, 9, 5, 6, 3, 8, 0, 6, 7, 4, 9, 3, 3, 3, 7, 3, 5, 1, 3,\n",
            "        8, 5, 7, 5, 9, 3, 2, 1, 1, 4, 4, 7, 9, 9, 5, 2, 8, 5, 5, 3, 2, 0, 0, 7,\n",
            "        4, 4, 0, 8, 5, 9, 4, 0, 9, 2, 3, 9, 5, 0, 8, 9, 5, 8, 5, 0, 7, 8, 4, 7,\n",
            "        9, 6, 4, 6, 0, 2, 5, 0, 5, 0, 4, 2])\n",
            "tensor([[-0.0819,  0.0745,  0.0105,  ..., -0.0783,  0.0383,  0.0441],\n",
            "        [ 0.0986, -0.1080,  0.5762,  ..., -0.5237, -0.1645, -0.1016],\n",
            "        [-0.2657,  0.0458, -0.1313,  ...,  0.3108,  0.2854,  0.1655],\n",
            "        ...,\n",
            "        [-0.2750,  0.1124, -0.2120,  ...,  0.3969,  0.1795,  0.2328],\n",
            "        [ 0.0686, -0.1269,  0.4115,  ..., -0.3025, -0.1159,  0.0291],\n",
            "        [-0.0932,  0.0270,  0.2164,  ..., -0.3490, -0.0166, -0.0411]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([6, 2, 7, 0, 7, 0, 7, 7, 3, 0, 3, 8, 6, 3, 2, 4, 4, 3, 3, 9, 5, 8, 3, 0,\n",
            "        2, 8, 5, 6, 3, 3, 9, 3, 2, 7, 7, 5, 9, 2, 3, 1, 4, 5, 4, 9, 7, 0, 4, 5,\n",
            "        1, 0, 3, 6, 8, 9, 2, 1, 8, 8, 8, 3, 2, 8, 1, 0, 1, 6, 2, 9, 8, 4, 3, 3,\n",
            "        4, 8, 5, 7, 2, 0, 1, 5, 9, 5, 7, 6, 9, 2, 5, 3, 2, 5, 1, 5, 7, 1, 7, 2,\n",
            "        1, 4, 0, 6, 8, 8, 0, 6, 8, 1, 3, 9, 5, 4, 7, 2, 7, 7, 0, 8, 7, 4, 0, 2,\n",
            "        9, 9, 0, 3, 1, 3, 5, 9, 4, 6, 5, 8, 1, 3, 6, 1, 1, 7, 6, 0, 4, 3, 9, 1,\n",
            "        4, 3, 9, 3, 1, 8, 3, 3, 4, 5, 8, 5, 3, 1, 0, 6, 3, 4, 7, 0, 0, 0, 4, 7,\n",
            "        8, 0, 4, 0, 0, 2, 8, 9, 4, 3, 2, 8, 7, 9, 7, 9, 3, 9, 5, 0, 8, 7, 3, 6,\n",
            "        0, 8, 9, 9, 8, 1, 4, 0, 5, 9, 2, 9, 7, 2, 1, 8, 9, 4, 6, 1, 4, 0, 1, 0,\n",
            "        4, 5, 3, 7, 4, 3, 8, 7, 9, 4, 0, 5, 4, 3, 9, 9, 6, 7, 9, 6, 8, 6, 3, 3,\n",
            "        8, 6, 5, 7, 4, 5, 5, 3, 9, 0, 2, 9, 0, 8, 2, 3, 6, 8, 1, 3, 6, 9, 8, 6,\n",
            "        5, 8, 1, 5, 3, 7, 9, 0, 0, 4, 5, 4, 8, 1, 4, 1, 2, 1, 8, 9, 6, 7, 6, 8,\n",
            "        8, 4, 9, 2, 8, 9, 2, 6, 0, 7, 0, 6])\n",
            "tensor([[-0.2703, -0.2303,  0.0580,  ..., -0.1482, -0.1179,  0.1852],\n",
            "        [ 0.0425, -0.2968,  0.7154,  ..., -0.6032, -0.0441,  0.0940],\n",
            "        [-0.1343,  0.4387,  0.3293,  ..., -0.1678, -0.0703, -0.1058],\n",
            "        ...,\n",
            "        [-0.0926, -0.0458,  0.3297,  ..., -0.3656, -0.0294, -0.0377],\n",
            "        [-0.1442,  0.0827, -0.0536,  ...,  0.0283,  0.1550,  0.1558],\n",
            "        [ 0.0047,  0.1072,  0.0571,  ..., -0.1064,  0.0085,  0.0905]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([9, 4, 1, 2, 4, 5, 5, 6, 1, 6, 8, 9, 8, 4, 3, 5, 9, 0, 9, 2, 7, 7, 0, 3,\n",
            "        5, 6, 0, 4, 8, 8, 6, 1, 3, 6, 7, 3, 6, 8, 3, 8, 5, 5, 4, 2, 7, 0, 1, 8,\n",
            "        9, 3, 4, 6, 8, 6, 5, 5, 7, 8, 9, 3, 8, 9, 1, 0, 0, 1, 3, 2, 1, 8, 8, 5,\n",
            "        3, 9, 3, 1, 0, 9, 2, 8, 1, 0, 2, 8, 6, 1, 8, 9, 3, 7, 0, 4, 3, 1, 5, 2,\n",
            "        7, 2, 4, 7, 2, 8, 0, 0, 3, 5, 7, 2, 3, 2, 5, 6, 4, 8, 0, 3, 2, 3, 3, 5,\n",
            "        5, 3, 4, 2, 3, 1, 5, 6, 6, 5, 2, 8, 0, 9, 4, 0, 2, 8, 4, 4, 1, 7, 1, 3,\n",
            "        6, 0, 7, 0, 4, 9, 7, 7, 5, 9, 8, 1, 8, 8, 4, 5, 2, 5, 7, 1, 2, 1, 5, 8,\n",
            "        8, 4, 5, 2, 6, 4, 4, 2, 0, 3, 4, 9, 6, 7, 8, 8, 9, 0, 8, 9, 2, 4, 7, 5,\n",
            "        9, 6, 3, 0, 2, 7, 2, 8, 5, 5, 0, 6, 4, 4, 8, 8, 7, 6, 1, 5, 1, 4, 4, 1,\n",
            "        4, 5, 2, 6, 2, 4, 9, 4, 6, 6, 6, 6, 0, 2, 7, 2, 4, 2, 9, 0, 7, 7, 1, 6,\n",
            "        8, 2, 1, 2, 7, 1, 3, 6, 9, 5, 4, 2, 8, 9, 9, 5, 4, 0, 3, 9, 9, 4, 9, 4,\n",
            "        3, 2, 5, 3, 7, 9, 3, 1, 4, 4, 4, 6, 6, 2, 7, 9, 5, 7, 0, 5, 4, 9, 7, 9,\n",
            "        0, 1, 8, 1, 6, 9, 3, 2, 6, 4, 5, 0])\n",
            "tensor([[ 0.0810, -0.1369,  0.5228,  ..., -0.5562, -0.1188, -0.0049],\n",
            "        [-0.0590,  0.1080,  0.0321,  ..., -0.0789,  0.0253,  0.0184],\n",
            "        [-0.1752, -0.0450,  0.0803,  ..., -0.2038, -0.0018,  0.3349],\n",
            "        ...,\n",
            "        [ 0.0412,  0.0800,  0.2279,  ..., -0.2656, -0.1889, -0.0369],\n",
            "        [ 0.0767, -0.1415,  0.2717,  ..., -0.3684, -0.0561,  0.1174],\n",
            "        [-0.2209, -0.0653, -0.1019,  ...,  0.0987,  0.3476,  0.3835]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([2, 0, 9, 3, 7, 0, 2, 7, 6, 5, 7, 8, 8, 3, 2, 5, 5, 1, 3, 0, 3, 5, 9, 3,\n",
            "        6, 1, 6, 7, 2, 2, 4, 3, 4, 6, 0, 7, 0, 4, 8, 7, 9, 4, 8, 4, 1, 2, 9, 8,\n",
            "        5, 1, 8, 9, 7, 2, 2, 2, 5, 9, 5, 2, 7, 9, 8, 4, 2, 6, 2, 8, 9, 0, 7, 0,\n",
            "        8, 2, 1, 3, 4, 7, 7, 4, 5, 4, 3, 0, 9, 1, 0, 2, 9, 1, 4, 4, 5, 2, 3, 4,\n",
            "        7, 1, 0, 8, 6, 0, 5, 9, 7, 6, 6, 7, 1, 4, 3, 5, 5, 8, 0, 9, 6, 2, 1, 6,\n",
            "        6, 7, 0, 7, 1, 3, 8, 8, 7, 7, 2, 7, 6, 5, 8, 5, 1, 0, 6, 0, 4, 3, 7, 1,\n",
            "        4, 5, 5, 2, 0, 5, 0, 9, 4, 4, 1, 7, 8, 7, 5, 0, 9, 3, 2, 0, 9, 1, 6, 7,\n",
            "        9, 2, 2, 4, 6, 5, 0, 7, 2, 6, 2, 3, 4, 8, 9, 2, 6, 0, 2, 8, 5, 5, 7, 2,\n",
            "        3, 1, 9, 2, 2, 7, 8, 5, 9, 7, 3, 8, 3, 1, 5, 1, 6, 4, 9, 6, 4, 0, 4, 1,\n",
            "        6, 8, 2, 0, 8, 0, 3, 0, 8, 2, 5, 4, 0, 8, 6, 2, 4, 3, 1, 1, 9, 1, 5, 9,\n",
            "        4, 8, 1, 9, 0, 8, 0, 0, 7, 7, 7, 3, 2, 9, 5, 2, 4, 4, 9, 2, 4, 4, 7, 0,\n",
            "        7, 2, 8, 4, 4, 7, 8, 4, 6, 0, 2, 2, 5, 5, 0, 0, 9, 9, 6, 1, 1, 5, 1, 8,\n",
            "        0, 3, 6, 4, 4, 9, 4, 0, 2, 3, 0, 9])\n",
            "tensor([[-0.1451,  0.0766, -0.0215,  ...,  0.1457,  0.0606,  0.1257],\n",
            "        [-0.1089,  0.4348,  0.3191,  ..., -0.1572, -0.0655, -0.0434],\n",
            "        [ 0.0926, -0.1382,  0.5612,  ..., -0.5863, -0.1631, -0.0649],\n",
            "        ...,\n",
            "        [ 0.0796, -0.2100,  0.7589,  ..., -0.7809, -0.0457, -0.0529],\n",
            "        [-0.2902,  0.0195, -0.1334,  ...,  0.2116,  0.3924,  0.4358],\n",
            "        [-0.1862,  0.1202, -0.0879,  ...,  0.0742,  0.0731,  0.0918]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([5, 1, 2, 5, 8, 8, 8, 4, 8, 1, 6, 2, 2, 3, 1, 4, 8, 3, 0, 4, 2, 1, 5, 2,\n",
            "        1, 8, 5, 6, 6, 8, 0, 7, 7, 1, 6, 8, 4, 3, 5, 4, 0, 2, 6, 8, 3, 4, 0, 9,\n",
            "        0, 1, 9, 8, 5, 4, 7, 3, 0, 7, 1, 1, 1, 8, 1, 6, 0, 8, 7, 3, 1, 7, 4, 3,\n",
            "        0, 8, 3, 1, 8, 8, 2, 8, 7, 5, 1, 7, 3, 9, 2, 0, 3, 7, 6, 3, 9, 9, 1, 2,\n",
            "        5, 2, 1, 8, 9, 7, 3, 1, 5, 5, 0, 6, 4, 6, 1, 5, 3, 2, 7, 3, 4, 1, 2, 9,\n",
            "        7, 5, 8, 6, 6, 1, 9, 8, 3, 9, 5, 5, 9, 9, 9, 3, 5, 2, 0, 0, 3, 0, 9, 2,\n",
            "        2, 5, 3, 9, 0, 8, 1, 5, 8, 9, 0, 0, 9, 6, 1, 3, 0, 9, 7, 9, 9, 4, 4, 5,\n",
            "        7, 1, 6, 2, 6, 7, 8, 8, 4, 5, 6, 4, 7, 3, 7, 7, 1, 2, 0, 7, 0, 9, 9, 6,\n",
            "        1, 2, 1, 0, 8, 3, 5, 2, 7, 5, 3, 5, 1, 8, 9, 1, 5, 4, 5, 9, 2, 5, 5, 0,\n",
            "        2, 3, 6, 3, 8, 5, 4, 0, 9, 8, 7, 4, 4, 6, 0, 2, 1, 1, 0, 8, 3, 1, 6, 3,\n",
            "        7, 7, 9, 2, 3, 3, 2, 1, 9, 7, 3, 6, 5, 6, 3, 9, 2, 8, 4, 8, 1, 8, 5, 3,\n",
            "        0, 5, 8, 6, 1, 2, 9, 1, 8, 1, 5, 1, 8, 8, 6, 0, 7, 2, 0, 5, 7, 5, 2, 4,\n",
            "        0, 1, 9, 6, 3, 9, 0, 5, 1, 4, 9, 5])\n",
            "tensor([[-0.1980, -0.3689,  0.4365,  ..., -0.4497,  0.0400,  0.1254],\n",
            "        [ 0.1570, -0.0650,  0.5228,  ..., -0.4501, -0.0822, -0.0576],\n",
            "        [-0.2485,  0.1191, -0.2369,  ...,  0.2826,  0.0286,  0.1174],\n",
            "        ...,\n",
            "        [-0.0836,  0.5637,  0.2630,  ..., -0.1155,  0.0804, -0.0125],\n",
            "        [ 0.0036, -0.1034,  0.5651,  ..., -0.6251, -0.0084, -0.1050],\n",
            "        [-0.0367,  0.3583,  0.3843,  ..., -0.3064, -0.1557, -0.0084]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([8, 0, 7, 5, 2, 7, 6, 2, 1, 2, 3, 5, 5, 2, 3, 7, 2, 8, 8, 4, 0, 4, 5, 0,\n",
            "        3, 2, 9, 2, 8, 6, 1, 9, 3, 7, 3, 5, 5, 2, 1, 0, 5, 0, 0, 1, 1, 2, 5, 9,\n",
            "        2, 8, 0, 1, 7, 3, 7, 7, 3, 5, 8, 1, 4, 3, 0, 1, 9, 5, 0, 1, 3, 1, 6, 6,\n",
            "        1, 6, 1, 9, 3, 6, 3, 4, 4, 6, 3, 7, 2, 9, 1, 6, 4, 6, 0, 4, 4, 0, 0, 9,\n",
            "        4, 3, 8, 5, 3, 9, 7, 8, 1, 1, 0, 4, 7, 7, 8, 3, 6, 6, 1, 1, 1, 5, 8, 6,\n",
            "        1, 4, 3, 6, 6, 5, 8, 0, 7, 5, 5, 1, 0, 5, 6, 8, 1, 6, 1, 1, 1, 1, 9, 1,\n",
            "        5, 4, 1, 6, 9, 0, 8, 2, 9, 8, 3, 7, 8, 7, 2, 0, 0, 4, 6, 8, 8, 6, 4, 3,\n",
            "        4, 7, 4, 5, 0, 2, 9, 9, 9, 1, 8, 6, 5, 0, 7, 6, 9, 6, 4, 1, 4, 3, 0, 1,\n",
            "        0, 7, 3, 7, 4, 3, 2, 4, 0, 6, 6, 2, 2, 8, 4, 4, 8, 6, 1, 6, 0, 2, 3, 2,\n",
            "        5, 1, 1, 5, 8, 9, 3, 3, 0, 0, 7, 8, 9, 0, 1, 7, 3, 2, 3, 9, 5, 2, 1, 6,\n",
            "        0, 3, 1, 1, 9, 0, 2, 9, 2, 9, 0, 2, 7, 1, 8, 2, 1, 5, 8, 2, 0, 8, 7, 7,\n",
            "        5, 6, 5, 0, 9, 0, 5, 3, 5, 5, 7, 3, 5, 0, 4, 5, 7, 5, 7, 9, 8, 8, 4, 5,\n",
            "        1, 4, 9, 9, 0, 6, 3, 0, 9, 1, 2, 3])\n",
            "tensor([[ 0.0507, -0.1621,  0.7414,  ..., -0.6936,  0.0316, -0.0272],\n",
            "        [-0.2509,  0.0909, -0.2083,  ...,  0.3992,  0.0848,  0.1873],\n",
            "        [-0.1057, -0.1277,  0.1656,  ..., -0.2631,  0.2825,  0.1872],\n",
            "        ...,\n",
            "        [-0.3414,  0.0058, -0.3165,  ...,  0.6007,  0.4808,  0.3707],\n",
            "        [ 0.0364, -0.0651,  0.5268,  ..., -0.5395, -0.0397, -0.0427],\n",
            "        [-0.1302,  0.1693,  0.1042,  ..., -0.1766, -0.0289, -0.0630]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([2, 7, 8, 2, 0, 7, 2, 6, 7, 5, 8, 2, 2, 4, 9, 2, 8, 7, 7, 9, 9, 7, 8, 6,\n",
            "        0, 4, 1, 7, 6, 4, 6, 1, 2, 3, 7, 4, 1, 4, 8, 9, 4, 8, 9, 3, 0, 2, 8, 8,\n",
            "        0, 5, 7, 9, 7, 8, 2, 7, 6, 1, 9, 2, 9, 6, 0, 7, 7, 4, 5, 0, 2, 0, 0, 1,\n",
            "        9, 0, 8, 1, 4, 2, 3, 0, 8, 6, 1, 1, 6, 9, 6, 3, 9, 8, 3, 8, 7, 6, 3, 1,\n",
            "        4, 2, 8, 5, 3, 6, 3, 9, 6, 8, 2, 2, 5, 5, 0, 8, 4, 3, 6, 5, 3, 2, 5, 7,\n",
            "        3, 7, 2, 4, 3, 3, 5, 6, 9, 6, 2, 3, 0, 2, 1, 8, 1, 9, 0, 4, 7, 0, 1, 1,\n",
            "        2, 2, 8, 2, 4, 3, 1, 9, 3, 6, 9, 7, 1, 2, 1, 5, 7, 5, 2, 8, 7, 7, 2, 9,\n",
            "        2, 6, 4, 0, 1, 9, 3, 4, 7, 0, 3, 2, 1, 7, 4, 8, 7, 4, 5, 6, 5, 8, 1, 7,\n",
            "        5, 4, 8, 3, 4, 7, 2, 2, 4, 1, 1, 5, 5, 3, 2, 1, 7, 0, 5, 3, 7, 8, 6, 6,\n",
            "        4, 4, 9, 4, 4, 7, 6, 7, 6, 2, 0, 9, 4, 1, 9, 4, 7, 0, 8, 9, 9, 7, 3, 4,\n",
            "        0, 9, 7, 0, 8, 2, 6, 0, 9, 1, 8, 5, 9, 5, 3, 0, 9, 2, 1, 1, 6, 3, 2, 1,\n",
            "        6, 1, 7, 6, 8, 7, 4, 8, 5, 1, 0, 4, 2, 6, 7, 1, 1, 1, 8, 6, 3, 1, 9, 1,\n",
            "        1, 2, 2, 1, 2, 3, 3, 0, 8, 7, 4, 3])\n",
            "tensor([[ 0.1030,  0.1280,  0.2002,  ..., -0.1375, -0.0378,  0.2243],\n",
            "        [-0.0141,  0.5350,  0.4387,  ..., -0.2733, -0.0361, -0.0504],\n",
            "        [-0.0739,  0.2071,  0.3695,  ..., -0.3413, -0.1185, -0.1053],\n",
            "        ...,\n",
            "        [ 0.0770,  0.0895,  0.3668,  ..., -0.3928, -0.0447, -0.1493],\n",
            "        [-0.0888,  0.1159,  0.0666,  ..., -0.1086,  0.0629,  0.0346],\n",
            "        [ 0.1296,  0.1188,  0.4854,  ..., -0.5390, -0.1515, -0.0754]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([0, 1, 3, 7, 2, 1, 1, 1, 7, 3, 4, 7, 0, 4, 8, 9, 2, 6, 9, 4, 9, 0, 1, 6,\n",
            "        1, 6, 0, 2, 1, 4, 9, 8, 5, 0, 5, 8, 5, 5, 9, 0, 5, 1, 4, 9, 1, 7, 5, 2,\n",
            "        3, 2, 3, 5, 6, 1, 7, 4, 7, 7, 6, 1, 0, 6, 2, 1, 0, 1, 3, 0, 5, 0, 6, 8,\n",
            "        3, 8, 4, 7, 3, 4, 6, 8, 4, 0, 1, 8, 5, 2, 4, 8, 5, 1, 3, 9, 2, 5, 7, 7,\n",
            "        9, 9, 3, 0, 6, 4, 1, 7, 6, 3, 1, 9, 4, 6, 1, 5, 9, 4, 4, 3, 1, 0, 4, 4,\n",
            "        1, 7, 1, 0, 3, 6, 9, 1, 4, 3, 1, 7, 8, 9, 7, 1, 7, 5, 7, 3, 5, 1, 8, 4,\n",
            "        5, 0, 7, 2, 9, 7, 1, 6, 5, 2, 8, 2, 8, 0, 3, 8, 5, 8, 8, 8, 5, 4, 3, 3,\n",
            "        4, 3, 7, 9, 8, 7, 8, 9, 6, 9, 4, 1, 3, 3, 0, 8, 6, 4, 1, 2, 6, 7, 6, 5,\n",
            "        5, 5, 2, 7, 7, 3, 7, 7, 8, 5, 8, 0, 6, 7, 8, 0, 2, 8, 1, 9, 8, 3, 2, 0,\n",
            "        2, 9, 5, 8, 1, 4, 8, 8, 0, 5, 2, 8, 9, 7, 4, 4, 4, 3, 8, 8, 0, 4, 7, 3,\n",
            "        3, 3, 5, 5, 0, 5, 5, 4, 7, 9, 3, 0, 4, 0, 5, 3, 2, 0, 8, 2, 1, 6, 0, 4,\n",
            "        8, 6, 8, 8, 2, 4, 2, 6, 5, 8, 8, 2, 5, 9, 3, 1, 9, 6, 3, 1, 9, 9, 6, 2,\n",
            "        7, 0, 4, 5, 3, 5, 9, 6, 3, 0, 3, 4])\n",
            "tensor([[-0.0434, -0.1136,  0.2757,  ..., -0.2452,  0.3733,  0.3090],\n",
            "        [ 0.0931,  0.2339,  0.4620,  ..., -0.4605, -0.1718, -0.1335],\n",
            "        [-0.3069,  0.0289, -0.1564,  ...,  0.2900,  0.2315,  0.1926],\n",
            "        ...,\n",
            "        [ 0.0677,  0.3529,  0.2863,  ..., -0.1810, -0.0655, -0.0827],\n",
            "        [ 0.3236, -0.2140,  0.6431,  ..., -0.6784, -0.1418,  0.0186],\n",
            "        [ 0.0829, -0.1218,  0.4575,  ..., -0.4910, -0.0459,  0.0135]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([8, 3, 5, 8, 7, 8, 5, 2, 8, 3, 3, 6, 1, 5, 2, 3, 0, 4, 0, 5, 2, 5, 5, 2,\n",
            "        7, 3, 5, 0, 4, 3, 2, 6, 8, 4, 4, 1, 1, 0, 3, 4, 6, 1, 7, 8, 7, 5, 0, 1,\n",
            "        8, 9, 7, 4, 2, 8, 1, 9, 2, 2, 0, 4, 7, 4, 1, 6, 3, 7, 2, 9, 4, 8, 6, 6,\n",
            "        1, 3, 1, 8, 1, 7, 6, 5, 9, 0, 8, 0, 0, 1, 6, 1, 1, 1, 7, 4, 2, 6, 4, 2,\n",
            "        6, 0, 4, 9, 6, 2, 8, 0, 0, 7, 8, 5, 3, 0, 3, 5, 4, 5, 6, 1, 0, 3, 6, 7,\n",
            "        1, 8, 8, 1, 9, 4, 1, 8, 5, 0, 8, 1, 7, 4, 2, 2, 6, 0, 9, 2, 6, 7, 9, 9,\n",
            "        9, 3, 0, 6, 1, 7, 0, 4, 7, 1, 3, 2, 6, 2, 2, 1, 8, 4, 8, 3, 7, 3, 4, 5,\n",
            "        2, 0, 2, 3, 2, 8, 7, 2, 5, 1, 7, 3, 0, 6, 7, 8, 1, 1, 7, 1, 3, 9, 1, 8,\n",
            "        4, 0, 3, 0, 8, 9, 1, 6, 5, 4, 2, 2, 3, 2, 0, 1, 8, 3, 7, 2, 3, 8, 2, 8,\n",
            "        6, 0, 3, 8, 4, 3, 4, 6, 0, 3, 9, 0, 4, 1, 6, 8, 8, 6, 6, 1, 5, 9, 7, 5,\n",
            "        0, 7, 0, 4, 7, 9, 4, 8, 5, 1, 3, 0, 2, 0, 7, 1, 3, 7, 3, 3, 9, 8, 0, 2,\n",
            "        8, 5, 8, 0, 4, 5, 6, 7, 5, 8, 9, 1, 6, 0, 8, 9, 0, 4, 2, 5, 6, 1, 6, 6,\n",
            "        5, 0, 8, 0, 3, 3, 9, 0, 8, 3, 0, 2])\n",
            "tensor([[ 0.1296, -0.0088,  0.6670,  ..., -0.6174,  0.0452, -0.0431],\n",
            "        [ 0.1933, -0.2749,  0.7773,  ..., -0.8382, -0.1314, -0.1146],\n",
            "        [-0.2264,  0.1660, -0.2369,  ...,  0.4049,  0.1382,  0.2041],\n",
            "        ...,\n",
            "        [ 0.1633,  0.1899,  0.3367,  ..., -0.2921, -0.0329, -0.0741],\n",
            "        [ 0.1276, -0.1416,  0.7941,  ..., -0.8113, -0.0317, -0.0767],\n",
            "        [-0.1650, -0.2636,  0.2871,  ..., -0.3981,  0.1370,  0.0457]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([4, 4, 7, 6, 9, 9, 0, 0, 1, 9, 6, 3, 3, 2, 7, 7, 9, 3, 5, 7, 6, 3, 5, 3,\n",
            "        0, 0, 4, 0, 9, 9, 0, 5, 5, 2, 8, 1, 0, 5, 7, 8, 7, 7, 2, 4, 4, 2, 6, 8,\n",
            "        7, 3, 9, 7, 8, 3, 8, 7, 7, 6, 9, 7, 1, 9, 9, 4, 5, 2, 5, 7, 5, 6, 1, 7,\n",
            "        1, 9, 0, 0, 8, 8, 1, 2, 4, 1, 3, 8, 2, 0, 3, 5, 9, 8, 6, 9, 4, 1, 9, 4,\n",
            "        8, 8, 6, 9, 0, 6, 7, 2, 4, 7, 2, 0, 8, 4, 6, 6, 4, 0, 3, 0, 9, 2, 9, 8,\n",
            "        0, 6, 6, 0, 3, 6, 3, 7, 2, 0, 6, 1, 1, 5, 6, 3, 5, 9, 9, 2, 4, 5, 5, 5,\n",
            "        1, 2, 0, 7, 1, 4, 0, 6, 9, 2, 7, 0, 0, 4, 5, 7, 0, 3, 2, 3, 5, 8, 8, 9,\n",
            "        8, 6, 5, 1, 4, 0, 7, 3, 0, 4, 9, 7, 9, 0, 1, 0, 4, 3, 1, 3, 2, 2, 7, 2,\n",
            "        0, 5, 3, 6, 4, 0, 6, 5, 3, 7, 9, 2, 9, 5, 0, 2, 7, 5, 9, 8, 3, 0, 5, 2,\n",
            "        4, 8, 4, 4, 1, 2, 4, 6, 8, 8, 0, 0, 0, 2, 7, 0, 4, 4, 3, 3, 1, 4, 9, 3,\n",
            "        6, 0, 3, 1, 6, 4, 5, 6, 0, 4, 2, 4, 0, 1, 7, 4, 6, 2, 2, 3, 4, 9, 6, 1,\n",
            "        7, 6, 0, 1, 8, 3, 1, 6, 8, 0, 1, 9, 1, 6, 6, 8, 4, 6, 2, 2, 7, 1, 9, 2,\n",
            "        4, 3, 8, 4, 7, 6, 8, 8, 7, 0, 4, 8])\n",
            "tensor([[-0.2406,  0.0697, -0.2410,  ...,  0.5562,  0.2771,  0.2684],\n",
            "        [-0.0177,  0.0575,  0.0769,  ..., -0.1193,  0.0628,  0.1017],\n",
            "        [-0.1234, -0.1762,  0.0993,  ..., -0.2576,  0.1472,  0.4471],\n",
            "        ...,\n",
            "        [ 0.0096, -0.1597,  0.7753,  ..., -0.7837,  0.0287,  0.0070],\n",
            "        [ 0.0169,  0.0076,  0.1834,  ..., -0.2581,  0.0734, -0.0039],\n",
            "        [-0.2575, -0.1147, -0.0972,  ...,  0.1916,  0.4358,  0.3086]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([7, 0, 9, 6, 5, 6, 6, 9, 3, 0, 2, 1, 4, 2, 1, 5, 6, 9, 6, 9, 3, 0, 3, 3,\n",
            "        5, 4, 5, 8, 2, 4, 2, 6, 8, 6, 3, 3, 1, 9, 6, 9, 5, 6, 0, 1, 3, 8, 7, 9,\n",
            "        3, 7, 7, 8, 1, 1, 7, 2, 1, 5, 7, 4, 4, 9, 3, 7, 3, 6, 2, 0, 4, 4, 5, 2,\n",
            "        6, 3, 8, 7, 8, 5, 8, 6, 4, 7, 6, 5, 9, 6, 7, 5, 1, 0, 4, 3, 4, 1, 1, 0,\n",
            "        3, 2, 1, 7, 1, 3, 3, 4, 4, 1, 4, 2, 6, 4, 7, 3, 9, 1, 9, 3, 8, 9, 5, 7,\n",
            "        0, 1, 5, 9, 1, 5, 1, 8, 7, 2, 8, 1, 7, 0, 1, 4, 3, 3, 7, 9, 3, 7, 7, 0,\n",
            "        1, 5, 6, 9, 1, 8, 0, 5, 5, 0, 2, 1, 5, 4, 5, 7, 8, 6, 1, 2, 5, 6, 8, 9,\n",
            "        4, 9, 0, 9, 1, 0, 1, 9, 1, 1, 9, 9, 3, 4, 5, 7, 8, 4, 9, 2, 8, 1, 1, 1,\n",
            "        4, 5, 5, 4, 0, 0, 0, 7, 8, 7, 1, 9, 0, 2, 6, 7, 4, 4, 7, 2, 1, 8, 2, 6,\n",
            "        2, 1, 4, 1, 8, 7, 2, 2, 0, 9, 9, 8, 6, 8, 0, 6, 1, 6, 2, 8, 5, 5, 0, 8,\n",
            "        2, 6, 9, 9, 4, 2, 0, 1, 0, 2, 0, 2, 2, 5, 5, 7, 3, 0, 7, 1, 1, 9, 4, 6,\n",
            "        1, 0, 2, 2, 6, 0, 3, 8, 4, 7, 8, 1, 1, 9, 4, 7, 4, 8, 4, 6, 8, 8, 2, 6,\n",
            "        9, 5, 0, 3, 1, 7, 9, 2, 5, 4, 2, 8])\n",
            "tensor([[-0.2053,  0.1121, -0.1907,  ...,  0.5210,  0.1705,  0.2628],\n",
            "        [-0.1244, -0.1764,  0.0345,  ..., -0.0722,  0.1679,  0.4233],\n",
            "        [ 0.0196, -0.0734,  0.2248,  ..., -0.2359,  0.0657,  0.0560],\n",
            "        ...,\n",
            "        [ 0.3649,  0.1798,  0.6307,  ..., -0.5648, -0.2097, -0.1646],\n",
            "        [-0.0423,  0.1992,  0.0826,  ..., -0.1922, -0.0611, -0.0643],\n",
            "        [ 0.3592,  0.0765,  0.5671,  ..., -0.6301, -0.1586, -0.0226]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([7, 9, 8, 9, 8, 6, 7, 7, 7, 0, 1, 4, 9, 5, 3, 5, 6, 4, 7, 9, 5, 7, 6, 5,\n",
            "        2, 5, 6, 1, 0, 2, 9, 0, 8, 1, 4, 2, 6, 7, 9, 4, 0, 1, 1, 6, 8, 4, 5, 3,\n",
            "        8, 3, 3, 8, 7, 8, 9, 5, 6, 4, 1, 9, 6, 3, 6, 4, 4, 0, 4, 3, 2, 7, 6, 9,\n",
            "        5, 9, 6, 7, 6, 1, 4, 7, 7, 2, 7, 6, 0, 6, 0, 1, 3, 7, 2, 5, 6, 5, 8, 7,\n",
            "        5, 2, 7, 9, 6, 2, 6, 4, 8, 4, 7, 2, 0, 7, 2, 3, 9, 0, 9, 8, 1, 9, 9, 2,\n",
            "        5, 8, 1, 3, 1, 3, 5, 5, 7, 7, 7, 4, 4, 8, 6, 8, 0, 8, 1, 6, 5, 5, 6, 6,\n",
            "        8, 1, 4, 1, 3, 3, 2, 9, 7, 3, 5, 2, 4, 9, 8, 0, 6, 3, 3, 1, 3, 1, 7, 8,\n",
            "        0, 7, 8, 5, 5, 6, 8, 2, 7, 7, 9, 4, 8, 5, 6, 8, 8, 8, 9, 9, 4, 9, 9, 7,\n",
            "        9, 3, 4, 2, 6, 7, 3, 6, 3, 0, 9, 3, 2, 4, 9, 2, 3, 7, 8, 3, 1, 4, 4, 5,\n",
            "        1, 5, 1, 0, 3, 8, 8, 1, 9, 7, 1, 9, 6, 8, 1, 5, 1, 7, 5, 0, 6, 6, 3, 6,\n",
            "        1, 1, 4, 8, 9, 3, 3, 6, 0, 2, 3, 3, 8, 7, 3, 1, 8, 6, 1, 6, 8, 0, 9, 2,\n",
            "        5, 2, 1, 4, 2, 4, 8, 3, 8, 4, 4, 2, 7, 3, 8, 9, 1, 9, 6, 7, 7, 8, 1, 8,\n",
            "        6, 7, 6, 6, 0, 9, 9, 1, 9, 0, 0, 0])\n",
            "tensor([[ 0.1165,  0.0209,  0.2293,  ..., -0.3599, -0.0597, -0.0100],\n",
            "        [ 0.1491, -0.2009,  0.3902,  ..., -0.4640,  0.0884,  0.0119],\n",
            "        [ 0.3410,  0.0203,  0.4788,  ..., -0.4842, -0.1377, -0.1049],\n",
            "        ...,\n",
            "        [-0.0744,  0.0895,  0.0011,  ..., -0.0941,  0.0767,  0.0427],\n",
            "        [ 0.0176,  0.1511,  0.0621,  ..., -0.1216,  0.0506,  0.0342],\n",
            "        [ 0.1251, -0.0760,  0.7179,  ..., -0.7783, -0.0594, -0.0877]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([0, 2, 0, 7, 8, 4, 8, 1, 5, 1, 2, 0, 0, 4, 1, 5, 9, 1, 7, 1, 2, 6, 9, 5,\n",
            "        0, 3, 4, 0, 8, 8, 5, 0, 2, 2, 1, 3, 6, 2, 9, 3, 4, 2, 4, 2, 1, 5, 1, 0,\n",
            "        8, 9, 1, 1, 1, 6, 3, 4, 3, 9, 6, 7, 4, 5, 9, 1, 8, 5, 9, 5, 6, 3, 9, 5,\n",
            "        3, 5, 0, 4, 7, 6, 0, 0, 5, 1, 3, 3, 2, 5, 4, 5, 9, 0, 5, 5, 9, 0, 4, 4,\n",
            "        8, 2, 7, 5, 6, 7, 9, 9, 8, 5, 0, 5, 6, 2, 4, 9, 1, 0, 9, 8, 5, 7, 3, 2,\n",
            "        4, 0, 5, 0, 6, 9, 7, 0, 1, 2, 3, 2, 0, 1, 2, 2, 9, 8, 9, 2, 3, 7, 8, 2,\n",
            "        4, 1, 7, 5, 6, 1, 4, 2, 3, 8, 0, 3, 9, 7, 7, 6, 2, 2, 4, 4, 5, 5, 3, 0,\n",
            "        2, 5, 4, 2, 3, 8, 8, 3, 0, 0, 9, 1, 0, 5, 6, 0, 8, 7, 2, 9, 2, 6, 1, 4,\n",
            "        6, 4, 3, 0, 1, 5, 5, 2, 2, 6, 7, 7, 3, 4, 3, 8, 8, 7, 1, 5, 3, 9, 4, 3,\n",
            "        2, 6, 4, 4, 6, 0, 8, 0, 6, 8, 0, 9, 3, 2, 3, 0, 2, 6, 6, 2, 8, 8, 0, 1,\n",
            "        4, 0, 7, 8, 5, 8, 4, 8, 6, 2, 5, 9, 9, 1, 8, 9, 3, 3, 9, 5, 1, 8, 5, 8,\n",
            "        1, 1, 1, 8, 2, 8, 4, 4, 7, 6, 4, 1, 2, 8, 5, 6, 8, 4, 4, 6, 1, 7, 3, 7,\n",
            "        7, 5, 4, 2, 2, 4, 0, 4, 6, 2, 0, 2])\n",
            "tensor([[-0.1544, -0.0296,  0.1037,  ..., -0.2225,  0.0925,  0.3526],\n",
            "        [-0.1203,  0.0622,  0.1126,  ..., -0.2692,  0.1630,  0.0123],\n",
            "        [-0.1257, -0.2415,  0.3260,  ...,  0.0055,  0.5435,  0.3993],\n",
            "        ...,\n",
            "        [ 0.0874,  0.4001,  0.5451,  ..., -0.5390, -0.2455, -0.1579],\n",
            "        [ 0.4272,  0.0187,  0.6032,  ..., -0.7036, -0.2483, -0.1265],\n",
            "        [-0.0914, -0.0309,  0.1173,  ..., -0.2946,  0.0919, -0.1466]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([9, 8, 8, 7, 9, 0, 7, 5, 2, 0, 9, 0, 0, 4, 9, 6, 4, 9, 4, 2, 0, 1, 8, 5,\n",
            "        9, 3, 8, 1, 1, 5, 7, 9, 1, 0, 4, 9, 4, 8, 2, 9, 8, 7, 5, 9, 2, 4, 9, 8,\n",
            "        7, 3, 2, 3, 6, 3, 9, 9, 6, 3, 6, 5, 5, 7, 7, 0, 7, 6, 4, 6, 2, 2, 7, 3,\n",
            "        9, 7, 3, 6, 4, 9, 6, 0, 6, 5, 7, 9, 8, 1, 8, 2, 3, 1, 2, 5, 6, 9, 1, 2,\n",
            "        3, 7, 6, 0, 6, 2, 5, 1, 6, 4, 4, 3, 5, 2, 4, 0, 5, 2, 6, 9, 2, 7, 4, 2,\n",
            "        7, 4, 8, 0, 6, 7, 9, 3, 2, 0, 2, 6, 5, 1, 5, 1, 7, 3, 1, 0, 4, 2, 3, 2,\n",
            "        4, 1, 9, 0, 3, 3, 3, 5, 0, 0, 7, 2, 8, 2, 2, 4, 4, 5, 7, 3, 5, 5, 1, 2,\n",
            "        2, 6, 2, 7, 4, 8, 0, 5, 9, 9, 3, 0, 3, 3, 2, 7, 5, 6, 5, 2, 4, 0, 9, 4,\n",
            "        7, 4, 4, 7, 3, 7, 1, 0, 2, 1, 2, 5, 8, 7, 7, 5, 0, 9, 1, 4, 4, 2, 2, 2,\n",
            "        5, 2, 6, 2, 3, 8, 7, 8, 4, 5, 8, 6, 2, 9, 8, 5, 9, 4, 7, 9, 1, 2, 4, 7,\n",
            "        9, 7, 3, 9, 1, 0, 6, 7, 3, 3, 7, 8, 0, 1, 4, 9, 5, 3, 6, 7, 4, 4, 4, 1,\n",
            "        1, 7, 2, 7, 6, 9, 7, 2, 3, 0, 9, 4, 1, 4, 1, 4, 3, 9, 7, 6, 3, 6, 7, 0,\n",
            "        0, 3, 3, 4, 6, 8, 9, 2, 1, 4, 0, 8])\n",
            "tensor([[ 0.1061, -0.1739,  0.7765,  ..., -0.8390,  0.0310, -0.1290],\n",
            "        [ 0.0471,  0.0150,  0.3828,  ..., -0.3843,  0.0276, -0.0152],\n",
            "        [ 0.0312, -0.3010,  0.6821,  ..., -0.6636,  0.3301,  0.1054],\n",
            "        ...,\n",
            "        [ 0.0247, -0.2313,  0.9288,  ..., -0.9306,  0.0708, -0.1505],\n",
            "        [-0.3802,  0.1294, -0.2202,  ...,  0.3795,  0.1857,  0.0710],\n",
            "        [-0.1359,  0.0226, -0.0796,  ...,  0.3056,  0.3713,  0.3865]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([4, 2, 8, 4, 1, 7, 4, 4, 1, 6, 2, 2, 3, 8, 8, 6, 7, 4, 5, 7, 3, 3, 7, 2,\n",
            "        2, 4, 8, 1, 8, 8, 9, 3, 7, 2, 8, 5, 0, 5, 2, 1, 9, 5, 5, 6, 2, 4, 0, 3,\n",
            "        8, 4, 4, 5, 2, 5, 6, 2, 5, 1, 3, 5, 9, 7, 3, 1, 8, 6, 1, 1, 0, 0, 0, 1,\n",
            "        4, 7, 3, 6, 8, 3, 4, 4, 0, 4, 5, 3, 6, 3, 3, 9, 2, 6, 5, 7, 3, 8, 7, 0,\n",
            "        9, 3, 8, 1, 5, 2, 7, 8, 3, 0, 6, 6, 8, 6, 1, 9, 7, 9, 9, 1, 5, 3, 1, 6,\n",
            "        2, 9, 3, 4, 9, 1, 9, 6, 7, 8, 5, 6, 0, 2, 1, 2, 9, 5, 2, 6, 5, 2, 6, 3,\n",
            "        4, 7, 9, 6, 2, 8, 4, 1, 1, 7, 5, 7, 2, 9, 5, 7, 9, 8, 7, 4, 0, 1, 9, 4,\n",
            "        1, 7, 9, 2, 2, 1, 3, 7, 0, 0, 1, 7, 1, 4, 5, 1, 5, 5, 7, 2, 0, 2, 8, 3,\n",
            "        8, 9, 1, 5, 0, 4, 5, 0, 8, 9, 3, 6, 7, 5, 8, 1, 4, 7, 8, 4, 5, 9, 7, 2,\n",
            "        4, 0, 1, 2, 7, 0, 6, 7, 5, 3, 3, 8, 9, 8, 7, 4, 3, 2, 4, 8, 0, 7, 0, 4,\n",
            "        5, 3, 1, 3, 6, 0, 8, 2, 1, 8, 3, 2, 7, 4, 1, 9, 4, 8, 9, 8, 1, 0, 9, 6,\n",
            "        2, 4, 0, 0, 4, 1, 3, 8, 0, 2, 2, 3, 3, 5, 4, 8, 7, 1, 9, 8, 3, 5, 1, 5,\n",
            "        1, 0, 9, 3, 3, 2, 0, 0, 6, 4, 8, 9])\n",
            "tensor([[-0.3389,  0.0096, -0.2284,  ...,  0.6094,  0.4299,  0.4170],\n",
            "        [-0.1507,  0.0542,  0.0796,  ...,  0.1363,  0.2038,  0.1697],\n",
            "        [-0.1056, -0.0566,  0.0553,  ..., -0.0801,  0.2251,  0.1622],\n",
            "        ...,\n",
            "        [ 0.1787, -0.3503,  0.9340,  ..., -1.0666,  0.0048, -0.1954],\n",
            "        [ 0.1051, -0.0279,  0.5894,  ..., -0.5949,  0.0387, -0.0230],\n",
            "        [ 0.4207,  0.1288,  0.6973,  ..., -0.6933, -0.2182, -0.1915]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([7, 8, 8, 9, 8, 1, 0, 7, 6, 1, 2, 0, 3, 4, 9, 4, 0, 6, 5, 0, 6, 1, 6, 1,\n",
            "        9, 1, 1, 0, 0, 3, 8, 2, 5, 4, 7, 4, 8, 4, 1, 5, 3, 0, 6, 9, 1, 0, 2, 8,\n",
            "        0, 4, 7, 6, 8, 5, 1, 8, 7, 6, 6, 6, 2, 7, 4, 4, 0, 2, 5, 9, 5, 4, 6, 4,\n",
            "        0, 8, 9, 0, 2, 8, 4, 9, 1, 2, 7, 2, 9, 8, 8, 4, 7, 6, 8, 6, 4, 0, 7, 8,\n",
            "        9, 1, 1, 5, 1, 1, 7, 5, 4, 8, 2, 1, 3, 7, 4, 4, 0, 1, 4, 0, 6, 5, 4, 6,\n",
            "        4, 7, 9, 5, 1, 0, 8, 8, 7, 0, 8, 7, 1, 3, 2, 3, 3, 0, 3, 8, 0, 3, 0, 8,\n",
            "        2, 0, 3, 2, 9, 5, 0, 8, 0, 2, 0, 8, 3, 6, 1, 8, 9, 7, 0, 1, 0, 8, 3, 8,\n",
            "        9, 6, 6, 4, 3, 3, 3, 0, 7, 4, 3, 0, 1, 5, 1, 2, 1, 1, 5, 5, 4, 2, 5, 6,\n",
            "        8, 4, 7, 9, 0, 1, 1, 8, 9, 1, 8, 2, 9, 6, 1, 9, 4, 0, 1, 6, 2, 9, 8, 7,\n",
            "        7, 1, 5, 5, 4, 3, 0, 6, 1, 8, 4, 0, 6, 9, 0, 3, 1, 5, 6, 1, 6, 2, 5, 0,\n",
            "        7, 1, 2, 0, 9, 6, 1, 1, 0, 5, 5, 2, 9, 2, 5, 7, 4, 0, 8, 2, 2, 4, 9, 3,\n",
            "        9, 6, 2, 8, 0, 8, 1, 7, 1, 8, 8, 2, 4, 0, 8, 4, 9, 5, 9, 2, 4, 8, 5, 8,\n",
            "        6, 0, 4, 0, 5, 2, 7, 0, 6, 4, 2, 0])\n",
            "tensor([[-0.2890,  0.0438, -0.1606,  ...,  0.3225,  0.3977,  0.3826],\n",
            "        [ 0.2599, -0.1842,  0.9075,  ..., -0.9079,  0.0721, -0.1066],\n",
            "        [ 0.3476,  0.2874,  0.6707,  ..., -0.5918, -0.1214, -0.1448],\n",
            "        ...,\n",
            "        [-0.3897,  0.0094, -0.2708,  ...,  0.6015,  0.5094,  0.5787],\n",
            "        [-0.2569, -0.0073, -0.1451,  ...,  0.2591,  0.4334,  0.5591],\n",
            "        [ 0.1686,  0.1748,  0.1878,  ..., -0.1935, -0.0280, -0.0654]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([7, 4, 3, 2, 5, 9, 9, 0, 0, 7, 5, 8, 5, 6, 2, 2, 7, 6, 4, 3, 7, 2, 2, 3,\n",
            "        5, 4, 6, 5, 4, 1, 4, 0, 6, 6, 2, 3, 8, 3, 7, 9, 6, 3, 6, 6, 9, 3, 4, 1,\n",
            "        5, 9, 4, 6, 0, 3, 9, 9, 9, 2, 5, 2, 4, 3, 9, 1, 2, 2, 6, 8, 5, 0, 2, 7,\n",
            "        3, 4, 4, 2, 1, 4, 8, 6, 8, 4, 6, 2, 5, 9, 7, 7, 9, 1, 4, 2, 1, 1, 4, 6,\n",
            "        7, 0, 5, 1, 7, 1, 3, 4, 4, 2, 3, 6, 2, 9, 3, 3, 2, 5, 0, 5, 9, 2, 6, 8,\n",
            "        8, 9, 5, 2, 5, 6, 0, 9, 8, 4, 0, 0, 0, 9, 7, 4, 1, 4, 7, 0, 0, 8, 4, 5,\n",
            "        3, 4, 0, 5, 4, 7, 1, 5, 7, 5, 4, 1, 9, 7, 2, 1, 2, 7, 8, 3, 7, 7, 4, 7,\n",
            "        4, 1, 4, 4, 7, 8, 0, 0, 1, 2, 0, 8, 2, 7, 1, 7, 8, 9, 9, 7, 4, 2, 8, 7,\n",
            "        1, 0, 8, 1, 7, 0, 4, 1, 0, 7, 3, 3, 1, 8, 9, 3, 5, 6, 1, 1, 7, 7, 1, 9,\n",
            "        5, 8, 9, 3, 8, 5, 1, 5, 1, 2, 9, 7, 7, 2, 6, 8, 6, 6, 0, 4, 9, 7, 7, 0,\n",
            "        2, 6, 1, 0, 1, 7, 9, 1, 2, 3, 6, 8, 5, 0, 2, 8, 8, 5, 1, 6, 7, 8, 0, 1,\n",
            "        9, 4, 5, 6, 4, 9, 7, 8, 2, 0, 0, 3, 7, 3, 1, 2, 5, 2, 5, 9, 8, 6, 2, 8,\n",
            "        6, 5, 8, 7, 3, 8, 5, 2, 4, 7, 9, 0])\n",
            "tensor([[-0.0668, -0.0601,  0.2840,  ..., -0.3582,  0.1421,  0.0455],\n",
            "        [ 0.3189, -0.2937,  0.9730,  ..., -0.9699,  0.0531, -0.0678],\n",
            "        [-0.1498, -0.0078, -0.0606,  ...,  0.0530,  0.4199,  0.4928],\n",
            "        ...,\n",
            "        [ 0.1050, -0.1740,  0.7711,  ..., -0.6432,  0.1375, -0.0188],\n",
            "        [-0.1993,  0.0966, -0.0836,  ...,  0.1225,  0.1216,  0.1392],\n",
            "        [ 0.2651, -0.3988,  1.1471,  ..., -1.1275,  0.0474, -0.1793]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([8, 6, 9, 6, 7, 1, 8, 0, 7, 4, 0, 1, 4, 3, 7, 6, 5, 0, 6, 4, 4, 8, 2, 8,\n",
            "        3, 2, 6, 3, 7, 2, 5, 8, 7, 6, 7, 3, 7, 5, 3, 7, 8, 1, 6, 8, 2, 7, 2, 5,\n",
            "        6, 7, 8, 3, 8, 3, 5, 2, 3, 0, 9, 1, 0, 3, 0, 2, 8, 6, 5, 8, 7, 8, 7, 4,\n",
            "        7, 0, 3, 2, 2, 8, 6, 6, 0, 6, 7, 9, 2, 1, 6, 2, 1, 5, 2, 3, 1, 9, 3, 2,\n",
            "        7, 6, 9, 0, 5, 1, 8, 2, 0, 3, 7, 7, 9, 7, 6, 9, 4, 6, 9, 9, 6, 5, 0, 9,\n",
            "        9, 4, 0, 2, 0, 0, 5, 5, 9, 4, 4, 9, 6, 8, 0, 8, 5, 0, 5, 3, 5, 4, 8, 5,\n",
            "        7, 9, 8, 7, 7, 5, 6, 8, 3, 8, 8, 2, 1, 1, 7, 8, 4, 3, 7, 8, 9, 0, 5, 9,\n",
            "        7, 1, 8, 8, 2, 8, 6, 6, 0, 3, 5, 3, 2, 1, 3, 9, 5, 0, 0, 2, 3, 3, 2, 1,\n",
            "        6, 4, 5, 8, 9, 8, 7, 2, 5, 9, 2, 4, 0, 5, 9, 3, 3, 1, 9, 7, 0, 5, 0, 8,\n",
            "        9, 6, 0, 0, 8, 4, 7, 6, 6, 7, 5, 9, 6, 4, 2, 4, 1, 4, 6, 4, 1, 8, 6, 8,\n",
            "        5, 2, 1, 1, 2, 2, 0, 5, 7, 1, 7, 8, 0, 3, 2, 6, 8, 4, 0, 8, 0, 8, 3, 4,\n",
            "        8, 3, 7, 7, 3, 2, 1, 0, 8, 3, 0, 8, 4, 7, 3, 3, 1, 5, 0, 8, 2, 2, 1, 5,\n",
            "        5, 3, 1, 7, 4, 7, 4, 9, 4, 4, 5, 2])\n",
            "tensor([[-0.2406, -0.0201, -0.1946,  ...,  0.2075,  0.5548,  0.6196],\n",
            "        [ 0.6091, -0.0014,  0.7658,  ..., -0.7438, -0.1548, -0.1681],\n",
            "        [-0.3036,  0.0217, -0.3370,  ...,  0.7529,  0.3282,  0.3934],\n",
            "        ...,\n",
            "        [ 0.0168,  0.0356,  0.1969,  ..., -0.3932,  0.1130, -0.0868],\n",
            "        [-0.3133,  0.0220, -0.2325,  ...,  0.1387,  0.3277,  0.3293],\n",
            "        [-0.0557, -0.2853,  0.4949,  ..., -0.2291,  0.5379,  0.3613]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([9, 0, 7, 7, 3, 1, 8, 8, 2, 0, 0, 0, 1, 2, 7, 4, 3, 6, 3, 9, 8, 4, 1, 9,\n",
            "        8, 0, 0, 2, 1, 5, 0, 1, 0, 4, 6, 9, 8, 8, 6, 9, 3, 7, 8, 1, 9, 3, 4, 5,\n",
            "        2, 9, 7, 9, 4, 4, 2, 5, 6, 3, 1, 3, 7, 3, 1, 1, 3, 8, 6, 2, 5, 2, 9, 3,\n",
            "        1, 6, 5, 9, 3, 0, 1, 3, 9, 3, 3, 2, 4, 3, 4, 2, 0, 7, 7, 6, 7, 4, 9, 2,\n",
            "        0, 7, 4, 1, 4, 5, 1, 1, 5, 2, 7, 9, 1, 0, 3, 1, 7, 2, 7, 3, 8, 0, 4, 0,\n",
            "        6, 8, 5, 8, 4, 4, 2, 8, 9, 4, 5, 5, 5, 6, 2, 5, 2, 3, 5, 9, 4, 2, 9, 5,\n",
            "        3, 9, 6, 1, 5, 5, 9, 6, 5, 1, 7, 3, 8, 5, 6, 1, 1, 6, 5, 2, 7, 0, 5, 9,\n",
            "        4, 7, 0, 3, 9, 1, 5, 0, 3, 3, 2, 4, 9, 4, 8, 3, 4, 3, 5, 6, 6, 0, 6, 8,\n",
            "        5, 4, 7, 1, 0, 3, 6, 2, 1, 8, 6, 8, 4, 1, 4, 2, 7, 0, 9, 3, 4, 3, 6, 6,\n",
            "        3, 9, 7, 6, 7, 2, 0, 5, 4, 3, 5, 7, 1, 3, 5, 4, 6, 3, 9, 5, 3, 7, 9, 8,\n",
            "        0, 7, 8, 2, 6, 5, 0, 1, 9, 6, 1, 1, 9, 4, 2, 9, 6, 6, 1, 7, 6, 2, 0, 4,\n",
            "        9, 8, 3, 5, 4, 0, 9, 2, 8, 4, 7, 5, 8, 2, 6, 3, 8, 2, 7, 3, 8, 4, 3, 9,\n",
            "        9, 9, 6, 2, 5, 8, 0, 1, 7, 8, 9, 8])\n",
            "tensor([[-0.0072,  0.0492,  0.3543,  ..., -0.3688, -0.0106,  0.0017],\n",
            "        [ 0.0135,  0.8563,  0.3459,  ..., -0.2536, -0.0604, -0.1448],\n",
            "        [ 0.2458, -0.5354,  1.1311,  ..., -1.1448,  0.0109, -0.1727],\n",
            "        ...,\n",
            "        [ 0.2593, -0.0512,  0.8189,  ..., -0.8716, -0.1464, -0.0948],\n",
            "        [-0.0051,  0.5511,  0.3390,  ..., -0.2892, -0.1307, -0.0976],\n",
            "        [-0.3630, -0.0134, -0.2279,  ...,  0.4737,  0.5735,  0.5219]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([6, 1, 2, 7, 3, 8, 3, 8, 8, 0, 5, 6, 5, 3, 0, 0, 9, 3, 1, 3, 4, 3, 3, 2,\n",
            "        4, 8, 1, 3, 4, 7, 4, 8, 7, 1, 9, 9, 6, 2, 8, 6, 5, 3, 2, 9, 6, 9, 0, 5,\n",
            "        9, 5, 9, 4, 5, 2, 1, 4, 9, 2, 2, 7, 6, 0, 0, 3, 9, 8, 7, 7, 9, 8, 3, 5,\n",
            "        4, 3, 2, 4, 7, 6, 6, 0, 6, 9, 7, 1, 6, 4, 5, 2, 8, 4, 6, 3, 4, 1, 4, 3,\n",
            "        8, 9, 9, 0, 9, 3, 9, 3, 6, 3, 7, 1, 8, 2, 1, 0, 1, 2, 5, 3, 1, 5, 9, 0,\n",
            "        8, 1, 9, 2, 3, 3, 2, 5, 8, 8, 3, 4, 2, 8, 1, 0, 2, 8, 5, 7, 7, 0, 3, 9,\n",
            "        2, 2, 8, 2, 9, 5, 9, 1, 4, 7, 8, 6, 3, 8, 1, 0, 5, 1, 9, 2, 4, 3, 0, 5,\n",
            "        7, 9, 9, 8, 7, 7, 3, 4, 6, 6, 2, 1, 7, 5, 1, 5, 4, 8, 3, 8, 2, 7, 0, 4,\n",
            "        1, 6, 7, 2, 7, 6, 8, 4, 0, 9, 2, 4, 2, 6, 3, 1, 0, 3, 0, 9, 3, 8, 7, 4,\n",
            "        0, 2, 3, 6, 9, 7, 4, 0, 7, 1, 2, 9, 2, 4, 8, 6, 9, 3, 8, 9, 3, 9, 9, 2,\n",
            "        7, 9, 5, 6, 8, 8, 2, 2, 6, 7, 5, 4, 7, 1, 2, 8, 2, 8, 3, 3, 6, 5, 3, 2,\n",
            "        9, 5, 5, 4, 9, 7, 3, 4, 3, 8, 9, 9, 6, 6, 5, 8, 3, 8, 2, 1, 1, 4, 0, 5,\n",
            "        2, 4, 0, 2, 4, 4, 5, 4, 6, 2, 3, 7])\n",
            "tensor([[-0.0956, -0.2859,  0.4738,  ..., -0.3821,  0.4287,  0.3043],\n",
            "        [-0.3044, -0.0876, -0.1933,  ...,  0.4645,  0.7876,  0.9260],\n",
            "        [-0.2058,  0.0960, -0.1427,  ...,  0.1888,  0.0681,  0.0945],\n",
            "        ...,\n",
            "        [-0.2125,  0.1566, -0.1990,  ...,  0.5068,  0.1061,  0.2281],\n",
            "        [ 0.5499, -0.0729,  0.6823,  ..., -0.7569, -0.2298, -0.0455],\n",
            "        [-0.0490,  0.0826,  0.0868,  ..., -0.1325, -0.0108,  0.0619]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([8, 9, 7, 6, 3, 6, 4, 2, 7, 1, 6, 4, 6, 2, 1, 6, 5, 5, 4, 7, 4, 4, 7, 8,\n",
            "        0, 4, 1, 3, 8, 9, 9, 2, 0, 2, 7, 7, 2, 4, 0, 8, 5, 0, 7, 9, 8, 4, 4, 2,\n",
            "        2, 1, 1, 7, 8, 6, 1, 8, 7, 0, 8, 4, 2, 2, 4, 2, 6, 1, 7, 7, 0, 6, 3, 8,\n",
            "        3, 4, 5, 3, 3, 4, 2, 0, 8, 9, 5, 1, 3, 1, 6, 1, 0, 6, 0, 7, 6, 3, 6, 4,\n",
            "        6, 8, 9, 3, 3, 3, 6, 0, 7, 9, 8, 5, 3, 6, 3, 8, 7, 7, 4, 0, 2, 7, 2, 8,\n",
            "        2, 1, 6, 4, 7, 7, 4, 1, 2, 2, 0, 9, 6, 4, 9, 3, 1, 1, 9, 9, 5, 9, 2, 3,\n",
            "        9, 2, 2, 4, 3, 7, 2, 9, 2, 2, 8, 9, 7, 4, 7, 7, 6, 7, 0, 9, 9, 5, 4, 1,\n",
            "        1, 9, 7, 1, 8, 5, 6, 1, 4, 3, 1, 4, 4, 9, 7, 1, 6, 8, 0, 3, 5, 7, 3, 7,\n",
            "        5, 3, 6, 1, 8, 3, 5, 8, 5, 0, 4, 8, 6, 8, 6, 5, 7, 6, 3, 2, 9, 0, 5, 9,\n",
            "        9, 8, 2, 7, 7, 8, 8, 6, 6, 7, 0, 4, 8, 3, 9, 0, 6, 2, 4, 9, 7, 2, 7, 1,\n",
            "        6, 9, 4, 7, 7, 7, 1, 0, 8, 4, 4, 1, 5, 9, 4, 9, 5, 5, 0, 9, 0, 1, 8, 2,\n",
            "        5, 0, 2, 4, 8, 1, 9, 1, 4, 1, 7, 0, 6, 0, 3, 4, 9, 6, 1, 0, 3, 1, 0, 0,\n",
            "        9, 0, 0, 2, 7, 3, 7, 2, 8, 5, 6, 4])\n",
            "tensor([[-0.0523, -0.0540,  0.1455,  ..., -0.2493,  0.0345,  0.0673],\n",
            "        [-0.1582,  0.1388, -0.0318,  ...,  0.1642,  0.0387,  0.0968],\n",
            "        [-0.2041,  0.1591, -0.1531,  ...,  0.2391,  0.0593,  0.1105],\n",
            "        ...,\n",
            "        [ 0.2771, -0.0766,  0.8136,  ..., -0.9297, -0.0515, -0.1898],\n",
            "        [-0.4579, -0.0289, -0.3365,  ...,  1.0098,  0.5782,  0.5516],\n",
            "        [-0.0412, -0.1635,  0.3551,  ..., -0.1900,  0.8267,  0.3998]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([6, 5, 7, 0, 3, 2, 9, 9, 5, 8, 0, 0, 7, 0, 6, 4, 0, 2, 7, 1, 8, 5, 5, 4,\n",
            "        2, 6, 4, 3, 0, 1, 2, 4, 3, 7, 7, 3, 6, 6, 0, 9, 7, 7, 8, 2, 3, 4, 4, 8,\n",
            "        1, 0, 4, 7, 4, 3, 2, 0, 6, 8, 4, 8, 9, 6, 7, 2, 1, 0, 1, 8, 6, 5, 7, 1,\n",
            "        3, 7, 0, 8, 1, 0, 0, 0, 1, 9, 4, 1, 5, 3, 1, 3, 0, 3, 9, 2, 1, 8, 4, 5,\n",
            "        5, 2, 1, 5, 8, 5, 8, 4, 3, 6, 9, 1, 7, 0, 9, 1, 2, 1, 7, 9, 1, 9, 7, 5,\n",
            "        6, 2, 3, 8, 8, 8, 2, 9, 4, 0, 5, 1, 8, 3, 6, 6, 6, 2, 9, 0, 3, 3, 2, 7,\n",
            "        9, 2, 2, 4, 0, 5, 8, 4, 7, 1, 7, 3, 4, 0, 1, 8, 8, 6, 9, 5, 0, 9, 9, 1,\n",
            "        7, 2, 2, 2, 0, 9, 1, 9, 0, 9, 9, 6, 1, 1, 4, 3, 5, 8, 5, 9, 9, 9, 9, 3,\n",
            "        3, 7, 8, 1, 1, 9, 2, 6, 7, 1, 8, 1, 1, 0, 8, 1, 7, 3, 6, 7, 0, 3, 6, 8,\n",
            "        3, 1, 5, 5, 3, 2, 7, 8, 1, 0, 2, 1, 9, 5, 5, 4, 3, 4, 4, 4, 1, 4, 2, 7,\n",
            "        3, 8, 5, 9, 9, 5, 3, 2, 9, 3, 1, 9, 4, 0, 3, 6, 1, 3, 6, 7, 9, 7, 6, 4,\n",
            "        8, 1, 1, 6, 0, 0, 4, 6, 7, 4, 9, 9, 0, 0, 0, 7, 7, 7, 8, 6, 0, 4, 7, 9,\n",
            "        2, 6, 2, 3, 9, 7, 9, 3, 4, 4, 7, 8])\n",
            "tensor([[-0.1603, -0.1629, -0.0554,  ...,  0.0020,  0.2685,  0.7466],\n",
            "        [ 0.1470,  0.3171,  0.3167,  ..., -0.3359, -0.1609, -0.0519],\n",
            "        [ 0.1605,  0.2844,  0.4436,  ..., -0.4455, -0.1695, -0.1569],\n",
            "        ...,\n",
            "        [-0.0825,  0.1450,  0.0647,  ..., -0.0738,  0.0151,  0.0233],\n",
            "        [ 0.0383, -0.2025,  0.6033,  ..., -0.5201,  0.1429,  0.0538],\n",
            "        [-0.2451,  0.1911,  0.0704,  ..., -0.1215,  0.0603,  0.0058]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([9, 0, 3, 5, 7, 3, 9, 1, 2, 9, 3, 2, 5, 2, 9, 9, 7, 9, 0, 6, 6, 5, 7, 0,\n",
            "        7, 6, 1, 0, 6, 5, 3, 2, 1, 7, 4, 5, 5, 2, 0, 9, 2, 1, 3, 6, 2, 5, 2, 8,\n",
            "        5, 2, 7, 0, 5, 3, 4, 8, 0, 1, 5, 7, 0, 7, 0, 1, 8, 3, 0, 6, 9, 2, 7, 2,\n",
            "        8, 5, 1, 4, 5, 0, 7, 7, 3, 7, 7, 2, 9, 5, 0, 5, 7, 5, 0, 2, 7, 3, 3, 1,\n",
            "        7, 8, 5, 9, 9, 7, 2, 7, 1, 4, 4, 2, 8, 5, 4, 7, 5, 9, 7, 8, 4, 9, 2, 8,\n",
            "        8, 7, 3, 2, 5, 1, 1, 2, 0, 0, 5, 4, 6, 8, 4, 5, 8, 1, 0, 4, 3, 0, 7, 8,\n",
            "        4, 9, 7, 8, 2, 8, 7, 9, 7, 2, 1, 3, 6, 6, 4, 9, 4, 9, 6, 9, 9, 2, 3, 5,\n",
            "        4, 3, 3, 5, 2, 2, 2, 9, 9, 5, 9, 1, 6, 2, 1, 0, 1, 6, 6, 4, 4, 5, 1, 7,\n",
            "        9, 1, 1, 3, 9, 3, 6, 6, 9, 9, 4, 5, 0, 1, 5, 4, 5, 4, 3, 4, 0, 9, 0, 9,\n",
            "        2, 3, 0, 3, 7, 2, 5, 4, 6, 2, 5, 9, 3, 1, 0, 2, 0, 5, 4, 3, 5, 2, 6, 3,\n",
            "        5, 1, 6, 1, 1, 7, 1, 2, 9, 6, 5, 4, 4, 9, 4, 3, 9, 0, 3, 2, 1, 9, 6, 3,\n",
            "        4, 1, 2, 7, 0, 7, 2, 0, 7, 2, 7, 3, 9, 6, 6, 1, 1, 9, 3, 4, 2, 8, 2, 7,\n",
            "        8, 2, 4, 6, 8, 8, 6, 2, 7, 0, 4, 8])\n",
            "tensor([[-0.3368, -0.0211, -0.2695,  ...,  0.6775,  0.7937,  1.1474],\n",
            "        [-0.0640,  0.1542,  0.0555,  ..., -0.0823,  0.0179,  0.0394],\n",
            "        [-0.1182,  0.1688,  0.0355,  ..., -0.0585,  0.0313,  0.0334],\n",
            "        ...,\n",
            "        [ 0.0398, -0.2950,  0.4483,  ..., -0.5318,  0.3106,  0.1094],\n",
            "        [ 0.8491, -0.0646,  0.8609,  ..., -0.9274, -0.2992, -0.2320],\n",
            "        [-0.0088,  0.0989,  0.1877,  ..., -0.2467,  0.0179,  0.0377]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([9, 0, 3, 5, 9, 2, 9, 7, 2, 3, 7, 8, 7, 8, 7, 3, 2, 3, 8, 4, 8, 6, 2, 4,\n",
            "        0, 2, 7, 3, 9, 0, 2, 2, 1, 4, 1, 1, 2, 6, 7, 1, 8, 7, 6, 8, 2, 6, 4, 6,\n",
            "        1, 4, 6, 9, 0, 6, 8, 0, 8, 4, 1, 7, 4, 0, 0, 3, 7, 6, 6, 8, 2, 0, 1, 4,\n",
            "        9, 4, 4, 7, 6, 3, 7, 3, 0, 5, 5, 9, 7, 9, 8, 0, 1, 4, 7, 7, 2, 2, 4, 2,\n",
            "        4, 0, 9, 5, 8, 3, 0, 0, 6, 7, 3, 6, 6, 5, 4, 4, 8, 0, 8, 1, 7, 3, 0, 2,\n",
            "        1, 7, 5, 5, 6, 1, 7, 1, 2, 3, 7, 1, 4, 2, 3, 0, 2, 9, 5, 6, 6, 0, 1, 6,\n",
            "        3, 5, 4, 7, 5, 5, 3, 0, 0, 6, 2, 4, 1, 8, 7, 6, 7, 0, 3, 5, 1, 8, 8, 7,\n",
            "        2, 9, 4, 0, 2, 1, 9, 4, 9, 9, 5, 5, 9, 0, 9, 7, 4, 1, 9, 6, 1, 2, 2, 1,\n",
            "        4, 5, 1, 6, 8, 9, 5, 8, 5, 1, 3, 4, 7, 4, 3, 2, 9, 3, 0, 3, 2, 0, 1, 6,\n",
            "        3, 0, 5, 2, 1, 0, 9, 4, 5, 8, 6, 4, 9, 0, 5, 9, 9, 0, 8, 3, 5, 9, 5, 7,\n",
            "        0, 9, 4, 2, 4, 1, 6, 7, 2, 3, 6, 3, 2, 6, 5, 0, 1, 7, 1, 8, 5, 3, 4, 9,\n",
            "        9, 6, 8, 2, 4, 7, 3, 2, 4, 7, 6, 3, 6, 8, 4, 4, 5, 3, 4, 8, 8, 4, 9, 7,\n",
            "        7, 1, 6, 8, 3, 1, 4, 8, 4, 8, 0, 2])\n",
            "tensor([[ 0.2181, -0.2759,  1.0730,  ..., -1.1183,  0.0651, -0.1544],\n",
            "        [ 0.1515,  0.1715,  0.4934,  ..., -0.6043, -0.2404, -0.1119],\n",
            "        [-0.2056, -0.0190, -0.1340,  ...,  0.3087,  0.2258,  0.4004],\n",
            "        ...,\n",
            "        [ 0.2466, -0.3348,  0.9249,  ..., -0.9554, -0.0233, -0.1602],\n",
            "        [ 0.1408,  0.2508,  0.2925,  ..., -0.4184, -0.2132, -0.0342],\n",
            "        [-0.2308,  0.0999, -0.1587,  ...,  0.2895,  0.0947,  0.1921]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([4, 4, 5, 4, 3, 2, 9, 3, 2, 7, 5, 0, 7, 9, 2, 3, 1, 4, 3, 7, 2, 2, 8, 4,\n",
            "        6, 4, 9, 8, 5, 6, 8, 6, 0, 4, 5, 3, 6, 2, 6, 3, 4, 5, 9, 7, 1, 7, 3, 9,\n",
            "        8, 0, 9, 6, 4, 3, 2, 2, 6, 3, 6, 9, 9, 1, 1, 7, 1, 2, 3, 3, 6, 7, 4, 9,\n",
            "        1, 6, 2, 0, 7, 9, 4, 9, 5, 9, 7, 2, 4, 1, 1, 4, 7, 6, 2, 9, 5, 0, 6, 6,\n",
            "        1, 4, 4, 3, 7, 1, 6, 2, 9, 5, 5, 6, 1, 4, 9, 4, 1, 6, 0, 1, 6, 2, 0, 4,\n",
            "        1, 2, 7, 4, 4, 8, 8, 0, 3, 4, 6, 3, 5, 7, 1, 6, 7, 2, 5, 5, 0, 5, 7, 5,\n",
            "        7, 4, 5, 7, 6, 0, 7, 8, 2, 9, 5, 4, 5, 3, 6, 9, 2, 3, 6, 4, 6, 2, 9, 8,\n",
            "        2, 6, 5, 6, 2, 4, 5, 4, 9, 0, 2, 6, 0, 5, 9, 2, 8, 5, 4, 9, 8, 5, 0, 8,\n",
            "        6, 7, 0, 7, 1, 7, 7, 1, 4, 1, 8, 8, 5, 8, 0, 3, 5, 7, 0, 6, 3, 7, 4, 4,\n",
            "        5, 1, 2, 0, 8, 8, 1, 2, 2, 1, 4, 9, 4, 8, 5, 5, 4, 3, 9, 9, 9, 2, 0, 2,\n",
            "        0, 5, 6, 6, 5, 4, 8, 2, 8, 2, 4, 2, 0, 5, 3, 5, 7, 4, 0, 4, 0, 5, 7, 4,\n",
            "        6, 7, 9, 5, 3, 0, 6, 5, 1, 8, 9, 5, 4, 6, 1, 0, 2, 9, 8, 2, 5, 7, 2, 4,\n",
            "        0, 8, 9, 0, 4, 7, 5, 0, 3, 6, 3, 5])\n",
            "tensor([[ 7.2183e-01,  9.2095e-02,  8.9823e-01,  ..., -9.5648e-01,\n",
            "         -2.6643e-01, -1.7919e-01],\n",
            "        [-3.0000e-01,  9.2176e-02, -2.9584e-01,  ...,  5.2389e-01,\n",
            "          2.8190e-01,  2.6486e-01],\n",
            "        [-1.1698e-01, -1.2022e-01,  1.6783e-01,  ..., -4.4838e-02,\n",
            "          6.8241e-01,  5.2345e-01],\n",
            "        ...,\n",
            "        [ 2.4064e-02,  1.5921e-01,  6.0471e-02,  ..., -7.1699e-02,\n",
            "          6.3867e-03,  5.8705e-03],\n",
            "        [ 6.1956e-01,  6.5084e-02,  5.8445e-01,  ..., -6.5304e-01,\n",
            "         -2.1526e-01, -1.6899e-01],\n",
            "        [ 1.9240e-04, -3.3430e-01,  6.1666e-01,  ..., -6.0847e-01,\n",
            "          3.1188e-01,  1.5582e-01]], grad_fn=<AddmmBackward>)\n",
            "tensor([0, 7, 8, 9, 3, 1, 8, 0, 5, 3, 7, 0, 6, 4, 8, 1, 6, 3, 4, 2, 2, 3, 2, 8,\n",
            "        7, 1, 0, 6, 5, 9, 6, 7, 0, 5, 7, 7, 1, 0, 9, 1, 8, 4, 7, 9, 0, 7, 7, 1,\n",
            "        3, 0, 0, 7, 6, 6, 0, 3, 7, 3, 7, 3, 1, 3, 5, 7, 9, 8, 4, 6, 9, 7, 6, 4,\n",
            "        6, 5, 8, 5, 2, 6, 3, 3, 4, 1, 8, 3, 9, 3, 0, 7, 2, 7, 7, 6, 6, 4, 0, 7,\n",
            "        2, 6, 1, 5, 2, 8, 0, 2, 6, 4, 8, 3, 8, 8, 7, 7, 8, 9, 1, 5, 0, 0, 9, 9,\n",
            "        9, 5, 0, 0, 4, 7, 1, 4, 7, 7, 0, 5, 4, 4, 0, 5, 0, 4, 1, 1, 1, 2, 8, 0,\n",
            "        6, 7, 6, 1, 6, 2, 4, 8, 2, 4, 0, 8, 0, 0, 1, 9, 4, 5, 7, 4, 1, 6, 5, 9,\n",
            "        1, 0, 2, 4, 0, 9, 2, 6, 7, 1, 9, 9, 8, 9, 5, 7, 6, 3, 7, 9, 8, 1, 2, 9,\n",
            "        9, 5, 6, 9, 8, 4, 4, 9, 3, 3, 7, 5, 7, 6, 3, 8, 4, 3, 4, 9, 1, 3, 7, 7,\n",
            "        7, 8, 9, 1, 0, 0, 3, 7, 6, 2, 5, 2, 4, 3, 3, 4, 4, 4, 5, 4, 6, 6, 6, 6,\n",
            "        9, 8, 5, 5, 0, 0, 2, 0, 2, 6, 9, 8, 8, 0, 2, 3, 8, 8, 1, 3, 9, 5, 1, 0,\n",
            "        1, 6, 6, 5, 3, 6, 8, 1, 8, 9, 5, 7, 9, 7, 1, 2, 8, 6, 0, 5, 9, 0, 1, 4,\n",
            "        6, 2, 5, 6, 0, 2, 0, 1, 1, 0, 0, 8])\n",
            "tensor([[ 0.1227, -0.3267,  0.3766,  ..., -0.1227,  0.6800,  0.5611],\n",
            "        [ 0.0210, -0.2205,  0.4526,  ..., -0.0308,  0.8079,  0.6922],\n",
            "        [ 0.0216,  0.1994,  0.2314,  ..., -0.2475, -0.0702, -0.1177],\n",
            "        ...,\n",
            "        [-0.2495, -0.2800,  0.0751,  ...,  0.4243,  0.9143,  0.7128],\n",
            "        [ 0.1556,  0.3706,  0.1698,  ..., -0.3313,  0.0224, -0.0788],\n",
            "        [ 0.7630,  0.0651,  0.6840,  ..., -0.8929, -0.2684, -0.2115]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([8, 8, 3, 4, 7, 3, 8, 2, 6, 1, 3, 6, 7, 8, 6, 0, 1, 3, 0, 4, 6, 5, 7, 9,\n",
            "        7, 7, 1, 1, 0, 9, 2, 3, 0, 5, 6, 3, 9, 5, 8, 2, 3, 2, 3, 6, 0, 3, 1, 6,\n",
            "        6, 3, 2, 1, 3, 1, 6, 4, 0, 0, 2, 3, 6, 2, 1, 0, 1, 8, 3, 6, 0, 4, 8, 8,\n",
            "        0, 4, 7, 3, 8, 9, 5, 4, 4, 7, 4, 3, 4, 2, 5, 8, 0, 5, 7, 7, 4, 8, 3, 3,\n",
            "        3, 2, 0, 8, 1, 0, 4, 4, 8, 6, 7, 3, 2, 4, 4, 2, 5, 6, 8, 4, 9, 4, 6, 9,\n",
            "        7, 2, 4, 7, 2, 1, 4, 9, 8, 7, 5, 7, 6, 0, 6, 6, 4, 1, 9, 4, 6, 5, 7, 6,\n",
            "        8, 7, 7, 4, 7, 6, 3, 8, 6, 1, 2, 3, 3, 8, 1, 2, 0, 1, 7, 6, 5, 4, 4, 3,\n",
            "        8, 4, 8, 1, 8, 4, 4, 4, 4, 1, 0, 3, 2, 3, 2, 8, 8, 3, 1, 3, 1, 6, 4, 7,\n",
            "        5, 3, 7, 2, 5, 7, 4, 6, 2, 2, 2, 7, 3, 0, 1, 2, 0, 7, 1, 6, 1, 8, 9, 5,\n",
            "        5, 2, 5, 5, 3, 0, 9, 6, 2, 7, 5, 3, 8, 4, 5, 0, 0, 6, 4, 2, 2, 1, 8, 1,\n",
            "        7, 7, 4, 5, 7, 1, 5, 2, 6, 5, 3, 1, 5, 8, 9, 3, 9, 8, 1, 7, 9, 7, 8, 3,\n",
            "        0, 0, 9, 7, 6, 6, 2, 1, 3, 8, 7, 7, 4, 9, 1, 7, 6, 8, 7, 5, 7, 4, 9, 4,\n",
            "        9, 5, 4, 0, 5, 8, 5, 2, 8, 8, 0, 0])\n",
            "tensor([[-0.1437, -0.0896,  0.1418,  ..., -0.1244,  0.4984,  0.0273],\n",
            "        [-0.1894,  0.1231, -0.1281,  ...,  0.4283,  0.1108,  0.2287],\n",
            "        [-0.2518,  0.2128, -0.1199,  ...,  0.3260,  0.2669,  0.2504],\n",
            "        ...,\n",
            "        [ 0.1331, -0.2263,  1.0190,  ..., -0.8801,  0.1822, -0.0508],\n",
            "        [ 0.1089, -0.3004,  0.7802,  ..., -0.8947,  0.1400, -0.1178],\n",
            "        [ 0.2243,  0.1557,  0.2960,  ..., -0.3815, -0.2155, -0.0714]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([8, 5, 5, 6, 1, 9, 8, 1, 0, 9, 6, 8, 2, 7, 0, 2, 6, 4, 0, 0, 6, 5, 2, 9,\n",
            "        5, 6, 4, 2, 9, 9, 0, 8, 9, 4, 5, 8, 8, 6, 8, 9, 5, 5, 9, 4, 7, 2, 4, 1,\n",
            "        4, 4, 9, 2, 2, 3, 1, 2, 7, 6, 8, 9, 8, 4, 3, 0, 1, 4, 1, 9, 2, 3, 3, 9,\n",
            "        1, 3, 6, 8, 3, 3, 2, 9, 9, 5, 3, 5, 0, 2, 3, 9, 8, 9, 4, 3, 1, 8, 2, 0,\n",
            "        5, 1, 7, 9, 6, 1, 4, 5, 8, 9, 8, 2, 8, 6, 8, 7, 1, 6, 5, 3, 2, 4, 1, 5,\n",
            "        3, 3, 8, 2, 5, 1, 1, 6, 6, 8, 3, 2, 8, 0, 9, 3, 1, 8, 4, 0, 4, 9, 6, 2,\n",
            "        0, 7, 1, 6, 3, 3, 1, 2, 0, 1, 3, 1, 3, 0, 1, 6, 9, 3, 6, 6, 9, 6, 0, 5,\n",
            "        4, 5, 2, 6, 9, 2, 1, 4, 7, 8, 2, 2, 3, 6, 2, 8, 2, 0, 1, 9, 0, 1, 0, 9,\n",
            "        5, 1, 5, 8, 5, 4, 0, 6, 7, 8, 1, 4, 5, 6, 4, 3, 9, 8, 9, 4, 9, 7, 7, 3,\n",
            "        5, 3, 5, 8, 1, 8, 7, 7, 3, 2, 7, 5, 4, 4, 2, 6, 1, 2, 9, 7, 4, 7, 2, 5,\n",
            "        3, 3, 3, 1, 7, 7, 6, 5, 8, 3, 9, 7, 3, 6, 8, 3, 2, 1, 1, 9, 4, 0, 5, 7,\n",
            "        1, 3, 4, 2, 2, 1, 0, 5, 4, 5, 2, 6, 8, 2, 9, 3, 2, 2, 0, 6, 6, 3, 9, 8,\n",
            "        8, 2, 6, 5, 8, 7, 9, 4, 8, 4, 4, 0])\n",
            "tensor([[ 0.1597,  0.7136,  0.3630,  ..., -0.4367, -0.2051, -0.1722],\n",
            "        [-0.3656, -0.0579, -0.3209,  ...,  0.8410,  0.3292,  0.4613],\n",
            "        [-0.4575,  0.0387, -0.4889,  ...,  1.1936,  0.4261,  0.5951],\n",
            "        ...,\n",
            "        [-0.2497, -0.1705,  0.0513,  ..., -0.1037,  0.6099,  0.2882],\n",
            "        [-0.0385,  0.9195,  0.3893,  ..., -0.2860, -0.3196, -0.2373],\n",
            "        [-0.2313,  0.0766, -0.1391,  ...,  0.3087,  0.2094,  0.2876]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([1, 7, 7, 2, 5, 8, 9, 5, 0, 5, 3, 2, 2, 8, 5, 9, 6, 5, 1, 3, 8, 7, 3, 2,\n",
            "        7, 8, 1, 4, 2, 7, 4, 4, 9, 2, 7, 5, 2, 1, 0, 3, 4, 6, 0, 2, 4, 0, 8, 8,\n",
            "        7, 9, 9, 2, 4, 4, 5, 0, 0, 8, 1, 2, 1, 8, 3, 3, 3, 5, 7, 7, 5, 0, 7, 8,\n",
            "        8, 4, 6, 7, 1, 4, 4, 9, 4, 3, 2, 6, 7, 9, 9, 2, 4, 8, 4, 3, 1, 3, 4, 0,\n",
            "        6, 0, 8, 3, 8, 5, 5, 5, 9, 4, 2, 8, 3, 5, 6, 6, 3, 4, 0, 6, 2, 8, 9, 2,\n",
            "        4, 5, 6, 8, 3, 8, 2, 8, 8, 1, 3, 6, 0, 2, 9, 9, 8, 0, 8, 1, 9, 8, 9, 7,\n",
            "        9, 5, 9, 8, 3, 6, 5, 6, 1, 9, 5, 0, 2, 7, 3, 2, 8, 7, 9, 3, 9, 4, 6, 2,\n",
            "        2, 5, 4, 9, 5, 8, 4, 9, 6, 9, 2, 1, 1, 7, 0, 9, 1, 8, 6, 3, 7, 8, 0, 0,\n",
            "        2, 5, 2, 3, 2, 0, 6, 1, 0, 7, 4, 9, 5, 8, 8, 6, 6, 3, 3, 4, 5, 4, 0, 9,\n",
            "        1, 6, 7, 2, 9, 0, 7, 3, 6, 3, 5, 5, 3, 4, 1, 6, 9, 6, 2, 7, 7, 2, 9, 9,\n",
            "        1, 7, 0, 3, 9, 5, 4, 0, 3, 8, 4, 2, 5, 4, 2, 0, 7, 5, 4, 6, 5, 9, 9, 8,\n",
            "        0, 6, 7, 6, 3, 5, 3, 2, 6, 5, 7, 0, 9, 4, 3, 4, 5, 5, 7, 3, 4, 7, 3, 7,\n",
            "        5, 9, 9, 1, 5, 3, 6, 8, 5, 8, 1, 5])\n",
            "tensor([[ 0.1805, -0.1355,  0.7391,  ..., -0.8142, -0.0197, -0.1752],\n",
            "        [ 0.5014,  0.3106,  0.5049,  ..., -0.5987, -0.2082, -0.2267],\n",
            "        [ 0.4324,  0.7381,  0.7641,  ..., -0.9458, -0.3514, -0.3975],\n",
            "        ...,\n",
            "        [-0.3032,  0.1010, -0.1719,  ...,  0.2648,  0.3549,  0.4528],\n",
            "        [-0.3912,  0.0103, -0.2700,  ...,  0.6878,  0.3045,  0.3968],\n",
            "        [ 0.0404,  1.2182,  0.4865,  ..., -0.3536, -0.2335, -0.2828]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([6, 0, 1, 4, 3, 5, 9, 6, 3, 9, 7, 9, 2, 8, 6, 5, 4, 3, 8, 8, 5, 4, 7, 9,\n",
            "        7, 9, 5, 1, 0, 8, 8, 2, 8, 4, 9, 8, 3, 4, 4, 8, 2, 6, 9, 2, 2, 0, 1, 2,\n",
            "        0, 4, 1, 9, 3, 3, 6, 9, 0, 3, 7, 8, 1, 4, 4, 0, 7, 1, 7, 7, 7, 2, 8, 4,\n",
            "        5, 2, 1, 9, 2, 7, 8, 1, 1, 9, 6, 4, 9, 2, 3, 7, 7, 3, 4, 2, 0, 3, 9, 2,\n",
            "        3, 4, 2, 7, 8, 9, 3, 7, 0, 1, 0, 6, 1, 6, 0, 0, 9, 0, 6, 8, 4, 1, 8, 9,\n",
            "        1, 3, 0, 7, 5, 8, 5, 1, 7, 0, 0, 5, 3, 2, 8, 4, 6, 6, 9, 1, 8, 9, 7, 8,\n",
            "        5, 2, 8, 1, 7, 8, 2, 9, 7, 1, 4, 4, 7, 2, 5, 3, 5, 4, 8, 1, 6, 7, 6, 4,\n",
            "        4, 5, 4, 2, 1, 0, 7, 5, 2, 4, 3, 2, 9, 8, 9, 0, 8, 8, 6, 4, 8, 6, 7, 7,\n",
            "        9, 0, 5, 6, 4, 4, 5, 9, 6, 1, 5, 9, 0, 6, 6, 4, 2, 5, 0, 4, 8, 2, 0, 0,\n",
            "        9, 5, 6, 7, 4, 9, 7, 7, 9, 1, 6, 9, 0, 5, 4, 9, 8, 7, 3, 6, 8, 7, 8, 8,\n",
            "        1, 2, 0, 6, 1, 6, 3, 0, 3, 6, 0, 0, 6, 1, 6, 6, 5, 8, 6, 4, 5, 8, 8, 5,\n",
            "        2, 6, 2, 2, 5, 5, 2, 5, 9, 9, 3, 8, 5, 6, 0, 9, 8, 1, 9, 0, 7, 5, 8, 9,\n",
            "        8, 0, 4, 0, 5, 4, 7, 3, 1, 5, 5, 1])\n",
            "tensor([[-0.2777, -0.3330, -0.0785,  ...,  0.1357,  0.5916,  0.8866],\n",
            "        [ 0.3952, -0.2593,  0.8870,  ..., -1.0406, -0.1254, -0.1750],\n",
            "        [-0.2370, -0.0420,  0.0454,  ...,  0.3596,  0.4949,  0.3805],\n",
            "        ...,\n",
            "        [-0.3392,  0.0227, -0.2056,  ...,  0.4699,  0.2264,  0.2672],\n",
            "        [ 0.0033, -0.2459,  0.7591,  ..., -0.7647,  0.2052,  0.0813],\n",
            "        [ 0.0809,  1.3361,  0.6056,  ..., -0.4922, -0.1038, -0.2937]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([9, 6, 8, 6, 1, 3, 8, 2, 8, 2, 8, 5, 3, 4, 5, 9, 5, 2, 6, 4, 8, 3, 0, 6,\n",
            "        0, 6, 7, 2, 8, 4, 8, 8, 5, 9, 5, 4, 2, 7, 9, 6, 5, 9, 0, 9, 8, 4, 5, 9,\n",
            "        3, 3, 2, 4, 4, 3, 9, 5, 6, 4, 9, 4, 8, 3, 8, 9, 6, 5, 3, 4, 9, 1, 4, 6,\n",
            "        9, 1, 8, 3, 3, 0, 4, 4, 7, 7, 2, 5, 4, 7, 0, 1, 7, 6, 4, 1, 2, 8, 2, 0,\n",
            "        7, 8, 8, 8, 7, 4, 1, 1, 3, 0, 9, 5, 5, 9, 6, 0, 3, 9, 5, 9, 5, 5, 4, 2,\n",
            "        1, 1, 4, 1, 4, 2, 9, 4, 3, 5, 3, 9, 8, 4, 7, 3, 7, 7, 6, 1, 2, 5, 7, 4,\n",
            "        1, 1, 4, 4, 6, 8, 1, 2, 2, 8, 8, 4, 8, 6, 1, 4, 4, 1, 0, 9, 9, 0, 2, 4,\n",
            "        5, 1, 4, 8, 3, 8, 8, 8, 3, 4, 0, 3, 1, 8, 8, 7, 9, 7, 0, 4, 3, 4, 5, 8,\n",
            "        6, 2, 0, 2, 1, 0, 5, 8, 2, 2, 6, 7, 5, 5, 3, 5, 4, 4, 1, 8, 6, 2, 7, 3,\n",
            "        9, 9, 0, 5, 2, 5, 1, 6, 0, 3, 6, 6, 5, 0, 4, 9, 3, 2, 3, 1, 2, 4, 5, 7,\n",
            "        8, 7, 2, 8, 1, 1, 0, 8, 3, 2, 4, 8, 9, 4, 3, 5, 5, 2, 9, 4, 5, 0, 4, 8,\n",
            "        0, 6, 6, 4, 2, 5, 5, 8, 3, 8, 5, 4, 5, 8, 5, 6, 0, 6, 8, 5, 9, 3, 8, 4,\n",
            "        0, 5, 5, 3, 6, 9, 2, 5, 5, 5, 4, 1])\n",
            "tensor([[ 0.4297,  0.5879,  0.7099,  ..., -0.8674, -0.2658, -0.3908],\n",
            "        [-0.1385, -0.2995,  0.1380,  ...,  0.1039,  0.8218,  0.6307],\n",
            "        [-0.0440,  1.1836,  0.4653,  ..., -0.3090, -0.1591, -0.2134],\n",
            "        ...,\n",
            "        [ 0.0148, -0.3833,  0.4415,  ..., -0.4458,  0.4818,  0.2108],\n",
            "        [-0.3653, -0.2197,  0.0290,  ...,  0.1324,  0.9805,  0.9021],\n",
            "        [-0.0480, -0.3197,  0.3118,  ..., -0.4092,  0.3496,  0.1435]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([3, 8, 1, 3, 4, 4, 2, 0, 8, 8, 6, 0, 1, 1, 7, 0, 7, 0, 0, 3, 4, 2, 2, 0,\n",
            "        2, 1, 0, 6, 6, 4, 0, 1, 3, 6, 7, 1, 1, 5, 9, 6, 0, 1, 1, 9, 9, 8, 1, 7,\n",
            "        4, 5, 8, 4, 9, 9, 3, 7, 6, 8, 0, 7, 6, 2, 6, 9, 5, 0, 8, 7, 6, 3, 7, 6,\n",
            "        2, 0, 3, 3, 9, 4, 2, 8, 3, 2, 7, 6, 8, 1, 8, 0, 3, 6, 9, 1, 5, 9, 1, 8,\n",
            "        0, 5, 9, 4, 9, 4, 9, 1, 3, 0, 2, 0, 7, 0, 3, 1, 7, 1, 3, 7, 5, 0, 0, 9,\n",
            "        6, 2, 3, 7, 7, 4, 3, 8, 7, 5, 4, 7, 6, 3, 8, 8, 8, 9, 2, 7, 2, 3, 6, 0,\n",
            "        7, 4, 9, 6, 6, 4, 2, 2, 1, 4, 8, 1, 4, 2, 5, 3, 7, 4, 3, 9, 8, 8, 4, 9,\n",
            "        5, 7, 6, 3, 7, 4, 8, 2, 0, 8, 5, 2, 8, 0, 1, 0, 0, 0, 9, 3, 0, 8, 1, 1,\n",
            "        2, 1, 4, 2, 4, 7, 9, 4, 9, 5, 9, 1, 0, 6, 1, 0, 1, 2, 8, 7, 2, 5, 2, 7,\n",
            "        5, 6, 7, 8, 4, 2, 7, 5, 2, 0, 9, 1, 2, 8, 4, 1, 8, 7, 0, 6, 2, 0, 8, 7,\n",
            "        8, 3, 3, 1, 3, 8, 4, 3, 0, 9, 2, 4, 3, 3, 7, 0, 9, 4, 1, 1, 2, 0, 9, 4,\n",
            "        4, 2, 7, 1, 2, 5, 7, 7, 4, 7, 7, 1, 7, 9, 3, 7, 3, 7, 0, 5, 8, 1, 4, 0,\n",
            "        1, 1, 6, 4, 1, 8, 9, 0, 5, 8, 5, 8])\n",
            "tensor([[ 0.2275,  1.3712,  0.6388,  ..., -0.6917, -0.2477, -0.3422],\n",
            "        [ 0.2081,  0.7104,  0.5534,  ..., -0.6213, -0.3390, -0.2869],\n",
            "        [ 0.1239,  0.1459,  0.2754,  ..., -0.3635, -0.0414, -0.0636],\n",
            "        ...,\n",
            "        [-0.4913, -0.2328, -0.3405,  ...,  0.9350,  1.1573,  1.2981],\n",
            "        [ 0.0390, -0.2639,  0.6513,  ..., -0.7549,  0.1788,  0.0420],\n",
            "        [-0.3197,  0.1382, -0.2994,  ...,  0.8721,  0.2784,  0.3883]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([1, 3, 4, 9, 3, 6, 8, 8, 6, 9, 9, 9, 2, 6, 3, 4, 0, 4, 5, 8, 2, 9, 3, 9,\n",
            "        5, 8, 6, 1, 8, 4, 0, 6, 1, 6, 8, 0, 8, 1, 5, 7, 2, 5, 2, 2, 2, 1, 9, 7,\n",
            "        9, 3, 7, 3, 2, 8, 4, 2, 1, 7, 4, 4, 2, 5, 6, 2, 8, 7, 4, 0, 5, 1, 5, 4,\n",
            "        9, 3, 5, 9, 2, 1, 8, 2, 0, 4, 9, 7, 7, 8, 7, 3, 4, 0, 2, 7, 4, 7, 6, 7,\n",
            "        8, 2, 4, 4, 8, 6, 0, 0, 2, 6, 6, 6, 9, 8, 1, 8, 9, 4, 7, 3, 9, 6, 1, 8,\n",
            "        7, 3, 6, 6, 0, 1, 9, 6, 3, 1, 0, 5, 7, 0, 8, 1, 9, 7, 9, 2, 1, 4, 3, 3,\n",
            "        0, 4, 0, 7, 2, 3, 0, 3, 5, 8, 3, 4, 5, 0, 0, 2, 1, 9, 2, 7, 4, 7, 3, 5,\n",
            "        9, 2, 4, 9, 1, 5, 7, 8, 7, 4, 3, 5, 0, 1, 7, 1, 7, 9, 2, 8, 3, 7, 3, 1,\n",
            "        8, 7, 8, 8, 1, 4, 3, 9, 8, 2, 1, 5, 3, 1, 1, 7, 3, 0, 5, 9, 1, 5, 6, 6,\n",
            "        2, 4, 8, 5, 7, 1, 9, 1, 9, 5, 6, 9, 2, 3, 3, 3, 1, 6, 5, 1, 2, 0, 7, 2,\n",
            "        4, 0, 2, 4, 3, 5, 8, 1, 5, 6, 1, 7, 9, 1, 1, 6, 8, 3, 7, 9, 9, 0, 6, 8,\n",
            "        6, 1, 6, 0, 1, 3, 5, 5, 6, 3, 7, 8, 6, 1, 1, 8, 0, 8, 1, 3, 7, 4, 4, 5,\n",
            "        8, 2, 5, 9, 3, 9, 0, 7, 4, 9, 4, 5])\n",
            "tensor([[ 0.0816, -0.2827,  0.9027,  ..., -0.7374,  0.2020, -0.1168],\n",
            "        [-0.2470, -0.1169, -0.0317,  ...,  0.0734,  0.5703,  0.4347],\n",
            "        [-0.3627, -0.2331, -0.1826,  ...,  0.7694,  0.9946,  0.6361],\n",
            "        ...,\n",
            "        [ 0.5769,  0.0575,  0.5506,  ..., -0.7651, -0.0723, -0.1834],\n",
            "        [ 0.1146,  0.2385,  0.4170,  ..., -0.5803, -0.0920, -0.2612],\n",
            "        [-0.3525,  0.0931, -0.4387,  ...,  0.9957,  0.3140,  0.4752]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([4, 8, 8, 0, 8, 8, 9, 6, 8, 0, 7, 2, 2, 5, 1, 9, 6, 1, 2, 6, 8, 1, 8, 1,\n",
            "        0, 0, 0, 0, 8, 5, 4, 6, 5, 5, 1, 1, 4, 7, 9, 4, 6, 7, 0, 5, 8, 3, 1, 9,\n",
            "        2, 7, 4, 0, 5, 9, 2, 1, 9, 1, 5, 0, 8, 1, 0, 9, 5, 3, 5, 5, 1, 2, 5, 2,\n",
            "        0, 8, 9, 5, 1, 2, 9, 8, 1, 7, 7, 7, 3, 8, 8, 8, 7, 1, 9, 9, 9, 1, 2, 4,\n",
            "        9, 7, 9, 3, 1, 9, 0, 2, 7, 0, 0, 4, 2, 9, 9, 9, 2, 0, 3, 3, 9, 6, 2, 8,\n",
            "        1, 2, 0, 3, 9, 2, 3, 8, 2, 3, 9, 4, 8, 3, 0, 2, 2, 3, 2, 3, 1, 0, 5, 1,\n",
            "        1, 2, 4, 7, 2, 3, 1, 0, 0, 0, 7, 5, 0, 3, 2, 0, 4, 5, 0, 9, 4, 6, 6, 1,\n",
            "        3, 8, 7, 1, 2, 8, 9, 8, 7, 2, 2, 0, 5, 6, 6, 7, 1, 6, 5, 6, 7, 6, 0, 7,\n",
            "        8, 1, 1, 3, 7, 0, 1, 7, 0, 3, 6, 8, 2, 5, 1, 9, 2, 0, 7, 5, 7, 8, 5, 6,\n",
            "        5, 3, 8, 4, 4, 9, 8, 8, 0, 3, 7, 5, 0, 3, 5, 7, 7, 6, 2, 0, 4, 7, 2, 2,\n",
            "        2, 4, 1, 4, 1, 2, 6, 6, 4, 4, 2, 7, 1, 9, 9, 7, 3, 0, 6, 6, 6, 6, 2, 5,\n",
            "        9, 9, 7, 0, 7, 6, 4, 4, 7, 8, 7, 6, 6, 0, 1, 6, 7, 0, 4, 9, 0, 5, 2, 5,\n",
            "        0, 9, 0, 5, 3, 7, 8, 9, 4, 0, 6, 7])\n",
            "tensor([[ 0.0780,  0.3293,  0.2318,  ..., -0.3706, -0.0169, -0.0596],\n",
            "        [ 0.3654, -0.2457,  1.2122,  ..., -1.3097,  0.1175, -0.2579],\n",
            "        [-0.3654,  0.0098, -0.4124,  ...,  0.9889,  0.5962,  0.8343],\n",
            "        ...,\n",
            "        [ 0.0174,  0.0484,  0.1586,  ..., -0.2808,  0.0548,  0.0123],\n",
            "        [-0.4221, -0.1614, -0.3567,  ...,  0.8298,  1.0717,  1.2132],\n",
            "        [-0.2640,  0.0818, -0.1847,  ...,  0.4209,  0.2561,  0.3068]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([3, 6, 7, 4, 4, 8, 2, 9, 6, 4, 0, 6, 3, 8, 0, 4, 7, 6, 9, 9, 5, 8, 5, 9,\n",
            "        6, 3, 0, 6, 9, 0, 2, 2, 9, 1, 4, 3, 5, 8, 0, 2, 2, 1, 1, 8, 9, 5, 0, 3,\n",
            "        6, 3, 2, 3, 0, 9, 5, 7, 0, 5, 3, 2, 0, 9, 3, 6, 0, 8, 6, 0, 4, 0, 0, 6,\n",
            "        2, 4, 8, 7, 8, 3, 0, 1, 5, 2, 1, 2, 4, 7, 8, 5, 7, 2, 0, 3, 9, 3, 0, 9,\n",
            "        8, 2, 4, 7, 1, 7, 9, 0, 6, 0, 1, 6, 7, 0, 2, 7, 5, 6, 4, 2, 0, 1, 5, 3,\n",
            "        8, 7, 6, 8, 9, 9, 8, 8, 1, 4, 4, 8, 2, 6, 6, 5, 5, 3, 0, 8, 0, 8, 5, 1,\n",
            "        6, 6, 9, 3, 6, 3, 8, 4, 2, 2, 5, 7, 3, 8, 9, 3, 7, 0, 4, 2, 5, 1, 5, 6,\n",
            "        9, 5, 4, 0, 4, 2, 1, 2, 0, 7, 0, 9, 7, 2, 4, 7, 1, 9, 1, 6, 1, 6, 0, 3,\n",
            "        0, 5, 4, 1, 8, 7, 2, 2, 8, 3, 2, 1, 2, 4, 7, 8, 4, 5, 8, 9, 2, 3, 4, 8,\n",
            "        2, 6, 4, 2, 8, 7, 5, 4, 4, 7, 5, 3, 6, 3, 4, 8, 4, 0, 2, 3, 4, 2, 3, 9,\n",
            "        6, 4, 9, 0, 1, 3, 8, 1, 2, 7, 3, 6, 1, 7, 4, 4, 3, 2, 6, 6, 2, 7, 4, 0,\n",
            "        1, 4, 0, 0, 1, 1, 9, 5, 7, 0, 7, 8, 1, 2, 2, 2, 7, 4, 2, 2, 8, 2, 5, 2,\n",
            "        1, 9, 1, 2, 9, 9, 3, 4, 8, 2, 9, 5])\n",
            "tensor([[ 0.3762, -0.4137,  1.2499,  ..., -1.2626,  0.4242,  0.0398],\n",
            "        [ 0.4992, -0.3724,  1.4089,  ..., -1.4472,  0.1128, -0.3012],\n",
            "        [-0.1725, -0.2183,  0.0639,  ...,  0.0088,  0.4822,  0.9207],\n",
            "        ...,\n",
            "        [-0.0345,  1.1022,  0.3351,  ..., -0.2795, -0.1065, -0.2475],\n",
            "        [ 0.0118, -0.0358,  0.0882,  ..., -0.1132,  0.1843,  0.1668],\n",
            "        [ 0.1310, -0.0077,  0.3684,  ..., -0.4796,  0.0370, -0.0171]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([4, 6, 9, 6, 9, 7, 0, 6, 5, 9, 0, 9, 2, 9, 9, 9, 6, 8, 9, 5, 6, 7, 2, 2,\n",
            "        3, 6, 5, 2, 1, 1, 7, 6, 9, 4, 4, 4, 4, 1, 9, 0, 2, 4, 1, 5, 1, 7, 5, 8,\n",
            "        9, 8, 3, 5, 7, 7, 4, 5, 0, 3, 4, 5, 5, 4, 1, 2, 3, 9, 3, 7, 1, 9, 5, 4,\n",
            "        6, 0, 0, 0, 2, 7, 6, 2, 8, 4, 5, 9, 9, 4, 7, 8, 3, 4, 9, 0, 1, 9, 9, 9,\n",
            "        2, 0, 1, 6, 4, 5, 8, 8, 4, 9, 5, 9, 3, 2, 6, 5, 4, 6, 1, 5, 4, 1, 3, 0,\n",
            "        2, 0, 1, 3, 4, 4, 9, 1, 1, 6, 7, 7, 9, 9, 1, 5, 6, 6, 9, 5, 6, 3, 2, 9,\n",
            "        8, 3, 7, 8, 7, 7, 1, 5, 0, 2, 0, 2, 8, 2, 5, 9, 2, 1, 1, 5, 1, 9, 0, 3,\n",
            "        3, 6, 2, 6, 0, 5, 6, 9, 3, 8, 4, 0, 9, 5, 7, 1, 6, 9, 2, 4, 3, 1, 7, 5,\n",
            "        9, 9, 7, 7, 3, 0, 9, 7, 9, 4, 4, 7, 0, 3, 7, 5, 5, 4, 3, 6, 8, 6, 4, 0,\n",
            "        0, 0, 4, 0, 1, 2, 3, 9, 0, 6, 8, 9, 8, 8, 3, 6, 0, 3, 4, 6, 0, 1, 5, 5,\n",
            "        3, 5, 2, 4, 6, 1, 7, 4, 8, 5, 9, 6, 6, 1, 5, 0, 6, 8, 2, 7, 0, 0, 0, 5,\n",
            "        7, 0, 9, 1, 5, 8, 9, 1, 0, 5, 5, 9, 5, 1, 8, 0, 3, 3, 3, 5, 2, 0, 7, 6,\n",
            "        6, 6, 3, 5, 8, 5, 5, 2, 0, 1, 6, 6])\n",
            "tensor([[ 4.1179e-01, -2.4517e-01,  1.1211e+00,  ..., -1.2254e+00,\n",
            "          1.2997e-01, -2.4134e-01],\n",
            "        [ 2.3568e-01, -2.5489e-02,  7.0979e-01,  ..., -7.1258e-01,\n",
            "          4.0590e-02, -1.6264e-01],\n",
            "        [ 8.9271e-02,  2.0632e-02,  3.3415e-01,  ..., -4.7778e-01,\n",
            "         -2.2491e-02, -5.1321e-03],\n",
            "        ...,\n",
            "        [-4.0733e-01, -3.2164e-04, -4.5849e-01,  ...,  1.1423e+00,\n",
            "          5.5910e-01,  6.3025e-01],\n",
            "        [ 6.7218e-01, -2.2727e-01,  9.6126e-01,  ..., -1.0026e+00,\n",
            "         -1.8712e-02, -9.1407e-02],\n",
            "        [-1.2634e-01,  3.3607e-01,  9.9806e-02,  ..., -1.9748e-01,\n",
            "         -5.4779e-02, -7.6806e-02]], grad_fn=<AddmmBackward>)\n",
            "tensor([2, 2, 6, 4, 9, 5, 8, 9, 7, 4, 5, 1, 5, 5, 0, 2, 4, 3, 1, 5, 0, 5, 8, 4,\n",
            "        9, 9, 4, 1, 5, 2, 8, 1, 2, 1, 8, 5, 1, 6, 0, 3, 7, 4, 3, 6, 8, 6, 7, 1,\n",
            "        2, 0, 2, 8, 9, 8, 9, 2, 7, 9, 3, 5, 9, 9, 9, 8, 1, 6, 3, 2, 6, 1, 9, 1,\n",
            "        7, 8, 5, 8, 8, 1, 8, 7, 7, 0, 9, 0, 1, 7, 7, 5, 7, 5, 7, 5, 4, 6, 1, 2,\n",
            "        3, 9, 8, 8, 6, 2, 9, 6, 6, 8, 9, 8, 0, 6, 4, 7, 7, 6, 9, 5, 9, 2, 6, 5,\n",
            "        6, 6, 6, 0, 5, 5, 0, 6, 3, 1, 8, 6, 5, 7, 7, 1, 2, 4, 4, 9, 2, 4, 6, 4,\n",
            "        9, 5, 3, 0, 3, 5, 2, 1, 2, 5, 9, 1, 0, 9, 1, 8, 2, 0, 2, 5, 8, 9, 1, 6,\n",
            "        5, 9, 7, 9, 0, 1, 0, 1, 9, 4, 9, 9, 0, 7, 8, 6, 0, 6, 5, 0, 8, 8, 8, 3,\n",
            "        6, 5, 6, 3, 6, 4, 2, 8, 7, 3, 6, 4, 1, 8, 2, 9, 1, 9, 2, 6, 1, 9, 6, 7,\n",
            "        9, 4, 7, 4, 8, 1, 1, 2, 0, 1, 0, 4, 5, 4, 4, 6, 5, 2, 3, 4, 5, 8, 3, 8,\n",
            "        9, 4, 3, 4, 0, 7, 2, 6, 3, 1, 9, 6, 2, 7, 9, 7, 0, 5, 4, 5, 1, 7, 5, 2,\n",
            "        4, 9, 8, 5, 7, 5, 1, 0, 2, 7, 2, 6, 7, 9, 9, 0, 7, 2, 4, 9, 4, 2, 6, 4,\n",
            "        9, 0, 1, 5, 6, 2, 7, 1, 8, 7, 0, 3])\n",
            "tensor([[ 0.2569, -0.0291,  0.4846,  ..., -0.5089,  0.1430,  0.0375],\n",
            "        [-0.3678,  0.0272, -0.4078,  ...,  0.8827,  0.4777,  0.6490],\n",
            "        [ 0.4801,  0.0767,  0.7657,  ..., -0.9033,  0.0042, -0.1438],\n",
            "        ...,\n",
            "        [ 0.1796, -0.1745,  0.1359,  ..., -0.2881,  0.2921,  0.1933],\n",
            "        [-0.4841,  0.0810, -0.5104,  ...,  1.2520,  0.4353,  0.6046],\n",
            "        [-0.1286, -0.3696,  0.3567,  ..., -0.1379,  0.6658,  0.4056]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([2, 7, 1, 1, 2, 4, 3, 7, 5, 9, 3, 7, 0, 7, 7, 4, 5, 3, 4, 8, 3, 9, 4, 9,\n",
            "        0, 7, 7, 1, 8, 9, 4, 1, 6, 0, 4, 2, 1, 0, 6, 2, 3, 3, 1, 0, 0, 7, 3, 4,\n",
            "        4, 4, 7, 3, 0, 5, 6, 6, 1, 0, 6, 6, 6, 2, 3, 3, 5, 5, 2, 9, 0, 8, 5, 8,\n",
            "        1, 1, 7, 3, 5, 8, 1, 0, 4, 8, 2, 4, 7, 2, 5, 9, 4, 7, 1, 2, 6, 6, 0, 1,\n",
            "        3, 7, 3, 2, 2, 0, 2, 0, 4, 3, 1, 4, 8, 5, 2, 4, 9, 9, 6, 7, 4, 2, 1, 8,\n",
            "        9, 3, 3, 4, 6, 1, 1, 1, 7, 8, 4, 8, 1, 8, 3, 9, 7, 6, 1, 7, 4, 6, 5, 7,\n",
            "        8, 2, 3, 5, 6, 6, 8, 7, 4, 1, 8, 1, 4, 0, 1, 3, 0, 9, 2, 1, 6, 0, 9, 0,\n",
            "        5, 2, 5, 2, 0, 8, 1, 0, 6, 6, 0, 5, 4, 7, 9, 6, 6, 6, 5, 6, 0, 6, 4, 5,\n",
            "        8, 6, 3, 0, 8, 6, 4, 0, 4, 6, 2, 9, 4, 5, 9, 1, 3, 8, 3, 0, 3, 4, 5, 9,\n",
            "        4, 5, 0, 2, 4, 0, 3, 8, 8, 3, 5, 6, 9, 4, 4, 4, 7, 2, 8, 1, 7, 8, 5, 7,\n",
            "        7, 4, 6, 2, 1, 5, 3, 8, 6, 4, 6, 2, 9, 9, 0, 7, 8, 1, 0, 4, 2, 0, 0, 3,\n",
            "        3, 3, 9, 6, 8, 2, 1, 4, 3, 2, 1, 5, 0, 6, 2, 6, 0, 8, 8, 9, 2, 1, 1, 0,\n",
            "        9, 5, 8, 1, 3, 2, 3, 9, 5, 6, 7, 8])\n",
            "tensor([[-0.5942, -0.1549, -0.3512,  ...,  0.8272,  0.6268,  0.9948],\n",
            "        [ 0.3383, -0.1684,  0.7383,  ..., -0.8010,  0.0527, -0.1538],\n",
            "        [ 0.6404, -0.4357,  1.2954,  ..., -1.4565,  0.5010,  0.1454],\n",
            "        ...,\n",
            "        [ 0.5090, -0.3520,  1.2891,  ..., -1.3456,  0.1443, -0.2193],\n",
            "        [-0.3850, -0.1658, -0.2094,  ...,  0.3554,  0.8186,  1.2096],\n",
            "        [-0.4061, -0.1860, -0.1977,  ...,  0.4678,  0.8696,  1.5047]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([5, 6, 2, 2, 4, 6, 4, 6, 3, 8, 9, 5, 6, 9, 4, 8, 1, 6, 4, 0, 5, 0, 5, 2,\n",
            "        9, 0, 7, 8, 2, 7, 7, 1, 0, 7, 8, 6, 9, 3, 3, 0, 5, 9, 7, 2, 9, 1, 9, 1,\n",
            "        1, 2, 0, 2, 3, 9, 4, 4, 9, 1, 6, 7, 0, 7, 9, 2, 1, 8, 5, 1, 9, 7, 0, 7,\n",
            "        8, 0, 2, 7, 6, 5, 8, 3, 4, 4, 9, 2, 3, 0, 3, 9, 0, 8, 9, 6, 4, 4, 2, 2,\n",
            "        0, 9, 1, 9, 8, 5, 6, 7, 6, 3, 3, 4, 9, 4, 0, 4, 7, 5, 6, 2, 6, 1, 3, 1,\n",
            "        8, 1, 5, 8, 9, 8, 4, 1, 6, 4, 6, 9, 9, 6, 3, 0, 5, 6, 0, 8, 4, 3, 6, 6,\n",
            "        0, 8, 7, 9, 7, 9, 8, 1, 8, 2, 1, 7, 4, 8, 0, 0, 8, 6, 0, 7, 2, 2, 7, 2,\n",
            "        2, 7, 7, 5, 1, 0, 3, 3, 4, 1, 6, 4, 7, 6, 5, 7, 4, 8, 7, 5, 3, 7, 9, 9,\n",
            "        7, 0, 7, 3, 9, 0, 6, 3, 7, 8, 9, 3, 7, 0, 1, 3, 8, 9, 3, 1, 7, 3, 9, 5,\n",
            "        1, 7, 8, 2, 1, 9, 0, 0, 9, 7, 3, 5, 1, 8, 3, 4, 7, 5, 5, 0, 3, 1, 5, 2,\n",
            "        7, 1, 1, 6, 6, 3, 4, 5, 4, 5, 7, 6, 3, 8, 1, 5, 2, 9, 7, 5, 8, 2, 3, 7,\n",
            "        6, 2, 6, 0, 6, 2, 9, 2, 7, 6, 3, 2, 8, 0, 2, 8, 8, 1, 8, 4, 8, 0, 9, 5,\n",
            "        2, 6, 1, 2, 1, 1, 0, 6, 4, 2, 9, 9])\n",
            "tensor([[-0.2100, -0.4121,  0.1956,  ...,  0.1277,  1.1574,  0.8163],\n",
            "        [ 0.1308,  0.2407,  0.0629,  ..., -0.2189, -0.0427, -0.0651],\n",
            "        [ 0.3138,  1.6915,  0.5768,  ..., -0.6417, -0.2616, -0.4158],\n",
            "        ...,\n",
            "        [ 0.4076, -0.1594,  1.0855,  ..., -1.3474,  0.0628, -0.3598],\n",
            "        [ 0.7225,  0.1060,  0.4585,  ..., -0.8319, -0.1395, -0.1254],\n",
            "        [-0.5700, -0.0265, -0.4296,  ...,  1.6172,  0.9295,  1.0850]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([8, 0, 1, 0, 5, 8, 3, 7, 3, 2, 4, 5, 3, 5, 1, 9, 5, 0, 5, 2, 5, 9, 4, 7,\n",
            "        9, 2, 2, 7, 8, 9, 4, 8, 3, 6, 2, 1, 6, 5, 6, 3, 4, 9, 6, 4, 9, 7, 5, 4,\n",
            "        5, 8, 6, 9, 3, 6, 8, 0, 1, 5, 6, 3, 9, 8, 4, 7, 4, 2, 9, 1, 5, 8, 5, 6,\n",
            "        9, 4, 0, 5, 1, 9, 4, 2, 1, 7, 7, 9, 3, 4, 7, 0, 9, 3, 3, 5, 0, 1, 3, 9,\n",
            "        0, 8, 7, 0, 9, 1, 5, 3, 0, 7, 3, 2, 9, 3, 8, 7, 0, 0, 5, 7, 4, 6, 6, 3,\n",
            "        3, 2, 4, 8, 7, 3, 1, 3, 3, 5, 0, 4, 3, 5, 8, 9, 8, 3, 4, 7, 4, 4, 0, 9,\n",
            "        4, 3, 2, 2, 0, 1, 3, 2, 6, 5, 5, 5, 4, 3, 8, 5, 7, 0, 6, 5, 1, 9, 7, 1,\n",
            "        8, 3, 9, 2, 0, 7, 3, 3, 2, 0, 9, 8, 6, 9, 8, 7, 5, 7, 6, 5, 4, 9, 7, 5,\n",
            "        8, 0, 6, 3, 8, 8, 9, 2, 9, 4, 2, 8, 9, 0, 3, 8, 9, 0, 6, 3, 3, 3, 0, 9,\n",
            "        9, 4, 2, 3, 2, 9, 9, 8, 3, 0, 2, 4, 4, 1, 0, 8, 9, 9, 7, 9, 9, 6, 0, 4,\n",
            "        9, 1, 0, 9, 7, 7, 6, 3, 4, 5, 2, 4, 1, 1, 2, 9, 8, 8, 8, 0, 1, 7, 7, 2,\n",
            "        0, 0, 1, 4, 9, 6, 5, 6, 9, 6, 5, 8, 4, 5, 3, 4, 1, 3, 2, 0, 2, 3, 1, 2,\n",
            "        0, 6, 3, 0, 0, 0, 5, 3, 9, 6, 0, 7])\n",
            "tensor([[ 0.0541,  0.2059,  0.0526,  ..., -0.1591, -0.0016, -0.0046],\n",
            "        [ 0.6234,  0.2962,  0.8922,  ..., -1.2707, -0.2693, -0.4041],\n",
            "        [-0.3798,  0.0056, -0.4233,  ...,  1.0656,  0.3454,  0.5688],\n",
            "        ...,\n",
            "        [-0.4488, -0.0875, -0.5165,  ...,  1.2790,  0.5748,  0.8338],\n",
            "        [-0.1198,  0.8230,  0.1413,  ..., -0.2027, -0.0087, -0.1748],\n",
            "        [ 0.1122,  1.3163,  0.3947,  ..., -0.4558, -0.3336, -0.3419]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([0, 3, 7, 1, 1, 6, 1, 1, 5, 7, 2, 9, 6, 7, 5, 2, 3, 1, 8, 1, 9, 9, 2, 5,\n",
            "        5, 4, 9, 4, 8, 7, 0, 3, 8, 3, 5, 3, 0, 5, 7, 5, 6, 3, 0, 9, 6, 4, 9, 7,\n",
            "        9, 7, 5, 6, 8, 7, 8, 5, 7, 6, 8, 6, 2, 2, 9, 4, 8, 7, 3, 8, 3, 4, 7, 3,\n",
            "        4, 0, 3, 1, 8, 9, 8, 3, 7, 3, 6, 4, 2, 1, 1, 7, 1, 8, 2, 1, 9, 7, 4, 5,\n",
            "        6, 6, 5, 7, 0, 6, 4, 4, 5, 6, 5, 9, 4, 7, 8, 2, 7, 6, 4, 4, 6, 2, 8, 0,\n",
            "        3, 3, 7, 2, 3, 0, 6, 1, 7, 6, 4, 6, 8, 1, 0, 8, 7, 2, 1, 4, 0, 0, 5, 8,\n",
            "        4, 7, 4, 2, 7, 9, 7, 1, 0, 8, 9, 0, 1, 1, 4, 4, 4, 5, 9, 2, 6, 9, 2, 2,\n",
            "        0, 0, 0, 9, 6, 5, 4, 0, 7, 8, 7, 2, 9, 4, 7, 3, 7, 7, 6, 1, 2, 6, 1, 6,\n",
            "        6, 3, 2, 7, 0, 3, 2, 1, 9, 2, 9, 0, 6, 7, 2, 4, 0, 0, 3, 7, 3, 2, 4, 0,\n",
            "        7, 4, 0, 3, 0, 7, 5, 5, 3, 3, 0, 0, 3, 0, 4, 4, 9, 8, 6, 6, 5, 5, 3, 3,\n",
            "        3, 5, 2, 7, 7, 8, 8, 2, 5, 6, 3, 3, 9, 5, 8, 3, 2, 6, 1, 9, 8, 4, 6, 2,\n",
            "        9, 7, 6, 0, 9, 9, 9, 2, 9, 0, 5, 6, 4, 6, 6, 5, 0, 5, 1, 6, 8, 5, 1, 4,\n",
            "        6, 6, 7, 8, 6, 2, 7, 0, 7, 7, 1, 1])\n",
            "tensor([[ 0.6168, -0.4214,  1.3809,  ..., -1.2204,  0.2820,  0.0268],\n",
            "        [ 0.7849, -0.7238,  1.5249,  ..., -1.6249,  0.6133,  0.1763],\n",
            "        [ 0.1348,  1.4713,  0.5180,  ..., -0.5989, -0.4443, -0.4239],\n",
            "        ...,\n",
            "        [ 1.1638,  0.2439,  0.8676,  ..., -1.1474, -0.2905, -0.4101],\n",
            "        [ 0.0398,  0.3617,  0.1662,  ..., -0.2264, -0.1820, -0.1041],\n",
            "        [-0.3832, -0.0340, -0.2022,  ...,  0.5187,  0.4920,  0.6514]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([2, 4, 1, 6, 2, 4, 9, 7, 9, 7, 3, 1, 5, 3, 2, 1, 7, 6, 9, 8, 9, 1, 1, 2,\n",
            "        7, 9, 3, 6, 7, 0, 8, 4, 3, 8, 8, 7, 7, 8, 5, 3, 2, 4, 7, 3, 2, 4, 5, 2,\n",
            "        6, 4, 0, 1, 4, 1, 5, 7, 7, 7, 3, 6, 6, 7, 0, 7, 0, 7, 1, 4, 5, 3, 6, 8,\n",
            "        9, 6, 7, 6, 5, 0, 6, 7, 7, 8, 8, 9, 9, 9, 1, 1, 3, 6, 1, 4, 2, 2, 8, 3,\n",
            "        1, 7, 1, 7, 3, 0, 5, 5, 3, 5, 7, 7, 1, 9, 2, 2, 2, 0, 6, 6, 4, 5, 5, 5,\n",
            "        3, 2, 7, 8, 1, 3, 4, 5, 6, 5, 3, 3, 5, 0, 0, 5, 7, 0, 0, 2, 4, 9, 8, 0,\n",
            "        3, 5, 9, 5, 5, 1, 4, 2, 0, 9, 1, 7, 3, 4, 9, 1, 2, 1, 0, 0, 3, 3, 4, 7,\n",
            "        6, 4, 7, 8, 0, 8, 3, 1, 4, 0, 5, 2, 1, 6, 7, 8, 8, 3, 8, 6, 0, 2, 2, 1,\n",
            "        8, 9, 8, 7, 7, 5, 1, 9, 1, 5, 8, 3, 3, 3, 1, 4, 0, 2, 2, 1, 9, 2, 6, 5,\n",
            "        4, 8, 8, 5, 8, 6, 8, 3, 6, 0, 3, 2, 1, 2, 1, 3, 8, 8, 2, 3, 2, 7, 3, 7,\n",
            "        8, 0, 5, 8, 6, 1, 5, 7, 8, 7, 1, 5, 0, 1, 3, 6, 3, 3, 0, 1, 5, 1, 1, 3,\n",
            "        9, 8, 8, 2, 6, 5, 0, 7, 3, 5, 6, 8, 9, 6, 4, 9, 2, 7, 8, 6, 0, 7, 8, 5,\n",
            "        1, 3, 2, 5, 9, 8, 7, 3, 7, 0, 3, 5])\n",
            "tensor([[ 0.4145, -0.0233,  0.4169,  ..., -0.5807,  0.0273, -0.0529],\n",
            "        [ 0.3716,  1.1572,  0.5579,  ..., -0.8480, -0.3084, -0.4048],\n",
            "        [ 0.2523, -0.1677,  0.7882,  ..., -0.8306,  0.1853, -0.1058],\n",
            "        ...,\n",
            "        [ 0.8518,  0.1531,  0.6257,  ..., -0.8598, -0.2183, -0.1948],\n",
            "        [ 0.6565, -0.2373,  1.3430,  ..., -1.5555,  0.1968, -0.2804],\n",
            "        [ 1.2556,  0.0958,  0.9464,  ..., -1.3312, -0.2990, -0.3308]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([0, 1, 2, 1, 3, 0, 1, 1, 9, 4, 5, 9, 7, 8, 4, 0, 6, 1, 2, 8, 2, 4, 4, 9,\n",
            "        5, 7, 2, 8, 2, 0, 2, 3, 8, 7, 9, 5, 4, 1, 1, 2, 3, 7, 5, 2, 1, 7, 0, 9,\n",
            "        7, 7, 4, 1, 5, 7, 5, 8, 5, 3, 4, 7, 6, 4, 4, 8, 5, 5, 5, 3, 5, 8, 1, 1,\n",
            "        7, 8, 5, 9, 4, 9, 0, 3, 9, 1, 9, 9, 0, 7, 3, 4, 9, 5, 9, 8, 1, 7, 6, 4,\n",
            "        0, 8, 1, 6, 1, 9, 6, 6, 9, 9, 1, 3, 2, 0, 6, 3, 9, 9, 0, 9, 9, 5, 8, 6,\n",
            "        1, 8, 5, 7, 0, 5, 7, 2, 5, 1, 3, 8, 4, 2, 7, 7, 2, 1, 7, 1, 4, 8, 5, 7,\n",
            "        5, 9, 8, 9, 1, 8, 8, 3, 3, 8, 6, 8, 7, 3, 0, 2, 4, 9, 4, 1, 7, 7, 1, 5,\n",
            "        0, 6, 4, 8, 1, 9, 0, 5, 9, 5, 4, 7, 5, 7, 9, 4, 8, 2, 3, 9, 1, 7, 8, 4,\n",
            "        3, 0, 5, 3, 7, 7, 3, 5, 8, 1, 6, 5, 5, 5, 3, 8, 3, 9, 5, 5, 4, 5, 2, 0,\n",
            "        8, 5, 2, 2, 2, 1, 5, 9, 2, 6, 3, 1, 8, 0, 9, 7, 7, 3, 7, 3, 7, 4, 8, 7,\n",
            "        7, 6, 4, 2, 2, 7, 1, 7, 4, 6, 4, 2, 9, 7, 0, 4, 7, 3, 8, 7, 3, 7, 8, 6,\n",
            "        6, 6, 5, 4, 7, 5, 1, 7, 0, 2, 8, 9, 6, 8, 5, 0, 5, 3, 0, 9, 5, 6, 7, 6,\n",
            "        3, 1, 7, 0, 8, 2, 2, 2, 1, 0, 4, 0])\n",
            "tensor([[ 0.6003, -0.1891,  1.0040,  ..., -1.1299, -0.0187, -0.2099],\n",
            "        [-0.2716, -0.5963,  0.3997,  ...,  0.0812,  1.6336,  0.9311],\n",
            "        [-0.6382, -0.3114, -0.5369,  ...,  1.1713,  1.3656,  1.8437],\n",
            "        ...,\n",
            "        [-0.6223, -0.0568, -0.5759,  ...,  1.7349,  0.7778,  0.9134],\n",
            "        [ 0.6266,  0.8310,  0.7253,  ..., -0.9398, -0.3318, -0.5479],\n",
            "        [-0.6335, -0.1243, -0.6497,  ...,  1.6492,  1.0591,  1.4347]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([4, 8, 9, 6, 4, 8, 8, 7, 4, 8, 8, 7, 3, 4, 8, 1, 9, 8, 5, 9, 3, 3, 3, 9,\n",
            "        5, 7, 1, 4, 2, 3, 1, 5, 5, 7, 3, 4, 5, 6, 6, 3, 9, 9, 4, 2, 6, 8, 1, 3,\n",
            "        0, 9, 9, 1, 4, 5, 8, 2, 2, 6, 4, 0, 0, 4, 0, 7, 2, 3, 0, 4, 9, 7, 2, 5,\n",
            "        2, 8, 9, 4, 3, 7, 2, 6, 4, 1, 8, 5, 8, 9, 0, 6, 7, 0, 6, 3, 4, 0, 9, 5,\n",
            "        2, 9, 8, 7, 3, 9, 8, 9, 5, 0, 7, 7, 6, 5, 6, 7, 1, 6, 3, 0, 5, 8, 8, 2,\n",
            "        4, 6, 1, 8, 2, 8, 6, 4, 7, 4, 9, 6, 8, 4, 8, 7, 0, 3, 9, 5, 4, 2, 7, 3,\n",
            "        7, 9, 2, 3, 8, 0, 7, 0, 9, 2, 5, 6, 8, 4, 8, 2, 6, 3, 6, 5, 9, 5, 9, 4,\n",
            "        3, 4, 7, 9, 9, 7, 4, 7, 1, 5, 2, 9, 7, 4, 8, 2, 8, 3, 2, 3, 8, 5, 8, 9,\n",
            "        7, 2, 1, 7, 9, 4, 3, 2, 5, 3, 7, 6, 9, 1, 0, 2, 3, 3, 6, 8, 4, 4, 5, 3,\n",
            "        7, 1, 9, 1, 7, 6, 1, 6, 2, 2, 9, 3, 2, 0, 4, 0, 3, 1, 4, 7, 7, 1, 2, 2,\n",
            "        7, 0, 2, 0, 8, 1, 7, 5, 2, 5, 0, 6, 4, 3, 9, 7, 0, 4, 2, 2, 2, 4, 7, 3,\n",
            "        7, 6, 5, 8, 3, 4, 4, 8, 6, 3, 6, 6, 6, 4, 9, 7, 8, 9, 0, 0, 4, 7, 0, 0,\n",
            "        3, 5, 7, 9, 1, 2, 2, 8, 3, 7, 0, 9])\n",
            "tensor([[ 4.3994e-01,  6.1392e-01,  5.1656e-01,  ..., -7.7236e-01,\n",
            "         -2.2273e-01, -3.6147e-01],\n",
            "        [-6.5745e-01, -1.3263e-01, -4.8179e-01,  ...,  1.2596e+00,\n",
            "          1.1708e+00,  1.6422e+00],\n",
            "        [ 5.8990e-01, -3.4791e-01,  1.4203e+00,  ..., -1.5997e+00,\n",
            "          1.7284e-01, -2.8451e-01],\n",
            "        ...,\n",
            "        [ 6.8783e-01, -3.6930e-01,  1.5733e+00,  ..., -1.8803e+00,\n",
            "          2.2671e-04, -4.9102e-01],\n",
            "        [ 1.1776e-01, -3.5791e-01,  3.7646e-01,  ..., -3.5291e-01,\n",
            "          4.3962e-01,  1.1517e+00],\n",
            "        [ 5.8645e-01, -3.9985e-01,  1.2173e+00,  ..., -1.4640e+00,\n",
            "          1.6286e-01, -2.8449e-01]], grad_fn=<AddmmBackward>)\n",
            "tensor([1, 9, 4, 8, 0, 1, 6, 2, 4, 6, 0, 6, 6, 3, 2, 4, 2, 5, 2, 4, 8, 1, 1, 5,\n",
            "        3, 8, 6, 9, 5, 3, 2, 9, 2, 8, 3, 9, 3, 1, 3, 5, 8, 9, 6, 8, 8, 9, 4, 4,\n",
            "        9, 7, 3, 3, 0, 8, 0, 4, 6, 5, 1, 6, 3, 1, 0, 8, 0, 1, 5, 7, 8, 0, 9, 6,\n",
            "        1, 6, 8, 0, 2, 4, 0, 2, 5, 8, 1, 3, 0, 7, 8, 8, 4, 1, 1, 3, 8, 4, 4, 2,\n",
            "        6, 0, 7, 6, 7, 6, 0, 2, 1, 8, 0, 0, 4, 5, 8, 7, 9, 0, 0, 2, 0, 7, 3, 5,\n",
            "        5, 3, 9, 3, 9, 0, 5, 1, 2, 0, 5, 3, 7, 9, 6, 6, 1, 4, 0, 5, 5, 5, 4, 2,\n",
            "        1, 1, 6, 1, 4, 0, 9, 5, 7, 0, 1, 4, 0, 0, 4, 4, 2, 5, 4, 9, 2, 7, 4, 8,\n",
            "        4, 5, 4, 9, 0, 7, 3, 8, 3, 1, 1, 6, 5, 9, 8, 3, 0, 1, 0, 8, 4, 0, 1, 4,\n",
            "        2, 8, 9, 9, 8, 6, 6, 8, 7, 8, 8, 0, 7, 4, 0, 7, 1, 1, 8, 9, 1, 3, 8, 7,\n",
            "        1, 1, 1, 4, 2, 3, 9, 9, 2, 6, 2, 8, 6, 3, 3, 1, 4, 4, 9, 9, 9, 5, 2, 5,\n",
            "        2, 8, 8, 9, 0, 0, 3, 2, 0, 3, 3, 9, 8, 1, 2, 2, 0, 0, 3, 7, 8, 6, 7, 4,\n",
            "        8, 4, 1, 2, 1, 5, 6, 5, 0, 0, 0, 2, 1, 7, 4, 3, 0, 9, 6, 7, 4, 3, 3, 4,\n",
            "        8, 7, 6, 0, 7, 0, 7, 8, 5, 6, 9, 2])\n",
            "tensor([[ 0.9789, -0.6354,  1.5329,  ..., -1.5583,  0.2610, -0.1748],\n",
            "        [-0.4284, -0.0088, -0.2631,  ...,  0.7930,  0.4670,  0.4798],\n",
            "        [ 1.1132,  0.1942,  0.8920,  ..., -1.2093, -0.3309, -0.4008],\n",
            "        ...,\n",
            "        [ 0.2245,  0.7441,  0.3844,  ..., -0.6833, -0.2291, -0.4401],\n",
            "        [ 0.5574, -0.2240,  0.6933,  ..., -1.0892, -0.0052, -0.2221],\n",
            "        [-0.0613,  0.3074,  0.0463,  ..., -0.2247, -0.0445, -0.0952]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([2, 5, 0, 7, 0, 4, 2, 1, 8, 3, 1, 6, 0, 3, 7, 0, 4, 9, 9, 9, 5, 1, 1, 2,\n",
            "        3, 0, 8, 6, 4, 3, 1, 6, 0, 0, 0, 4, 3, 2, 8, 2, 6, 1, 3, 6, 9, 4, 8, 4,\n",
            "        4, 7, 7, 8, 5, 9, 5, 1, 7, 8, 2, 9, 3, 6, 8, 7, 0, 0, 7, 1, 5, 0, 2, 9,\n",
            "        2, 4, 9, 5, 5, 5, 4, 0, 5, 4, 5, 5, 0, 8, 3, 9, 8, 2, 6, 8, 2, 3, 0, 3,\n",
            "        9, 5, 2, 6, 6, 3, 2, 6, 8, 9, 4, 8, 9, 7, 7, 9, 6, 0, 8, 9, 0, 6, 3, 0,\n",
            "        1, 5, 5, 4, 8, 1, 0, 4, 7, 0, 0, 1, 2, 4, 5, 4, 7, 6, 6, 5, 8, 3, 2, 2,\n",
            "        7, 9, 2, 5, 0, 7, 7, 3, 1, 5, 0, 3, 2, 8, 0, 2, 3, 7, 4, 1, 0, 0, 0, 9,\n",
            "        5, 6, 5, 1, 7, 7, 1, 7, 6, 2, 0, 9, 6, 7, 6, 0, 4, 1, 5, 6, 0, 5, 4, 5,\n",
            "        8, 0, 5, 1, 6, 5, 8, 0, 5, 0, 0, 9, 5, 2, 2, 8, 6, 3, 3, 2, 9, 4, 3, 2,\n",
            "        1, 1, 1, 8, 4, 4, 0, 6, 0, 4, 2, 0, 1, 3, 8, 8, 0, 1, 6, 5, 0, 4, 5, 0,\n",
            "        4, 8, 1, 4, 4, 7, 2, 6, 2, 5, 8, 3, 1, 5, 6, 3, 2, 2, 7, 2, 8, 9, 3, 0,\n",
            "        8, 0, 2, 6, 6, 7, 8, 9, 4, 5, 3, 0, 9, 5, 0, 8, 1, 6, 8, 4, 6, 6, 8, 1,\n",
            "        8, 7, 5, 4, 1, 1, 4, 4, 6, 3, 4, 6])\n",
            "tensor([[ 0.9722, -0.4888,  1.7926,  ..., -1.7974,  0.4218, -0.2924],\n",
            "        [-0.2416,  0.0899, -0.2272,  ...,  0.3672,  0.2476,  0.4969],\n",
            "        [ 0.4931, -0.3691,  1.2962,  ..., -1.3730,  0.3450, -0.2339],\n",
            "        ...,\n",
            "        [ 0.5837, -0.2768,  1.2103,  ..., -1.4616,  0.0728, -0.3739],\n",
            "        [-0.0574, -0.2912,  0.2244,  ..., -0.1602,  0.7765,  0.5552],\n",
            "        [ 0.4850,  0.9280,  0.4957,  ..., -0.8703, -0.3684, -0.3976]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([2, 5, 2, 0, 3, 7, 3, 5, 9, 9, 5, 4, 6, 6, 7, 6, 4, 9, 7, 7, 3, 3, 6, 8,\n",
            "        1, 0, 2, 0, 7, 5, 5, 9, 8, 7, 7, 2, 5, 7, 5, 5, 2, 2, 3, 7, 7, 5, 1, 0,\n",
            "        2, 5, 9, 2, 5, 8, 1, 4, 5, 1, 2, 8, 0, 4, 1, 9, 2, 0, 1, 0, 1, 6, 3, 3,\n",
            "        5, 3, 8, 8, 6, 5, 9, 1, 1, 3, 4, 2, 0, 8, 9, 6, 9, 8, 6, 9, 5, 6, 0, 1,\n",
            "        7, 7, 7, 6, 2, 2, 0, 3, 8, 8, 3, 0, 0, 1, 9, 6, 4, 8, 0, 8, 3, 8, 0, 5,\n",
            "        4, 6, 6, 6, 7, 8, 3, 7, 7, 8, 0, 0, 4, 4, 4, 8, 4, 5, 5, 4, 6, 0, 2, 2,\n",
            "        2, 0, 6, 0, 8, 7, 0, 5, 7, 9, 0, 6, 6, 9, 3, 4, 0, 0, 6, 1, 3, 1, 3, 4,\n",
            "        7, 2, 1, 4, 4, 0, 6, 1, 7, 6, 5, 1, 5, 1, 6, 4, 8, 7, 3, 5, 5, 8, 6, 2,\n",
            "        3, 4, 4, 4, 3, 0, 1, 1, 4, 6, 5, 6, 7, 3, 5, 0, 7, 4, 0, 3, 9, 4, 8, 7,\n",
            "        6, 1, 2, 1, 2, 9, 9, 4, 5, 4, 2, 8, 7, 9, 4, 6, 8, 2, 7, 8, 0, 2, 7, 3,\n",
            "        4, 6, 0, 5, 4, 4, 6, 5, 7, 1, 4, 1, 5, 0, 4, 2, 8, 4, 6, 4, 4, 3, 8, 9,\n",
            "        6, 6, 4, 6, 5, 6, 6, 8, 7, 0, 6, 2, 0, 2, 2, 9, 4, 8, 9, 9, 9, 9, 0, 4,\n",
            "        2, 7, 4, 0, 3, 2, 4, 8, 8, 2, 8, 3])\n",
            "tensor([[ 0.1534, -0.4998,  0.2420,  ..., -0.4684,  0.5349,  0.1336],\n",
            "        [ 0.0714,  1.2812,  0.3145,  ..., -0.3821, -0.1745, -0.3531],\n",
            "        [-0.2334, -0.5380,  0.0564,  ...,  0.0173,  1.2681,  0.4834],\n",
            "        ...,\n",
            "        [-0.1515,  0.1007,  0.2061,  ..., -0.1569,  0.1123,  0.0727],\n",
            "        [ 0.2651,  0.9660,  0.4783,  ..., -0.6347, -0.3487, -0.3912],\n",
            "        [-0.5661, -0.0411, -0.6590,  ...,  1.5468,  0.6250,  1.0054]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([8, 1, 5, 0, 7, 1, 6, 3, 4, 4, 2, 0, 2, 1, 1, 7, 1, 7, 0, 6, 8, 4, 8, 8,\n",
            "        8, 3, 0, 1, 1, 8, 4, 4, 8, 9, 1, 7, 9, 0, 6, 4, 8, 9, 8, 9, 9, 2, 7, 0,\n",
            "        1, 0, 2, 3, 3, 2, 7, 2, 0, 5, 9, 7, 9, 1, 6, 3, 3, 5, 8, 5, 2, 9, 6, 3,\n",
            "        8, 1, 8, 4, 0, 4, 3, 5, 6, 8, 2, 3, 6, 6, 0, 6, 9, 8, 4, 7, 5, 0, 8, 6,\n",
            "        2, 7, 4, 6, 1, 8, 3, 4, 1, 2, 5, 1, 2, 6, 6, 2, 8, 1, 3, 7, 0, 1, 7, 0,\n",
            "        2, 7, 8, 8, 0, 4, 9, 2, 2, 3, 9, 6, 1, 0, 7, 1, 1, 0, 6, 4, 5, 1, 3, 4,\n",
            "        4, 5, 8, 2, 9, 7, 4, 9, 3, 2, 7, 7, 2, 3, 5, 0, 8, 2, 5, 2, 3, 6, 5, 5,\n",
            "        8, 1, 3, 3, 6, 6, 3, 0, 8, 0, 5, 5, 3, 1, 3, 2, 0, 8, 7, 2, 2, 1, 4, 0,\n",
            "        7, 8, 9, 2, 2, 1, 7, 0, 3, 7, 5, 0, 2, 1, 2, 9, 5, 4, 5, 6, 2, 6, 9, 0,\n",
            "        8, 2, 8, 8, 9, 1, 2, 0, 9, 2, 8, 7, 9, 3, 8, 4, 4, 6, 4, 2, 3, 6, 7, 4,\n",
            "        7, 2, 1, 2, 7, 1, 1, 6, 4, 5, 3, 5, 3, 7, 3, 1, 5, 7, 9, 1, 6, 5, 6, 2,\n",
            "        9, 0, 4, 9, 6, 4, 4, 3, 8, 9, 5, 0, 1, 2, 5, 6, 9, 0, 2, 6, 9, 2, 8, 5,\n",
            "        3, 4, 5, 0, 5, 1, 1, 7, 9, 6, 3, 7])\n",
            "tensor([[ 0.4475, -0.7128,  1.5502,  ..., -1.5523,  0.5377, -0.0939],\n",
            "        [-0.8018, -0.2228, -0.7102,  ...,  1.8656,  0.9525,  1.0384],\n",
            "        [ 0.1685,  0.2430,  0.4564,  ..., -0.4349,  0.0193, -0.2034],\n",
            "        ...,\n",
            "        [ 0.7760, -0.4190,  1.5666,  ..., -1.7599,  0.0868, -0.5920],\n",
            "        [ 0.2529,  0.9122,  0.4925,  ..., -0.6343, -0.3234, -0.3846],\n",
            "        [ 0.7130,  0.9405,  0.9642,  ..., -1.3303, -0.5778, -0.6578]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([2, 7, 2, 1, 6, 4, 7, 8, 8, 6, 7, 5, 7, 3, 6, 4, 1, 7, 7, 0, 2, 5, 0, 9,\n",
            "        4, 9, 7, 4, 9, 4, 2, 2, 4, 0, 5, 5, 8, 4, 3, 4, 8, 2, 6, 1, 6, 9, 3, 5,\n",
            "        7, 6, 1, 2, 8, 6, 5, 3, 3, 8, 9, 5, 9, 9, 8, 2, 0, 3, 3, 5, 4, 9, 2, 0,\n",
            "        7, 7, 4, 5, 4, 9, 7, 3, 8, 2, 7, 0, 4, 8, 1, 3, 3, 8, 4, 2, 5, 1, 2, 2,\n",
            "        4, 4, 8, 2, 4, 8, 1, 9, 5, 2, 3, 6, 1, 0, 2, 9, 1, 4, 2, 4, 5, 6, 3, 9,\n",
            "        4, 4, 1, 5, 0, 9, 0, 2, 5, 7, 0, 3, 0, 3, 4, 8, 9, 8, 5, 9, 5, 5, 8, 9,\n",
            "        3, 2, 6, 5, 5, 4, 0, 6, 5, 1, 6, 9, 8, 9, 9, 5, 4, 5, 3, 3, 3, 0, 9, 5,\n",
            "        4, 8, 0, 7, 9, 9, 8, 1, 9, 3, 4, 6, 0, 9, 1, 0, 7, 6, 5, 7, 7, 9, 3, 6,\n",
            "        5, 2, 1, 6, 3, 7, 1, 5, 1, 8, 8, 4, 6, 7, 5, 9, 3, 5, 1, 7, 7, 9, 3, 0,\n",
            "        7, 5, 6, 0, 0, 1, 0, 1, 0, 9, 5, 8, 5, 1, 7, 4, 1, 0, 0, 7, 4, 5, 6, 9,\n",
            "        2, 9, 6, 9, 8, 5, 4, 7, 7, 4, 1, 1, 0, 3, 4, 9, 6, 8, 6, 1, 4, 3, 2, 7,\n",
            "        6, 2, 3, 9, 9, 4, 5, 7, 6, 2, 8, 4, 2, 5, 6, 7, 6, 8, 2, 4, 3, 1, 8, 1,\n",
            "        0, 6, 8, 5, 4, 8, 2, 8, 6, 6, 3, 3])\n",
            "tensor([[-0.6439,  0.0261, -0.6987,  ...,  1.7163,  0.4976,  0.7396],\n",
            "        [ 0.5638,  1.3115,  0.7428,  ..., -1.0826, -0.4661, -0.8552],\n",
            "        [ 0.3516, -0.1152,  0.8491,  ..., -1.0322,  0.1435, -0.2781],\n",
            "        ...,\n",
            "        [-0.7143, -0.0544, -0.6923,  ...,  1.6827,  0.6192,  0.8600],\n",
            "        [ 0.0284,  0.0304,  0.1546,  ..., -0.6358,  0.0369, -0.0359],\n",
            "        [ 0.5965, -0.1179,  0.6101,  ..., -0.9731, -0.0666, -0.2917]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([7, 3, 4, 9, 1, 9, 0, 5, 2, 4, 1, 7, 4, 2, 4, 6, 8, 9, 3, 9, 2, 6, 4, 6,\n",
            "        7, 3, 0, 6, 7, 3, 9, 4, 9, 0, 6, 0, 7, 5, 9, 4, 6, 4, 1, 3, 8, 9, 9, 6,\n",
            "        2, 5, 2, 7, 1, 6, 8, 1, 2, 5, 5, 0, 6, 5, 4, 5, 1, 0, 9, 1, 6, 1, 1, 6,\n",
            "        1, 1, 7, 2, 8, 2, 7, 5, 3, 8, 4, 3, 3, 5, 5, 1, 8, 8, 3, 2, 9, 5, 4, 0,\n",
            "        7, 8, 1, 0, 1, 3, 6, 2, 3, 4, 9, 3, 2, 8, 5, 8, 5, 5, 9, 8, 0, 0, 8, 2,\n",
            "        9, 2, 0, 8, 1, 7, 5, 1, 8, 0, 3, 8, 3, 3, 6, 4, 2, 8, 7, 6, 3, 2, 0, 5,\n",
            "        8, 5, 0, 3, 8, 7, 6, 7, 7, 1, 2, 9, 4, 1, 5, 5, 8, 2, 1, 2, 9, 8, 1, 3,\n",
            "        2, 1, 6, 8, 4, 7, 8, 7, 6, 6, 6, 8, 4, 3, 7, 5, 3, 9, 6, 4, 2, 9, 0, 0,\n",
            "        5, 0, 2, 2, 0, 3, 3, 7, 6, 4, 3, 2, 3, 2, 8, 9, 4, 8, 4, 3, 5, 4, 0, 3,\n",
            "        8, 6, 7, 7, 3, 8, 3, 6, 0, 2, 2, 9, 0, 0, 1, 7, 1, 3, 4, 6, 9, 7, 0, 3,\n",
            "        9, 5, 5, 0, 6, 5, 9, 2, 0, 1, 8, 8, 0, 8, 1, 3, 9, 5, 8, 2, 5, 9, 9, 5,\n",
            "        4, 3, 6, 1, 6, 7, 4, 3, 5, 5, 3, 7, 3, 7, 2, 3, 8, 8, 9, 4, 0, 0, 9, 4,\n",
            "        2, 5, 6, 1, 8, 7, 9, 5, 6, 7, 8, 0])\n",
            "tensor([[-0.4273, -0.0266, -0.2819,  ...,  0.4844,  0.4642,  0.6097],\n",
            "        [ 1.0708, -0.6520,  1.3420,  ..., -1.6674,  0.0830, -0.4232],\n",
            "        [-0.1211,  0.2483, -0.0365,  ..., -0.1101,  0.0277, -0.0695],\n",
            "        ...,\n",
            "        [ 0.7557,  0.7338,  0.5498,  ..., -0.9766, -0.3009, -0.4953],\n",
            "        [ 0.6879,  0.4839,  0.5606,  ..., -0.8787, -0.3341, -0.3789],\n",
            "        [ 0.1909,  0.8405,  0.2631,  ..., -0.5511, -0.2573, -0.4040]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([5, 6, 8, 3, 9, 2, 7, 2, 5, 0, 6, 6, 0, 8, 4, 0, 1, 4, 2, 3, 3, 7, 5, 0,\n",
            "        0, 7, 1, 6, 1, 5, 2, 2, 9, 6, 6, 4, 5, 1, 5, 5, 6, 6, 6, 7, 8, 7, 1, 1,\n",
            "        1, 8, 0, 9, 8, 9, 1, 4, 2, 4, 8, 8, 3, 0, 1, 5, 7, 2, 8, 0, 6, 5, 1, 4,\n",
            "        0, 0, 5, 3, 0, 5, 6, 4, 0, 4, 0, 2, 9, 7, 2, 6, 0, 8, 0, 3, 1, 2, 3, 7,\n",
            "        7, 5, 1, 5, 5, 7, 7, 8, 7, 9, 1, 9, 2, 3, 2, 9, 6, 1, 0, 8, 1, 0, 2, 4,\n",
            "        8, 2, 2, 6, 0, 4, 0, 9, 8, 9, 3, 0, 2, 5, 4, 0, 7, 4, 8, 2, 3, 3, 8, 6,\n",
            "        3, 7, 8, 3, 0, 4, 0, 2, 0, 7, 5, 6, 1, 7, 6, 5, 5, 4, 4, 8, 2, 8, 2, 1,\n",
            "        8, 2, 1, 1, 1, 3, 5, 9, 0, 6, 4, 8, 1, 4, 7, 7, 4, 8, 9, 8, 3, 1, 7, 8,\n",
            "        9, 2, 8, 1, 9, 5, 7, 6, 5, 7, 4, 9, 2, 4, 0, 0, 6, 6, 0, 8, 8, 5, 1, 5,\n",
            "        0, 8, 3, 1, 2, 7, 1, 9, 9, 6, 1, 5, 5, 3, 2, 8, 4, 3, 6, 2, 1, 5, 3, 4,\n",
            "        3, 2, 8, 9, 5, 9, 6, 6, 9, 8, 6, 3, 8, 5, 8, 1, 1, 5, 5, 5, 5, 0, 1, 5,\n",
            "        5, 9, 6, 6, 0, 6, 6, 9, 9, 5, 9, 5, 2, 1, 3, 0, 9, 5, 5, 9, 6, 2, 9, 4,\n",
            "        9, 7, 1, 4, 4, 4, 6, 6, 9, 3, 0, 3])\n",
            "tensor([[ 0.3504,  0.6158,  0.4094,  ..., -0.8349, -0.4049, -0.4702],\n",
            "        [ 0.7650,  0.5172,  0.8308,  ..., -1.5588, -0.4124, -0.5928],\n",
            "        [-0.6508, -0.3196, -0.5797,  ...,  1.3161,  1.2672,  1.7182],\n",
            "        ...,\n",
            "        [-0.5629, -0.0432, -0.5675,  ...,  1.2474,  0.5456,  0.7223],\n",
            "        [ 0.4355, -0.2777,  1.2003,  ..., -1.4113,  0.2291, -0.3955],\n",
            "        [-0.3711,  0.0959, -0.4226,  ...,  0.6818,  0.2537,  0.3753]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([3, 3, 9, 1, 5, 1, 9, 6, 1, 4, 0, 7, 0, 2, 7, 6, 8, 2, 6, 6, 9, 1, 8, 1,\n",
            "        3, 7, 5, 3, 3, 6, 7, 9, 2, 0, 2, 8, 8, 4, 8, 7, 4, 8, 8, 6, 7, 7, 4, 6,\n",
            "        9, 0, 2, 5, 9, 7, 9, 7, 3, 8, 7, 5, 4, 8, 4, 9, 8, 6, 7, 2, 2, 3, 5, 0,\n",
            "        6, 5, 6, 4, 5, 1, 3, 3, 2, 2, 4, 2, 2, 8, 5, 3, 4, 3, 2, 1, 6, 7, 8, 8,\n",
            "        4, 3, 4, 0, 5, 7, 9, 7, 3, 2, 6, 7, 4, 0, 6, 0, 8, 7, 7, 5, 1, 0, 2, 3,\n",
            "        7, 2, 5, 3, 3, 8, 7, 4, 8, 5, 6, 8, 3, 6, 5, 6, 6, 4, 3, 5, 5, 5, 4, 9,\n",
            "        7, 3, 6, 0, 3, 4, 5, 7, 5, 6, 0, 4, 0, 1, 7, 6, 5, 9, 7, 1, 2, 1, 0, 8,\n",
            "        8, 9, 9, 4, 6, 2, 2, 1, 1, 0, 0, 3, 1, 7, 5, 8, 9, 9, 9, 7, 0, 2, 3, 2,\n",
            "        8, 8, 8, 6, 5, 2, 2, 2, 3, 8, 0, 5, 7, 1, 8, 4, 3, 1, 2, 1, 3, 6, 3, 7,\n",
            "        9, 7, 6, 3, 8, 0, 0, 4, 2, 8, 6, 0, 3, 2, 4, 2, 4, 1, 2, 5, 0, 4, 8, 2,\n",
            "        4, 8, 4, 5, 8, 4, 4, 9, 3, 3, 3, 4, 5, 9, 3, 2, 3, 8, 2, 3, 3, 4, 5, 9,\n",
            "        0, 8, 8, 1, 0, 6, 3, 0, 3, 4, 6, 3, 6, 1, 6, 6, 9, 2, 4, 9, 3, 6, 6, 8,\n",
            "        0, 0, 5, 1, 9, 9, 4, 1, 9, 7, 6, 7])\n",
            "tensor([[-0.0334, -0.6160,  0.2477,  ..., -0.4870,  0.7317,  0.1629],\n",
            "        [ 0.4209, -0.4605,  0.7676,  ..., -0.7059,  0.7699,  0.1315],\n",
            "        [ 1.0833, -0.4366,  1.4293,  ..., -1.8114,  0.0249, -0.5436],\n",
            "        ...,\n",
            "        [ 0.4031,  1.4937,  0.6530,  ..., -0.9968, -0.6454, -0.6366],\n",
            "        [ 0.5612,  0.2413,  0.4490,  ..., -0.7714, -0.2321, -0.3197],\n",
            "        [ 0.5638, -0.3707,  1.2973,  ..., -1.6591,  0.2328, -0.4204]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([8, 0, 0, 4, 3, 5, 6, 7, 4, 5, 6, 9, 8, 4, 5, 6, 1, 4, 0, 9, 2, 4, 3, 7,\n",
            "        3, 4, 2, 5, 5, 4, 9, 3, 8, 3, 4, 9, 5, 8, 6, 3, 8, 8, 0, 4, 3, 3, 0, 2,\n",
            "        8, 3, 6, 5, 6, 3, 4, 6, 5, 2, 9, 2, 9, 6, 6, 7, 4, 8, 0, 4, 9, 0, 9, 9,\n",
            "        5, 5, 2, 5, 7, 1, 2, 0, 1, 3, 4, 2, 2, 5, 8, 3, 1, 3, 8, 4, 1, 4, 5, 8,\n",
            "        8, 8, 6, 2, 7, 0, 1, 5, 7, 5, 9, 9, 3, 7, 2, 8, 3, 6, 3, 6, 7, 5, 5, 9,\n",
            "        8, 1, 6, 4, 8, 8, 7, 9, 7, 9, 5, 7, 6, 0, 5, 0, 7, 6, 9, 0, 4, 8, 1, 6,\n",
            "        5, 1, 9, 3, 3, 7, 4, 1, 7, 2, 4, 4, 2, 5, 5, 2, 7, 2, 8, 0, 9, 4, 4, 8,\n",
            "        0, 6, 1, 2, 9, 8, 9, 3, 3, 1, 1, 4, 9, 9, 5, 5, 3, 5, 3, 0, 4, 0, 9, 4,\n",
            "        5, 2, 1, 2, 9, 3, 9, 8, 2, 6, 8, 5, 2, 2, 2, 7, 2, 6, 4, 4, 4, 6, 8, 7,\n",
            "        6, 7, 8, 2, 2, 5, 7, 0, 9, 2, 8, 8, 9, 2, 5, 3, 0, 1, 0, 9, 1, 3, 1, 3,\n",
            "        2, 6, 0, 7, 2, 5, 7, 5, 4, 8, 2, 5, 9, 1, 6, 4, 9, 6, 9, 9, 2, 7, 5, 4,\n",
            "        1, 3, 7, 3, 9, 0, 0, 7, 1, 0, 6, 7, 1, 8, 6, 1, 5, 3, 5, 4, 4, 8, 2, 1,\n",
            "        9, 6, 0, 5, 9, 5, 7, 3, 4, 1, 6, 6])\n",
            "tensor([[ 0.6826,  0.4268,  0.5757,  ..., -0.9107, -0.1932, -0.3794],\n",
            "        [ 0.1614,  1.9051,  0.4869,  ..., -0.6886, -0.5482, -0.6898],\n",
            "        [-0.4635, -0.0942, -0.2529,  ...,  0.8089,  0.6916,  1.0367],\n",
            "        ...,\n",
            "        [ 0.8509, -0.6249,  1.4717,  ..., -1.7865,  0.1838, -0.4734],\n",
            "        [-0.0573,  1.0829,  0.1179,  ..., -0.2255, -0.1569, -0.2543],\n",
            "        [ 0.5831, -0.3935,  1.3593,  ..., -1.4659,  0.3322, -0.3104]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([0, 1, 5, 7, 2, 7, 2, 0, 2, 5, 5, 9, 8, 2, 5, 8, 8, 4, 9, 8, 5, 5, 0, 5,\n",
            "        6, 3, 6, 9, 9, 7, 4, 8, 5, 7, 3, 2, 7, 2, 0, 8, 3, 9, 3, 2, 4, 9, 4, 2,\n",
            "        5, 1, 9, 8, 8, 4, 7, 6, 8, 0, 6, 2, 1, 4, 1, 5, 4, 3, 3, 3, 0, 9, 8, 9,\n",
            "        7, 5, 3, 3, 8, 8, 5, 6, 8, 2, 3, 0, 2, 2, 9, 3, 1, 5, 1, 4, 1, 0, 3, 1,\n",
            "        4, 6, 3, 3, 1, 1, 0, 6, 9, 0, 9, 3, 6, 0, 9, 6, 6, 9, 0, 0, 3, 6, 6, 4,\n",
            "        8, 6, 8, 5, 8, 1, 5, 3, 8, 4, 4, 6, 1, 4, 1, 2, 2, 9, 4, 5, 0, 9, 3, 2,\n",
            "        4, 7, 7, 7, 2, 4, 3, 6, 3, 1, 8, 2, 0, 3, 2, 5, 5, 3, 7, 4, 0, 6, 1, 4,\n",
            "        5, 5, 3, 3, 5, 9, 4, 0, 0, 1, 3, 7, 7, 8, 3, 2, 8, 9, 2, 7, 2, 5, 7, 1,\n",
            "        9, 2, 7, 5, 1, 2, 3, 8, 0, 8, 5, 8, 1, 1, 5, 7, 2, 2, 2, 4, 8, 4, 6, 1,\n",
            "        0, 1, 6, 3, 9, 5, 9, 8, 7, 2, 3, 7, 8, 1, 6, 3, 4, 2, 7, 5, 1, 2, 6, 6,\n",
            "        3, 3, 1, 6, 6, 6, 9, 4, 8, 7, 8, 2, 9, 9, 5, 9, 3, 7, 4, 5, 7, 9, 1, 5,\n",
            "        5, 9, 9, 7, 8, 4, 0, 6, 3, 9, 3, 8, 0, 4, 5, 4, 4, 6, 5, 7, 0, 5, 5, 9,\n",
            "        9, 2, 4, 8, 0, 5, 3, 5, 0, 4, 1, 2])\n",
            "tensor([[-0.0386, -0.6639,  0.5932,  ..., -0.3178,  1.2860,  0.6294],\n",
            "        [ 0.1149,  0.2331,  0.1019,  ..., -0.3536, -0.1541, -0.1794],\n",
            "        [ 0.0489,  1.2249,  0.2758,  ..., -0.3763, -0.3165, -0.3640],\n",
            "        ...,\n",
            "        [ 0.9485,  0.6233,  0.9561,  ..., -1.4661, -0.3329, -0.8676],\n",
            "        [ 0.7821, -0.4639,  1.2989,  ..., -1.4225,  0.5831, -0.0143],\n",
            "        [ 0.7270,  1.1139,  0.7743,  ..., -1.3958, -0.5452, -0.9830]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([8, 3, 1, 7, 7, 6, 9, 1, 4, 5, 8, 5, 1, 6, 9, 6, 7, 5, 8, 9, 8, 3, 6, 3,\n",
            "        1, 6, 4, 2, 8, 8, 1, 7, 2, 8, 1, 7, 6, 4, 6, 1, 5, 3, 1, 5, 6, 8, 8, 6,\n",
            "        6, 6, 3, 9, 9, 5, 8, 0, 2, 0, 7, 1, 4, 3, 4, 8, 4, 8, 5, 0, 5, 0, 2, 6,\n",
            "        1, 3, 8, 9, 0, 1, 8, 5, 9, 9, 7, 3, 2, 9, 3, 1, 8, 4, 7, 8, 1, 0, 2, 2,\n",
            "        8, 2, 9, 6, 3, 7, 1, 8, 4, 4, 8, 2, 9, 7, 9, 9, 7, 8, 3, 9, 5, 5, 4, 9,\n",
            "        4, 1, 9, 8, 3, 0, 2, 3, 9, 1, 3, 7, 1, 0, 5, 8, 3, 2, 6, 1, 8, 1, 9, 6,\n",
            "        9, 6, 9, 2, 8, 3, 5, 8, 6, 8, 7, 0, 1, 8, 4, 6, 1, 1, 2, 7, 9, 9, 2, 8,\n",
            "        9, 7, 6, 3, 4, 9, 8, 6, 7, 3, 9, 1, 8, 6, 0, 8, 1, 3, 0, 9, 1, 2, 8, 1,\n",
            "        2, 0, 1, 9, 2, 9, 6, 8, 9, 5, 3, 3, 4, 7, 5, 5, 4, 6, 0, 7, 8, 3, 3, 8,\n",
            "        3, 8, 6, 8, 3, 3, 6, 1, 4, 6, 4, 1, 2, 2, 9, 1, 3, 4, 7, 8, 1, 7, 5, 7,\n",
            "        4, 7, 9, 2, 7, 7, 2, 9, 8, 4, 4, 8, 9, 1, 4, 6, 8, 8, 7, 4, 3, 5, 9, 0,\n",
            "        0, 0, 0, 0, 4, 2, 5, 9, 7, 2, 4, 2, 2, 5, 8, 8, 3, 1, 8, 7, 6, 3, 2, 1,\n",
            "        2, 2, 7, 3, 2, 5, 6, 4, 9, 6, 1, 3])\n",
            "tensor([[-0.1404, -0.0339,  0.0332,  ..., -0.1188,  0.1163,  0.1013],\n",
            "        [ 0.2799, -0.2963,  0.6954,  ..., -0.8039,  0.1806, -0.2346],\n",
            "        [-0.8100, -0.1590, -0.7914,  ...,  1.7920,  1.0660,  1.2897],\n",
            "        ...,\n",
            "        [-0.4976,  0.0571, -0.3478,  ...,  0.6135,  0.6945,  0.9748],\n",
            "        [ 0.1386, -0.0602,  0.5879,  ..., -0.6114,  0.1493, -0.1449],\n",
            "        [ 0.0595, -0.2418,  0.8800,  ..., -1.2519,  0.4319,  0.0246]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([6, 4, 9, 3, 5, 9, 7, 3, 6, 3, 4, 7, 4, 3, 8, 5, 7, 7, 5, 7, 7, 5, 2, 3,\n",
            "        9, 7, 4, 1, 0, 8, 9, 7, 0, 3, 5, 4, 9, 9, 9, 3, 7, 5, 0, 6, 2, 9, 5, 2,\n",
            "        2, 8, 3, 2, 6, 3, 0, 2, 0, 7, 6, 9, 9, 7, 9, 8, 4, 4, 4, 1, 7, 0, 9, 4,\n",
            "        3, 7, 3, 9, 6, 2, 0, 5, 4, 4, 7, 5, 0, 5, 2, 3, 7, 8, 5, 5, 1, 0, 7, 9,\n",
            "        4, 1, 2, 8, 0, 3, 3, 9, 1, 6, 7, 3, 6, 7, 6, 3, 9, 8, 6, 5, 4, 8, 3, 8,\n",
            "        6, 6, 5, 9, 6, 1, 5, 6, 6, 8, 1, 1, 3, 0, 5, 3, 9, 2, 9, 7, 2, 4, 7, 9,\n",
            "        7, 4, 7, 5, 3, 7, 3, 7, 7, 1, 0, 0, 7, 4, 5, 3, 2, 1, 7, 8, 1, 4, 3, 5,\n",
            "        9, 2, 5, 1, 3, 1, 1, 6, 8, 1, 5, 9, 9, 3, 6, 2, 9, 9, 3, 6, 5, 9, 6, 4,\n",
            "        5, 9, 1, 9, 9, 8, 6, 7, 8, 9, 7, 7, 9, 9, 6, 2, 6, 6, 9, 8, 0, 2, 0, 0,\n",
            "        2, 9, 6, 9, 4, 2, 6, 7, 1, 4, 4, 5, 0, 8, 3, 8, 1, 3, 3, 3, 2, 1, 0, 1,\n",
            "        7, 1, 4, 6, 0, 4, 1, 7, 0, 1, 7, 1, 7, 0, 1, 4, 0, 4, 7, 5, 8, 1, 6, 6,\n",
            "        3, 1, 3, 8, 9, 5, 1, 5, 5, 4, 0, 9, 5, 8, 8, 7, 6, 6, 3, 3, 8, 7, 5, 6,\n",
            "        2, 0, 4, 3, 6, 3, 8, 4, 2, 5, 6, 4])\n",
            "tensor([[ 0.9499,  1.2809,  0.9846,  ..., -1.6806, -0.7872, -0.8845],\n",
            "        [ 1.0546,  0.4953,  0.7859,  ..., -1.4192, -0.3600, -0.6470],\n",
            "        [-0.3395, -0.4757,  0.0411,  ...,  0.3345,  1.5726,  1.1322],\n",
            "        ...,\n",
            "        [-0.6206, -0.2101, -0.4929,  ...,  1.3013,  0.9567,  1.1057],\n",
            "        [ 0.0921,  2.0281,  0.4060,  ..., -0.4782, -0.4596, -0.5200],\n",
            "        [-0.5314, -0.0950, -0.5503,  ...,  1.4199,  0.5818,  0.7514]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([3, 0, 8, 0, 6, 6, 0, 0, 8, 9, 1, 2, 2, 7, 2, 2, 7, 9, 4, 9, 0, 5, 6, 9,\n",
            "        1, 9, 2, 7, 2, 3, 1, 8, 9, 1, 3, 1, 7, 1, 3, 8, 0, 0, 8, 2, 0, 0, 1, 7,\n",
            "        8, 4, 9, 9, 1, 5, 4, 5, 9, 8, 1, 6, 1, 3, 9, 9, 0, 8, 6, 7, 6, 4, 0, 9,\n",
            "        7, 5, 4, 1, 6, 6, 2, 6, 4, 6, 2, 3, 7, 9, 9, 5, 9, 5, 2, 3, 2, 8, 2, 2,\n",
            "        6, 2, 5, 3, 3, 5, 6, 3, 3, 5, 0, 2, 3, 6, 9, 8, 4, 1, 0, 1, 1, 7, 3, 3,\n",
            "        8, 1, 3, 7, 7, 4, 4, 9, 0, 6, 0, 1, 6, 8, 6, 8, 8, 8, 3, 4, 3, 6, 1, 1,\n",
            "        6, 7, 3, 2, 4, 3, 0, 3, 3, 4, 3, 7, 2, 1, 0, 6, 4, 0, 3, 9, 8, 4, 4, 7,\n",
            "        8, 4, 5, 5, 5, 2, 8, 7, 7, 0, 5, 8, 4, 7, 5, 3, 3, 9, 2, 3, 5, 7, 7, 2,\n",
            "        2, 4, 1, 0, 8, 9, 0, 0, 4, 9, 0, 9, 1, 4, 5, 7, 4, 5, 2, 1, 2, 7, 0, 8,\n",
            "        3, 4, 7, 5, 3, 9, 6, 4, 7, 7, 8, 9, 6, 7, 1, 1, 7, 4, 1, 6, 1, 8, 4, 2,\n",
            "        5, 4, 4, 9, 2, 7, 5, 7, 7, 7, 6, 7, 0, 0, 7, 3, 6, 2, 5, 7, 0, 3, 6, 5,\n",
            "        6, 5, 4, 9, 6, 8, 0, 9, 3, 4, 5, 1, 7, 0, 1, 0, 4, 2, 5, 0, 5, 5, 0, 0,\n",
            "        9, 4, 6, 3, 7, 0, 8, 9, 6, 7, 1, 5])\n",
            "tensor([[-0.9687, -0.3866, -0.7669,  ...,  2.0307,  1.5061,  1.7241],\n",
            "        [-0.6180, -0.0503, -0.5991,  ...,  1.3625,  0.5913,  0.8317],\n",
            "        [ 0.7187, -0.6256,  1.6581,  ..., -1.9881,  0.1976, -0.4613],\n",
            "        ...,\n",
            "        [-0.1712, -0.2182, -0.0890,  ..., -0.0622,  0.4265,  0.5303],\n",
            "        [ 0.8270, -0.5496,  1.6305,  ..., -1.8220,  0.3226, -0.4760],\n",
            "        [ 0.2865,  1.9394,  0.4339,  ..., -0.7688, -0.4540, -0.5721]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([7, 7, 2, 8, 9, 4, 3, 4, 5, 3, 6, 4, 0, 3, 9, 2, 9, 2, 0, 8, 6, 1, 5, 7,\n",
            "        7, 8, 2, 8, 9, 9, 2, 6, 3, 9, 7, 5, 0, 0, 9, 2, 4, 1, 1, 5, 9, 9, 3, 8,\n",
            "        9, 3, 3, 0, 2, 5, 7, 5, 7, 5, 2, 5, 5, 2, 5, 4, 5, 3, 5, 2, 9, 0, 8, 2,\n",
            "        8, 8, 3, 2, 5, 1, 6, 4, 3, 8, 2, 4, 2, 7, 0, 2, 9, 6, 1, 7, 1, 9, 1, 8,\n",
            "        2, 1, 4, 5, 8, 1, 4, 1, 1, 0, 9, 9, 9, 4, 7, 2, 4, 7, 5, 6, 5, 9, 9, 8,\n",
            "        0, 9, 5, 8, 8, 2, 5, 5, 6, 8, 0, 4, 2, 4, 1, 9, 4, 3, 7, 8, 0, 2, 9, 3,\n",
            "        4, 7, 3, 3, 2, 1, 4, 3, 9, 6, 0, 8, 2, 2, 4, 5, 1, 0, 8, 9, 6, 3, 8, 4,\n",
            "        3, 7, 8, 6, 6, 1, 1, 1, 5, 1, 4, 8, 8, 4, 9, 2, 6, 0, 2, 6, 1, 7, 1, 9,\n",
            "        9, 7, 8, 6, 4, 2, 7, 1, 4, 8, 7, 3, 0, 3, 0, 9, 9, 6, 8, 4, 6, 2, 8, 9,\n",
            "        4, 5, 5, 7, 4, 2, 2, 9, 3, 5, 4, 6, 9, 4, 5, 6, 6, 6, 0, 3, 0, 3, 3, 1,\n",
            "        9, 0, 8, 8, 8, 2, 8, 1, 6, 9, 7, 0, 9, 0, 6, 1, 4, 6, 6, 9, 7, 2, 8, 4,\n",
            "        0, 7, 1, 2, 5, 4, 6, 5, 9, 2, 7, 7, 9, 7, 2, 5, 7, 7, 1, 5, 6, 0, 6, 5,\n",
            "        2, 3, 7, 4, 5, 5, 9, 1, 9, 5, 2, 1])\n",
            "tensor([[-0.8662, -0.2379, -0.8277,  ...,  2.1340,  0.9725,  1.3662],\n",
            "        [ 0.2205,  2.1758,  0.4726,  ..., -0.6546, -0.6122, -0.6391],\n",
            "        [ 0.4563,  0.2965,  0.2270,  ..., -0.6943, -0.0370, -0.3399],\n",
            "        ...,\n",
            "        [ 0.0495,  1.4116,  0.3340,  ..., -0.5147, -0.4006, -0.5485],\n",
            "        [-0.5088, -0.4158, -0.4046,  ...,  0.8202,  1.2966,  2.4801],\n",
            "        [ 0.6589, -0.3890,  1.2210,  ..., -1.6937,  0.2141, -0.4651]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([7, 1, 6, 5, 2, 5, 7, 4, 2, 6, 2, 8, 6, 6, 8, 0, 5, 9, 5, 0, 9, 2, 0, 9,\n",
            "        6, 5, 1, 1, 4, 9, 0, 4, 4, 8, 3, 4, 3, 9, 0, 3, 0, 6, 2, 8, 3, 5, 8, 4,\n",
            "        7, 6, 4, 6, 6, 8, 0, 7, 4, 8, 1, 4, 4, 2, 8, 8, 5, 1, 8, 8, 7, 7, 2, 7,\n",
            "        6, 5, 8, 0, 8, 6, 6, 9, 8, 9, 9, 4, 8, 5, 1, 6, 3, 1, 4, 5, 5, 5, 9, 3,\n",
            "        3, 6, 3, 0, 0, 1, 2, 6, 6, 4, 2, 2, 3, 0, 3, 7, 7, 0, 9, 6, 4, 1, 1, 6,\n",
            "        3, 7, 4, 6, 1, 3, 6, 9, 3, 3, 7, 9, 7, 8, 6, 1, 6, 9, 9, 4, 8, 7, 3, 7,\n",
            "        8, 9, 0, 5, 5, 7, 0, 9, 0, 1, 7, 2, 6, 0, 8, 4, 6, 6, 4, 9, 6, 0, 5, 8,\n",
            "        1, 8, 9, 4, 3, 0, 1, 5, 2, 7, 8, 0, 2, 2, 7, 9, 4, 6, 5, 5, 6, 9, 9, 7,\n",
            "        2, 7, 0, 5, 3, 5, 0, 0, 7, 0, 4, 9, 2, 8, 8, 4, 2, 3, 5, 7, 8, 6, 8, 2,\n",
            "        1, 1, 9, 6, 0, 4, 1, 5, 9, 1, 1, 8, 5, 1, 3, 7, 8, 5, 3, 2, 2, 4, 0, 5,\n",
            "        9, 0, 8, 8, 0, 2, 6, 3, 9, 8, 6, 5, 1, 3, 5, 7, 7, 0, 7, 9, 6, 1, 3, 3,\n",
            "        1, 5, 9, 2, 7, 6, 1, 2, 7, 0, 0, 6, 3, 5, 3, 3, 9, 2, 6, 2, 6, 5, 3, 2,\n",
            "        3, 2, 6, 8, 5, 3, 6, 9, 6, 1, 9, 4])\n",
            "tensor([[ 0.9500,  0.4757,  1.0537,  ..., -1.9653, -0.1043, -0.8909],\n",
            "        [ 0.4633,  0.1847,  0.2652,  ..., -0.5301, -0.2406, -0.1979],\n",
            "        [ 1.0588, -0.4301,  1.8265,  ..., -2.0997,  0.3423, -0.4785],\n",
            "        ...,\n",
            "        [ 0.1965,  1.5026,  0.3188,  ..., -0.6256, -0.5474, -0.4473],\n",
            "        [ 0.6803, -0.2677,  1.3469,  ..., -1.7043,  0.0602, -0.4960],\n",
            "        [ 0.4694,  1.1033,  0.5377,  ..., -0.8907, -0.2528, -0.4386]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([6, 6, 2, 9, 5, 0, 3, 4, 6, 0, 0, 0, 1, 1, 1, 0, 0, 2, 7, 2, 3, 1, 4, 1,\n",
            "        8, 9, 8, 1, 6, 4, 0, 3, 1, 2, 1, 9, 9, 9, 2, 0, 5, 2, 6, 2, 6, 2, 3, 3,\n",
            "        7, 6, 6, 6, 5, 3, 7, 6, 0, 5, 8, 6, 4, 0, 5, 7, 7, 8, 2, 6, 7, 4, 9, 6,\n",
            "        9, 7, 3, 4, 7, 1, 5, 5, 2, 0, 8, 5, 1, 4, 6, 0, 4, 7, 8, 7, 9, 5, 2, 8,\n",
            "        9, 1, 8, 1, 2, 0, 9, 4, 3, 3, 3, 8, 8, 4, 1, 9, 9, 8, 1, 0, 6, 6, 2, 0,\n",
            "        0, 9, 5, 1, 5, 4, 8, 9, 0, 3, 2, 3, 2, 0, 3, 0, 3, 1, 7, 0, 1, 8, 6, 1,\n",
            "        1, 6, 5, 3, 3, 6, 6, 8, 3, 9, 2, 3, 0, 5, 7, 5, 6, 4, 0, 0, 0, 5, 8, 2,\n",
            "        5, 3, 8, 7, 8, 3, 5, 3, 8, 7, 1, 9, 4, 7, 1, 5, 2, 0, 3, 8, 2, 0, 1, 5,\n",
            "        4, 4, 3, 7, 9, 0, 1, 8, 8, 9, 7, 6, 3, 6, 6, 5, 3, 1, 2, 7, 4, 7, 5, 3,\n",
            "        4, 2, 8, 5, 9, 9, 9, 7, 1, 0, 8, 7, 8, 7, 5, 7, 1, 1, 8, 6, 6, 2, 5, 6,\n",
            "        8, 7, 6, 3, 9, 6, 2, 4, 2, 0, 6, 6, 5, 3, 3, 7, 8, 3, 6, 2, 0, 1, 2, 6,\n",
            "        3, 3, 6, 1, 6, 2, 6, 5, 4, 6, 7, 4, 3, 8, 4, 3, 9, 9, 0, 5, 3, 5, 4, 2,\n",
            "        9, 0, 1, 4, 8, 7, 9, 7, 3, 1, 4, 4])\n",
            "tensor([[ 0.7274, -0.8257,  1.8378,  ..., -2.0278,  0.4889, -0.3110],\n",
            "        [ 0.7262,  0.1230,  0.6382,  ..., -0.9559, -0.1201, -0.3465],\n",
            "        [ 1.3949, -0.6469,  1.6954,  ..., -1.9636,  0.4556, -0.2064],\n",
            "        ...,\n",
            "        [-0.8228, -0.2135, -0.8880,  ...,  2.4144,  1.1292,  1.2506],\n",
            "        [-0.4446,  0.0301, -0.5188,  ...,  1.0955,  0.3213,  0.5784],\n",
            "        [-0.8545, -0.0950, -0.7106,  ...,  1.8985,  1.1093,  1.5424]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([4, 6, 6, 3, 4, 3, 0, 3, 3, 4, 4, 4, 3, 2, 3, 0, 6, 8, 2, 7, 1, 6, 7, 3,\n",
            "        5, 1, 1, 8, 4, 4, 0, 0, 6, 9, 3, 9, 4, 8, 1, 5, 5, 8, 6, 7, 6, 0, 9, 2,\n",
            "        3, 1, 5, 5, 9, 7, 4, 2, 8, 9, 2, 1, 0, 2, 2, 6, 8, 0, 7, 8, 3, 0, 8, 1,\n",
            "        4, 7, 8, 4, 4, 8, 5, 3, 7, 0, 4, 9, 5, 8, 6, 2, 9, 7, 6, 7, 6, 7, 3, 8,\n",
            "        2, 4, 0, 6, 3, 8, 4, 0, 2, 4, 7, 2, 6, 6, 7, 1, 7, 6, 2, 1, 4, 1, 8, 1,\n",
            "        4, 1, 4, 5, 5, 2, 3, 3, 8, 5, 6, 9, 6, 0, 1, 6, 7, 8, 8, 1, 3, 6, 7, 3,\n",
            "        5, 6, 0, 1, 9, 2, 5, 3, 5, 1, 2, 2, 1, 3, 4, 4, 5, 4, 1, 0, 4, 7, 4, 6,\n",
            "        5, 2, 3, 6, 2, 0, 0, 2, 1, 2, 1, 8, 3, 1, 7, 0, 5, 6, 8, 5, 6, 3, 4, 2,\n",
            "        6, 6, 2, 0, 2, 2, 3, 1, 5, 6, 0, 4, 7, 6, 6, 3, 0, 2, 5, 7, 1, 5, 5, 8,\n",
            "        7, 6, 0, 9, 0, 7, 4, 2, 2, 7, 8, 2, 1, 6, 5, 9, 1, 3, 8, 5, 1, 8, 8, 8,\n",
            "        8, 9, 7, 8, 0, 4, 4, 2, 6, 3, 3, 1, 6, 0, 1, 3, 1, 6, 1, 9, 3, 7, 1, 0,\n",
            "        4, 8, 5, 5, 3, 0, 8, 0, 9, 2, 0, 0, 9, 0, 7, 3, 9, 8, 8, 3, 3, 5, 7, 2,\n",
            "        5, 1, 5, 0, 3, 8, 0, 1, 0, 7, 8, 9])\n",
            "tensor([[ 0.1706,  2.3388,  0.4431,  ..., -0.6864, -0.5416, -0.6595],\n",
            "        [ 0.3849,  2.0151,  0.6210,  ..., -1.0630, -0.7294, -0.7320],\n",
            "        [-0.1795,  0.3588, -0.0031,  ..., -0.0749, -0.0184, -0.0348],\n",
            "        ...,\n",
            "        [ 0.6482,  0.3803,  0.3800,  ..., -0.6411, -0.3135, -0.4130],\n",
            "        [ 0.7817,  1.4970,  0.6599,  ..., -1.4600, -0.6989, -0.9756],\n",
            "        [ 0.4404, -0.5470,  1.0861,  ..., -1.1427,  1.3196,  0.6705]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([1, 1, 3, 8, 5, 2, 5, 7, 6, 4, 3, 7, 3, 3, 9, 8, 1, 4, 9, 8, 5, 4, 5, 3,\n",
            "        3, 2, 9, 8, 9, 1, 5, 9, 8, 3, 9, 4, 7, 0, 4, 4, 2, 0, 3, 8, 2, 2, 4, 7,\n",
            "        5, 8, 1, 3, 8, 0, 2, 6, 3, 5, 7, 0, 8, 8, 7, 8, 3, 7, 1, 4, 0, 4, 6, 7,\n",
            "        2, 1, 1, 9, 1, 1, 6, 6, 9, 8, 8, 5, 6, 1, 0, 0, 9, 0, 3, 7, 2, 1, 0, 0,\n",
            "        6, 7, 5, 2, 3, 6, 2, 6, 7, 9, 1, 0, 8, 1, 4, 7, 0, 7, 1, 2, 4, 8, 3, 2,\n",
            "        3, 3, 7, 0, 3, 6, 3, 9, 6, 3, 5, 2, 7, 4, 3, 8, 3, 3, 7, 1, 4, 5, 1, 6,\n",
            "        9, 1, 1, 1, 1, 7, 1, 9, 0, 1, 4, 6, 8, 4, 5, 7, 2, 9, 2, 1, 2, 9, 5, 0,\n",
            "        7, 0, 4, 8, 4, 5, 7, 3, 7, 9, 6, 5, 6, 5, 3, 4, 1, 2, 6, 6, 5, 2, 1, 6,\n",
            "        6, 9, 7, 2, 8, 3, 2, 2, 1, 8, 5, 3, 5, 8, 9, 5, 1, 3, 5, 8, 8, 2, 6, 1,\n",
            "        6, 1, 2, 8, 8, 3, 7, 5, 2, 8, 7, 3, 3, 4, 0, 4, 5, 7, 9, 5, 9, 7, 4, 7,\n",
            "        7, 2, 9, 0, 1, 2, 6, 3, 1, 5, 8, 9, 1, 5, 1, 8, 7, 4, 3, 9, 7, 0, 3, 8,\n",
            "        0, 9, 0, 3, 5, 7, 7, 4, 2, 0, 4, 3, 0, 3, 3, 7, 8, 8, 5, 8, 7, 4, 1, 2,\n",
            "        1, 9, 5, 5, 1, 3, 4, 2, 3, 0, 3, 6])\n",
            "tensor([[-0.3588, -1.1331,  0.4811,  ..., -0.0736,  2.1994,  1.1584],\n",
            "        [ 0.1170,  1.9065,  0.2930,  ..., -0.5738, -0.4730, -0.5836],\n",
            "        [-0.6027, -0.2415, -0.5767,  ...,  0.9963,  1.0513,  1.3809],\n",
            "        ...,\n",
            "        [-0.6433, -0.1956, -0.6910,  ...,  1.2405,  0.9639,  1.7329],\n",
            "        [-0.7058, -0.1232, -0.8202,  ...,  1.8442,  0.7779,  0.9811],\n",
            "        [ 0.1118, -0.6219,  0.3442,  ..., -0.5976,  0.8781,  0.2011]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([8, 1, 7, 3, 5, 5, 5, 3, 3, 9, 3, 8, 9, 6, 2, 4, 1, 0, 2, 2, 8, 1, 1, 9,\n",
            "        3, 9, 4, 1, 5, 3, 7, 8, 2, 3, 7, 2, 3, 8, 8, 3, 4, 6, 6, 8, 3, 3, 3, 6,\n",
            "        5, 4, 2, 4, 2, 7, 0, 0, 4, 5, 8, 1, 0, 1, 6, 0, 3, 6, 9, 8, 4, 6, 1, 0,\n",
            "        1, 4, 3, 7, 7, 7, 5, 8, 1, 6, 0, 3, 5, 1, 2, 4, 2, 6, 8, 9, 2, 8, 5, 7,\n",
            "        2, 3, 1, 6, 9, 1, 1, 2, 1, 6, 3, 7, 1, 8, 8, 9, 1, 6, 7, 2, 3, 0, 6, 9,\n",
            "        5, 5, 6, 8, 7, 3, 3, 9, 0, 1, 9, 0, 9, 2, 7, 7, 3, 4, 3, 9, 9, 9, 7, 8,\n",
            "        0, 4, 1, 1, 7, 8, 5, 0, 9, 0, 1, 7, 7, 1, 5, 2, 2, 7, 1, 1, 4, 4, 3, 5,\n",
            "        2, 7, 2, 3, 5, 2, 1, 7, 4, 0, 3, 2, 4, 8, 9, 9, 6, 8, 4, 3, 7, 4, 2, 6,\n",
            "        6, 2, 2, 4, 8, 9, 9, 8, 6, 0, 3, 1, 9, 1, 6, 4, 2, 5, 9, 0, 1, 7, 0, 1,\n",
            "        2, 9, 7, 9, 0, 5, 3, 9, 6, 4, 8, 3, 5, 7, 2, 9, 7, 0, 1, 6, 9, 4, 1, 3,\n",
            "        8, 8, 4, 6, 9, 0, 7, 0, 4, 6, 9, 8, 2, 6, 2, 3, 9, 1, 6, 8, 0, 7, 5, 7,\n",
            "        6, 9, 6, 5, 3, 3, 9, 9, 0, 6, 8, 9, 7, 4, 4, 8, 9, 5, 9, 3, 7, 2, 1, 3,\n",
            "        1, 4, 0, 0, 4, 4, 2, 6, 4, 9, 7, 8])\n",
            "tensor([[-0.7651, -0.2145, -0.7628,  ...,  1.8128,  0.8634,  1.0369],\n",
            "        [-0.3392, -0.0239, -0.2753,  ...,  0.4985,  0.2725,  0.4141],\n",
            "        [ 0.7525, -0.4560,  1.2598,  ..., -1.4215,  0.7447,  0.1371],\n",
            "        ...,\n",
            "        [-0.3908,  0.0449, -0.3407,  ...,  0.5678,  0.1686,  0.2052],\n",
            "        [-0.2210, -0.3985, -0.0807,  ...,  0.1468,  0.7020,  1.8062],\n",
            "        [-0.7198,  0.0139, -0.7675,  ...,  1.7159,  0.4718,  0.7491]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([7, 5, 6, 6, 7, 6, 7, 2, 2, 7, 7, 5, 2, 2, 3, 3, 8, 0, 2, 2, 1, 9, 2, 9,\n",
            "        3, 7, 2, 1, 2, 5, 1, 7, 8, 1, 8, 0, 1, 3, 6, 6, 6, 4, 0, 8, 2, 9, 8, 5,\n",
            "        2, 0, 4, 2, 8, 2, 0, 3, 5, 4, 3, 7, 2, 5, 0, 9, 1, 9, 0, 6, 4, 2, 2, 2,\n",
            "        4, 6, 7, 1, 4, 5, 5, 6, 3, 8, 5, 6, 0, 0, 0, 0, 5, 9, 4, 1, 9, 2, 3, 8,\n",
            "        6, 6, 9, 9, 6, 9, 5, 1, 1, 6, 2, 9, 1, 5, 5, 8, 0, 8, 5, 8, 4, 5, 6, 1,\n",
            "        6, 0, 0, 9, 8, 3, 5, 1, 3, 3, 8, 2, 8, 8, 4, 5, 0, 8, 2, 6, 3, 8, 7, 1,\n",
            "        9, 1, 4, 0, 3, 6, 1, 7, 6, 1, 2, 4, 5, 6, 4, 4, 4, 9, 5, 5, 9, 3, 2, 2,\n",
            "        3, 6, 1, 6, 3, 2, 6, 9, 0, 7, 0, 8, 3, 8, 5, 6, 0, 0, 7, 3, 6, 1, 6, 5,\n",
            "        2, 8, 7, 1, 0, 7, 7, 3, 7, 5, 0, 2, 1, 4, 9, 6, 3, 2, 6, 4, 0, 3, 8, 6,\n",
            "        9, 8, 3, 3, 4, 7, 8, 4, 8, 6, 7, 5, 5, 2, 2, 7, 0, 4, 9, 5, 6, 7, 1, 7,\n",
            "        8, 7, 1, 1, 0, 5, 3, 6, 0, 0, 4, 9, 9, 7, 1, 2, 7, 4, 8, 6, 8, 6, 0, 1,\n",
            "        8, 0, 2, 9, 2, 5, 3, 4, 7, 2, 6, 6, 9, 9, 6, 1, 6, 3, 7, 1, 4, 7, 9, 4,\n",
            "        8, 1, 3, 2, 4, 2, 7, 5, 9, 5, 9, 7])\n",
            "tensor([[ 0.7909, -0.5857,  1.6868,  ..., -2.0231,  0.5759, -0.3773],\n",
            "        [ 0.7617,  1.0934,  0.5415,  ..., -1.2941, -0.4210, -0.7891],\n",
            "        [ 0.8977,  1.3078,  0.7505,  ..., -1.6544, -0.5355, -1.0185],\n",
            "        ...,\n",
            "        [ 0.6989,  0.8052,  0.8163,  ..., -1.3362, -0.3000, -0.7392],\n",
            "        [ 0.1018,  1.0930,  0.1247,  ..., -0.3471, -0.2588, -0.3033],\n",
            "        [-0.6252, -0.0067, -0.7047,  ...,  1.5312,  0.3966,  0.6783]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([2, 0, 6, 2, 8, 3, 9, 3, 7, 1, 3, 1, 0, 2, 8, 4, 1, 6, 2, 9, 6, 3, 6, 5,\n",
            "        7, 6, 1, 1, 0, 8, 4, 1, 9, 0, 6, 1, 2, 7, 2, 2, 9, 7, 0, 3, 1, 2, 9, 5,\n",
            "        0, 0, 8, 0, 5, 9, 4, 5, 9, 9, 0, 5, 2, 0, 6, 8, 5, 7, 6, 7, 2, 0, 1, 7,\n",
            "        3, 1, 9, 6, 2, 4, 9, 6, 7, 2, 9, 3, 0, 4, 7, 9, 7, 4, 7, 2, 2, 5, 1, 5,\n",
            "        4, 9, 3, 2, 9, 2, 7, 9, 4, 1, 6, 9, 4, 2, 8, 3, 4, 2, 5, 9, 9, 5, 0, 1,\n",
            "        1, 7, 9, 1, 7, 5, 8, 4, 4, 2, 9, 3, 6, 9, 3, 1, 6, 9, 2, 2, 4, 0, 6, 6,\n",
            "        6, 8, 0, 3, 1, 9, 3, 8, 7, 9, 8, 1, 5, 7, 6, 1, 0, 1, 2, 2, 8, 8, 0, 3,\n",
            "        0, 7, 5, 7, 4, 3, 2, 9, 6, 8, 7, 6, 9, 8, 9, 5, 6, 5, 2, 0, 8, 4, 0, 1,\n",
            "        3, 9, 0, 7, 6, 8, 7, 2, 1, 8, 4, 6, 3, 2, 8, 1, 2, 8, 5, 3, 1, 5, 5, 7,\n",
            "        6, 5, 5, 1, 6, 8, 7, 3, 7, 9, 2, 5, 3, 6, 0, 3, 9, 8, 1, 3, 7, 7, 4, 6,\n",
            "        4, 8, 0, 0, 7, 6, 7, 3, 1, 0, 8, 1, 1, 5, 4, 2, 3, 5, 6, 4, 2, 8, 0, 0,\n",
            "        4, 4, 8, 4, 3, 5, 1, 7, 9, 9, 6, 7, 7, 0, 5, 3, 0, 1, 5, 1, 4, 5, 2, 6,\n",
            "        1, 4, 2, 2, 0, 8, 8, 5, 1, 3, 1, 7])\n",
            "tensor([[ 0.4865, -0.2038,  0.5740,  ..., -0.9036,  0.1586, -0.1250],\n",
            "        [ 0.2470,  1.4419,  0.2258,  ..., -0.7961, -0.5137, -0.7529],\n",
            "        [ 0.2575,  2.0741,  0.4153,  ..., -0.6552, -0.5438, -0.7192],\n",
            "        ...,\n",
            "        [ 0.5633,  0.4967,  0.4514,  ..., -0.9060, -0.2221, -0.4487],\n",
            "        [-0.7362, -0.0376, -0.8031,  ...,  2.0295,  0.6120,  0.9506],\n",
            "        [-1.1719, -0.4221, -0.9317,  ...,  2.5838,  1.8002,  2.5712]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([2, 3, 1, 8, 6, 1, 6, 0, 4, 3, 7, 3, 8, 5, 1, 6, 1, 3, 7, 9, 9, 9, 7, 2,\n",
            "        7, 9, 6, 3, 8, 6, 4, 6, 9, 4, 3, 7, 9, 4, 9, 0, 7, 1, 0, 9, 4, 4, 3, 8,\n",
            "        2, 9, 7, 7, 8, 0, 2, 5, 2, 8, 2, 0, 6, 8, 6, 7, 4, 5, 6, 3, 6, 9, 5, 8,\n",
            "        4, 1, 2, 2, 7, 6, 3, 4, 2, 0, 8, 8, 7, 3, 3, 3, 5, 1, 8, 6, 2, 3, 6, 4,\n",
            "        1, 9, 9, 6, 2, 8, 8, 8, 4, 1, 8, 7, 6, 9, 6, 2, 7, 3, 4, 5, 5, 6, 5, 5,\n",
            "        8, 5, 8, 1, 1, 4, 5, 7, 6, 8, 1, 4, 8, 2, 9, 2, 2, 1, 2, 1, 8, 7, 8, 0,\n",
            "        6, 1, 5, 8, 7, 5, 5, 9, 2, 1, 6, 4, 0, 8, 6, 1, 4, 1, 9, 5, 3, 1, 2, 2,\n",
            "        4, 4, 0, 3, 0, 1, 6, 7, 6, 6, 0, 3, 0, 1, 2, 1, 7, 9, 1, 3, 8, 8, 8, 8,\n",
            "        9, 6, 5, 7, 9, 3, 9, 1, 8, 6, 2, 9, 7, 3, 0, 5, 4, 2, 3, 5, 4, 5, 7, 6,\n",
            "        2, 6, 1, 5, 0, 2, 6, 8, 8, 8, 5, 2, 7, 8, 2, 3, 6, 1, 8, 0, 2, 0, 3, 3,\n",
            "        4, 4, 5, 6, 5, 4, 1, 0, 4, 2, 6, 0, 3, 1, 6, 0, 4, 4, 1, 3, 2, 4, 0, 9,\n",
            "        8, 9, 6, 1, 3, 5, 3, 0, 3, 3, 2, 5, 2, 0, 1, 9, 0, 3, 8, 1, 3, 6, 1, 4,\n",
            "        1, 6, 4, 3, 3, 9, 9, 2, 7, 0, 7, 9])\n",
            "tensor([[ 0.1670, -0.5997,  0.8191,  ..., -0.8263,  0.4797, -0.1119],\n",
            "        [-0.2290,  0.1489, -0.2205,  ...,  0.2867,  0.1537,  0.3638],\n",
            "        [-0.8350, -1.0281, -0.0300,  ...,  1.3830,  2.6878,  1.7532],\n",
            "        ...,\n",
            "        [-1.1403, -0.2783, -1.0255,  ...,  2.7181,  1.4121,  1.6940],\n",
            "        [ 0.5464, -0.1580,  1.0624,  ..., -1.4584, -0.0148, -0.5448],\n",
            "        [-0.3651, -1.0365,  0.5415,  ..., -0.0635,  2.2208,  0.8912]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([4, 5, 8, 8, 3, 0, 9, 0, 6, 8, 1, 2, 7, 1, 3, 7, 6, 2, 7, 1, 5, 2, 4, 8,\n",
            "        4, 0, 9, 2, 5, 0, 3, 2, 4, 8, 2, 4, 3, 6, 4, 1, 8, 7, 9, 2, 3, 7, 5, 2,\n",
            "        3, 8, 5, 1, 8, 4, 7, 3, 3, 2, 5, 1, 5, 0, 2, 0, 4, 8, 2, 3, 7, 1, 4, 5,\n",
            "        9, 8, 6, 7, 7, 5, 8, 7, 1, 4, 3, 1, 6, 5, 6, 2, 0, 0, 8, 3, 8, 1, 1, 8,\n",
            "        3, 8, 9, 3, 7, 7, 0, 9, 4, 4, 3, 1, 4, 0, 2, 8, 2, 0, 6, 8, 8, 3, 1, 0,\n",
            "        1, 7, 8, 5, 5, 7, 8, 2, 4, 6, 7, 1, 9, 4, 9, 3, 6, 6, 2, 5, 2, 1, 6, 0,\n",
            "        3, 5, 6, 0, 9, 7, 2, 6, 5, 3, 2, 4, 8, 5, 4, 7, 0, 8, 7, 0, 6, 5, 4, 3,\n",
            "        5, 4, 0, 4, 5, 7, 2, 9, 5, 1, 4, 2, 2, 8, 5, 6, 7, 6, 0, 4, 3, 6, 9, 4,\n",
            "        7, 0, 5, 1, 5, 9, 2, 2, 4, 0, 3, 1, 3, 8, 7, 4, 1, 7, 4, 2, 5, 8, 3, 8,\n",
            "        7, 2, 8, 7, 6, 8, 5, 9, 7, 5, 1, 5, 4, 8, 1, 9, 8, 2, 9, 2, 9, 0, 7, 6,\n",
            "        3, 8, 0, 6, 9, 2, 8, 7, 6, 2, 5, 8, 4, 2, 0, 9, 6, 6, 1, 7, 7, 1, 7, 2,\n",
            "        8, 1, 8, 3, 1, 8, 7, 4, 6, 3, 1, 8, 3, 7, 5, 1, 7, 1, 9, 6, 8, 6, 8, 2,\n",
            "        0, 0, 1, 9, 4, 5, 2, 1, 7, 7, 6, 8])\n",
            "tensor([[-0.3349, -0.4572,  0.3087,  ..., -0.0903,  1.4757,  0.9483],\n",
            "        [ 0.6766, -0.7833,  1.4591,  ..., -1.9236,  0.5898, -0.7243],\n",
            "        [ 0.6288, -0.5628,  1.3590,  ..., -1.8954,  0.4272, -0.5589],\n",
            "        ...,\n",
            "        [-0.6755, -0.4304, -0.4953,  ...,  0.8992,  1.5056,  2.2918],\n",
            "        [ 0.8635, -0.4155,  1.8939,  ..., -1.9932,  0.3699, -0.6024],\n",
            "        [ 0.0808,  0.8745,  0.0333,  ..., -0.4520, -0.3374, -0.3190]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([8, 4, 4, 9, 5, 5, 2, 8, 9, 1, 5, 8, 8, 5, 5, 9, 8, 6, 2, 6, 7, 0, 2, 9,\n",
            "        0, 4, 4, 2, 2, 0, 1, 7, 9, 6, 3, 6, 7, 6, 2, 8, 5, 5, 3, 5, 9, 1, 4, 6,\n",
            "        2, 6, 3, 4, 3, 9, 7, 4, 3, 0, 5, 5, 1, 1, 9, 8, 0, 7, 7, 4, 5, 2, 0, 2,\n",
            "        7, 7, 3, 4, 6, 6, 1, 1, 3, 9, 6, 7, 7, 9, 8, 4, 4, 3, 9, 3, 8, 8, 2, 8,\n",
            "        7, 0, 0, 8, 8, 7, 5, 7, 6, 7, 9, 8, 2, 3, 8, 4, 6, 2, 5, 8, 7, 8, 2, 4,\n",
            "        4, 7, 2, 7, 7, 6, 9, 7, 2, 7, 4, 8, 7, 7, 8, 9, 7, 8, 8, 8, 9, 0, 9, 8,\n",
            "        1, 1, 1, 5, 0, 9, 2, 9, 8, 3, 0, 4, 4, 8, 0, 6, 6, 8, 9, 5, 2, 0, 0, 2,\n",
            "        7, 8, 5, 1, 7, 8, 7, 4, 8, 6, 8, 8, 3, 0, 1, 8, 2, 5, 9, 3, 4, 1, 1, 4,\n",
            "        4, 8, 1, 4, 3, 7, 2, 6, 0, 5, 0, 2, 8, 1, 9, 5, 5, 7, 6, 6, 9, 0, 6, 7,\n",
            "        6, 8, 5, 0, 2, 9, 3, 8, 4, 0, 9, 5, 6, 3, 6, 2, 4, 4, 9, 5, 7, 3, 1, 7,\n",
            "        1, 9, 9, 6, 9, 5, 4, 9, 7, 3, 5, 1, 8, 7, 4, 3, 5, 8, 3, 4, 6, 6, 9, 4,\n",
            "        2, 1, 3, 0, 4, 1, 8, 0, 8, 9, 3, 1, 5, 6, 0, 7, 3, 0, 5, 4, 3, 3, 5, 5,\n",
            "        8, 3, 7, 0, 6, 5, 0, 8, 0, 9, 2, 3])\n",
            "tensor([[ 0.5255, -0.9689,  1.8933,  ..., -1.9359,  0.9311, -0.4194],\n",
            "        [ 0.5356,  1.2827,  0.5224,  ..., -1.3515, -0.6961, -0.9670],\n",
            "        [-0.8625, -0.2002, -0.7151,  ...,  1.7954,  1.2615,  1.4105],\n",
            "        ...,\n",
            "        [-0.4048, -0.2746, -0.2756,  ...,  0.3451,  0.5199,  0.6647],\n",
            "        [-0.0811,  0.5629,  0.0594,  ..., -0.1745, -0.1472, -0.1757],\n",
            "        [ 1.7402,  0.5856,  0.9881,  ..., -1.7981, -0.4648, -0.9307]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([4, 3, 5, 7, 6, 0, 0, 3, 6, 6, 9, 4, 3, 7, 1, 6, 2, 5, 4, 2, 7, 0, 4, 4,\n",
            "        3, 1, 1, 2, 4, 6, 6, 2, 0, 9, 9, 6, 5, 7, 9, 4, 0, 3, 0, 3, 2, 7, 7, 5,\n",
            "        5, 9, 3, 9, 9, 2, 3, 5, 1, 2, 6, 8, 5, 3, 0, 4, 5, 2, 8, 2, 1, 2, 4, 7,\n",
            "        0, 5, 5, 9, 8, 5, 7, 0, 2, 7, 9, 4, 7, 1, 6, 3, 4, 6, 0, 8, 6, 4, 2, 4,\n",
            "        0, 6, 8, 6, 8, 9, 1, 3, 2, 6, 2, 0, 3, 7, 2, 4, 9, 0, 5, 9, 0, 0, 1, 7,\n",
            "        7, 3, 5, 5, 5, 7, 2, 9, 9, 0, 5, 1, 0, 4, 1, 5, 4, 2, 5, 7, 3, 9, 0, 9,\n",
            "        4, 1, 9, 7, 9, 2, 5, 8, 2, 8, 8, 9, 4, 9, 4, 8, 5, 4, 9, 5, 4, 8, 0, 0,\n",
            "        6, 5, 7, 9, 9, 6, 5, 9, 2, 2, 7, 3, 0, 3, 6, 8, 5, 8, 3, 3, 8, 2, 9, 2,\n",
            "        7, 3, 7, 4, 1, 0, 0, 3, 8, 7, 1, 6, 1, 5, 0, 1, 3, 5, 9, 8, 7, 9, 3, 9,\n",
            "        6, 8, 5, 3, 6, 8, 2, 2, 8, 2, 1, 0, 2, 5, 3, 2, 0, 9, 1, 1, 0, 2, 0, 0,\n",
            "        2, 4, 6, 4, 5, 4, 2, 0, 4, 6, 3, 1, 2, 4, 3, 0, 7, 7, 8, 4, 3, 0, 0, 6,\n",
            "        4, 5, 4, 3, 5, 9, 2, 9, 1, 6, 3, 9, 7, 1, 0, 8, 7, 7, 9, 7, 3, 2, 6, 4,\n",
            "        4, 3, 7, 5, 3, 8, 4, 4, 5, 5, 2, 0])\n",
            "tensor([[-9.5179e-01, -6.5205e-01, -7.5489e-01,  ...,  1.7441e+00,\n",
            "          1.9529e+00,  3.0051e+00],\n",
            "        [-8.6203e-01, -2.3695e-01, -8.8333e-01,  ...,  2.0776e+00,\n",
            "          9.0922e-01,  1.1153e+00],\n",
            "        [-7.4207e-01, -6.3894e-01, -5.4124e-01,  ...,  1.1935e+00,\n",
            "          1.7167e+00,  2.3830e+00],\n",
            "        ...,\n",
            "        [-8.8082e-01, -2.2994e-01, -8.1055e-01,  ...,  2.1778e+00,\n",
            "          8.0526e-01,  9.3253e-01],\n",
            "        [-2.1512e-03,  2.5661e-01,  1.1006e-01,  ..., -1.7781e-01,\n",
            "          1.8461e-02, -9.0139e-02],\n",
            "        [ 6.4858e-01,  2.5014e+00,  6.0419e-01,  ..., -1.1731e+00,\n",
            "         -5.5823e-01, -1.0721e+00]], grad_fn=<AddmmBackward>)\n",
            "tensor([9, 7, 9, 7, 6, 6, 4, 0, 6, 7, 8, 5, 8, 1, 8, 7, 2, 8, 3, 8, 3, 0, 1, 0,\n",
            "        2, 3, 7, 6, 3, 5, 2, 6, 0, 9, 4, 7, 7, 4, 0, 9, 6, 3, 9, 0, 1, 0, 1, 3,\n",
            "        1, 1, 4, 2, 2, 2, 9, 0, 0, 9, 0, 0, 9, 7, 5, 0, 0, 0, 7, 2, 8, 9, 1, 0,\n",
            "        1, 6, 5, 2, 6, 1, 6, 8, 9, 9, 4, 9, 2, 6, 6, 3, 3, 0, 7, 6, 4, 2, 3, 6,\n",
            "        6, 2, 0, 7, 6, 5, 8, 3, 9, 3, 8, 4, 0, 1, 7, 0, 1, 3, 8, 3, 5, 3, 7, 2,\n",
            "        1, 0, 0, 7, 9, 7, 0, 4, 6, 2, 1, 7, 7, 0, 0, 6, 2, 9, 4, 1, 9, 7, 7, 4,\n",
            "        7, 8, 7, 1, 1, 0, 7, 9, 0, 8, 6, 0, 8, 1, 7, 4, 0, 0, 7, 7, 0, 0, 8, 6,\n",
            "        7, 3, 2, 8, 5, 8, 6, 7, 5, 5, 5, 1, 2, 1, 7, 2, 0, 4, 5, 3, 1, 6, 3, 1,\n",
            "        1, 4, 8, 9, 3, 6, 5, 3, 5, 4, 4, 9, 5, 1, 6, 6, 6, 0, 0, 2, 1, 2, 5, 8,\n",
            "        0, 8, 6, 4, 0, 4, 2, 3, 0, 5, 3, 1, 9, 4, 3, 2, 6, 1, 1, 6, 4, 0, 1, 6,\n",
            "        1, 6, 2, 2, 4, 7, 2, 7, 2, 3, 1, 3, 4, 9, 6, 0, 0, 8, 5, 1, 8, 9, 9, 8,\n",
            "        6, 2, 9, 8, 3, 7, 6, 8, 1, 0, 4, 6, 8, 8, 9, 4, 2, 8, 3, 0, 2, 9, 8, 4,\n",
            "        7, 0, 3, 4, 0, 9, 7, 3, 1, 7, 2, 1])\n",
            "tensor([[ 0.1647,  1.8829,  0.2446,  ..., -0.5040, -0.4593, -0.6457],\n",
            "        [ 1.0576, -0.6139,  1.9892,  ..., -2.3071,  0.6086, -0.5338],\n",
            "        [ 1.1729,  1.4593,  0.6886,  ..., -1.8252, -0.8787, -0.9949],\n",
            "        ...,\n",
            "        [-0.0805, -0.0559, -0.0496,  ...,  0.2419,  0.3161,  0.6206],\n",
            "        [ 0.1085,  0.2150,  0.0253,  ..., -0.1954, -0.0717, -0.1276],\n",
            "        [-0.4718, -1.0297,  0.1544,  ...,  0.6113,  2.2253,  1.2880]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([1, 2, 3, 0, 2, 2, 3, 5, 5, 0, 1, 6, 7, 1, 6, 9, 7, 4, 3, 9, 9, 2, 3, 5,\n",
            "        4, 8, 2, 2, 8, 6, 3, 5, 3, 0, 4, 4, 7, 5, 0, 1, 2, 3, 1, 2, 9, 1, 9, 5,\n",
            "        0, 3, 6, 2, 8, 0, 9, 2, 8, 6, 6, 7, 3, 9, 5, 2, 1, 8, 8, 8, 2, 9, 3, 9,\n",
            "        7, 9, 4, 4, 0, 3, 9, 8, 5, 7, 2, 1, 4, 4, 8, 6, 1, 8, 4, 5, 6, 4, 2, 1,\n",
            "        1, 3, 4, 0, 6, 0, 3, 1, 4, 0, 5, 3, 3, 2, 5, 1, 8, 7, 4, 8, 6, 3, 7, 4,\n",
            "        2, 9, 5, 9, 8, 4, 5, 6, 5, 2, 6, 0, 4, 7, 5, 5, 1, 3, 7, 2, 2, 9, 5, 1,\n",
            "        6, 1, 7, 2, 6, 2, 3, 8, 9, 5, 0, 5, 5, 9, 2, 6, 2, 1, 4, 9, 4, 8, 0, 8,\n",
            "        5, 2, 6, 7, 9, 4, 9, 4, 2, 9, 1, 8, 8, 6, 8, 9, 0, 7, 9, 4, 9, 5, 6, 2,\n",
            "        1, 3, 0, 5, 6, 1, 9, 2, 6, 5, 7, 1, 0, 6, 9, 8, 8, 6, 8, 9, 4, 8, 4, 8,\n",
            "        7, 9, 7, 8, 2, 1, 3, 7, 3, 1, 7, 3, 6, 6, 1, 7, 3, 9, 2, 9, 3, 9, 7, 7,\n",
            "        8, 2, 6, 6, 5, 4, 3, 0, 2, 3, 9, 2, 1, 5, 1, 1, 6, 6, 6, 3, 6, 4, 2, 7,\n",
            "        5, 3, 0, 6, 8, 1, 8, 0, 2, 6, 1, 5, 3, 0, 6, 6, 8, 7, 4, 5, 2, 9, 4, 6,\n",
            "        8, 3, 8, 4, 8, 8, 1, 0, 5, 9, 4, 8])\n",
            "tensor([[-0.3856,  0.0542, -0.3783,  ...,  0.7299,  0.1697,  0.3242],\n",
            "        [ 0.9701,  0.8987,  0.7101,  ..., -1.3815, -0.5574, -0.7878],\n",
            "        [-1.0576, -0.3071, -1.0458,  ...,  2.8285,  1.2084,  1.4958],\n",
            "        ...,\n",
            "        [ 2.3007,  0.1810,  1.3330,  ..., -2.3672, -0.3535, -0.6875],\n",
            "        [ 0.4990, -0.2431,  0.6103,  ..., -0.8744,  0.0819, -0.2760],\n",
            "        [ 0.5321,  2.7744,  0.5659,  ..., -1.2039, -0.9258, -1.0691]],\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([5, 6, 7, 7, 8, 6, 7, 3, 1, 8, 8, 0, 1, 9, 6, 5, 9, 3, 6, 7, 7, 7, 4, 6,\n",
            "        1, 4, 3, 7, 9, 0, 6, 0, 7, 6, 0, 4, 0, 0, 9, 1, 6, 1, 0, 8, 9, 7, 3, 9,\n",
            "        0, 3, 4, 1, 7, 6, 7, 1, 7, 1, 1, 4, 8, 0, 4, 6, 8, 4, 9, 6, 3, 2, 7, 2,\n",
            "        3, 9, 3, 7, 3, 8, 6, 0, 2, 6, 2, 1, 4, 9, 0, 6, 9, 0, 3, 8, 7, 4, 2, 5,\n",
            "        6, 2, 7, 7, 0, 5, 5, 4, 2, 6, 3, 5, 1, 3, 8, 9, 8, 8, 5, 5, 0, 2, 2, 0,\n",
            "        1, 2, 2, 5, 9, 0, 8, 0, 5, 9, 4, 4, 0, 1, 2, 5, 9, 4, 6, 2, 2, 2, 1, 3,\n",
            "        1, 2, 6, 6, 0, 2, 4, 8, 2, 5, 5, 5, 0, 7, 5, 2, 9, 8, 9, 9, 9, 3, 7, 6,\n",
            "        5, 3, 3, 7, 3, 3, 9, 0, 6, 5, 5, 6, 3, 8, 4, 6, 3, 8, 6, 5, 4, 6, 0, 2,\n",
            "        5, 6, 2, 1, 9, 1, 4, 2, 9, 8, 3, 5, 2, 6, 2, 3, 2, 6, 4, 4, 3, 7, 7, 0,\n",
            "        5, 8, 2, 9, 4, 2, 3, 7, 7, 3, 7, 7, 4, 6, 1, 7, 5, 2, 1, 9, 1, 9, 1, 8,\n",
            "        0, 7, 3, 9, 9, 8, 2, 0, 0, 4, 8, 9, 6, 2, 0, 8, 5, 4, 2, 5, 7, 5, 1, 4,\n",
            "        4, 7, 2, 8, 1, 8, 6, 4, 1, 9, 7, 3, 9, 1, 9, 2, 6, 9, 6, 1, 9, 7, 4, 3,\n",
            "        9, 1, 2, 6, 5, 0, 9, 2, 1, 0, 2, 1])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-4a5b8788c965>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-38dd3a1934f8>\u001b[0m in \u001b[0;36mrun\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbest_measure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbestweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;31m# print(metrics)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mnn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbestweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-652c6ddc475c>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, device, optimizer, num_epochs, train_loader, val_loader, test_loader, criterion)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0macc_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_loss_val\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-e487a502a516>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, device, criterion, epoch, train_loader, optimizer)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNormalized\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \"\"\"\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m     \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXtOrSEReEP2",
        "colab_type": "text"
      },
      "source": [
        "# Part 3\n",
        "\n",
        "Selecting the model based on all epochs of the test dataset will cause the model to be biased towards the test values which may not give a good fitting to other test sets. The validation set is a part of the training set that ensures the model is training well on the training data and thus we should be using models with good parameters after validating on the validation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfQqkslhSlKL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}