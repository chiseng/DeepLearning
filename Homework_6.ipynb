{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Homework 6.1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "pv5qavwt0qPC",
        "colab_type": "code",
        "outputId": "65be0cbd-d3fc-439a-b3b3-1a6573c2276b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFChrBSV026I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# root_dir = \"/content/gdrive/My Drive/PDF slides/Term 7/50.039 Theory and practice of Deep Learning/HW5\"\n",
        "root_dir = \"/content/gdrive/My Drive/\" #CS root dir\n",
        "\n",
        "from zipfile import ZipFile\n",
        "import os\n",
        "\n",
        "if not os.path.exists(\"data\"):\n",
        "    with ZipFile(os.path.join(root_dir, 'data.zip'), 'r') as zipObj:\n",
        "    # Extract all the contents of zip file in current directory\n",
        "        zipObj.extractall()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62MX9_i12Zeo",
        "colab_type": "text"
      },
      "source": [
        "# Preprocess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrQJ7cCc2ajZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import glob\n",
        "import os\n",
        "import torch\n",
        "import unicodedata\n",
        "import string\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "class utils:\n",
        "    def __init__(self):\n",
        "        self.path = 'data/names/*.txt'\n",
        "        self.all_letters = string.ascii_letters + \" .,;'\"\n",
        "        self.n_letters = len(self.all_letters)\n",
        "        self.category_lines = {}\n",
        "        self.all_categories = []\n",
        "\n",
        "        for filename in glob.glob(self.path):\n",
        "            category = os.path.splitext(os.path.basename(filename))[0]\n",
        "            self.all_categories.append(category)\n",
        "            lines = self.readLines(filename)\n",
        "            self.category_lines[category] = lines\n",
        "\n",
        "        self.n_categories = len(self.all_categories)\n",
        "\n",
        "    # Turn a Unicode string to plain ASCII, thanks to https://stackoverflow.com/a/518232/2809427\n",
        "    def unicodeToAscii(self,s):\n",
        "        return ''.join(\n",
        "            c for c in unicodedata.normalize('NFD', s)\n",
        "            if unicodedata.category(c) != 'Mn'\n",
        "            and c in self.all_letters\n",
        "        )\n",
        "    # Build the category_lines dictionary, a list of names per language\n",
        "    \n",
        "    # Read a file and split into lines\n",
        "    def readLines(self, filename):\n",
        "        lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n",
        "        return [self.unicodeToAscii(line) for line in lines]\n",
        "\n",
        "    # Find letter index from all_letters, e.g. \"a\" = 0\n",
        "    def letterToIndex(self,letter):\n",
        "        return self.all_letters.find(letter)\n",
        "\n",
        "    # Just for demonstration, turn a letter into a <1 x n_letters> Tensor\n",
        "    def letterToTensor(self,letter):\n",
        "        tensor = torch.zeros(1, self.n_letters)\n",
        "        tensor[0][self.letterToIndex(letter)] = 1\n",
        "        return tensor\n",
        "\n",
        "    # Turn a line into a <line_length x 1 x n_letters>,\n",
        "    # or an array of one-hot letter vectors\n",
        "    def lineToTensor(self,line):\n",
        "        tensor = torch.zeros(len(line), 1, self.n_letters)\n",
        "        for li, letter in enumerate(line):\n",
        "            tensor[li][0][self.letterToIndex(letter)] = 1\n",
        "        return tensor\n",
        "\n",
        "    def category_to_tensor(self, category):\n",
        "        return torch.tensor([self.all_categories.index(category)], dtype=torch.long)\n",
        "\n",
        "    def batch_categoryFromOutput(self, output):\n",
        "        # print(output)\n",
        "        output_tensor = torch.unbind(output, dim=0)\n",
        "        ret_val = []\n",
        "        for outp in output_tensor:\n",
        "            top_n, top_i = outp.topk(1,0)\n",
        "            category_i = top_i[0].item()\n",
        "            ret_val.append(category_i)\n",
        "        return ret_val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fc8K5o2l6hgD",
        "colab_type": "text"
      },
      "source": [
        "# Define model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhlBzJiV4CZ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(RNN, self).__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
        "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        combined = torch.cat((input, hidden), 1)\n",
        "        hidden = self.i2h(combined)\n",
        "        output = self.i2o(combined)\n",
        "        output = self.softmax(output)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, self.hidden_size)\n",
        "\n",
        "class LSTM_batchy(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, num_layers):\n",
        "        super(LSTM_batchy, self).__init__()\n",
        "        \n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=-1)\n",
        "\n",
        "    def forward(self, input, hidden_states):\n",
        "        h0, c0 = hidden_states\n",
        "        output, (hn, cn) = self.lstm(input, (h0,c0))\n",
        "        output = self.out(output)\n",
        "        output = self.softmax(output)\n",
        "        return output, (hn, cn)\n",
        "\n",
        "    def initHidden(self, batch_size):\n",
        "        # return h0, c0\n",
        "        self.batch_size = batch_size\n",
        "        return (torch.zeros(self.num_layers*1, self.batch_size, self.hidden_size), torch.zeros(self.num_layers*1, self.batch_size, self.hidden_size))\n",
        "\n",
        "class GRU(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(GRU, self).__init__()\n",
        "        \n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.gru = nn.GRU(input_size, hidden_size, 1)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=-1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        output, hidden = self.gru(input, hidden)\n",
        "        output = self.out(output)\n",
        "        output = self.softmax(output)\n",
        "        # print(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self, batch_size):\n",
        "        self.batch_size = batch_size\n",
        "        return torch.zeros(1, self.batch_size, self.hidden_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6lg76gr9c3S",
        "colab_type": "text"
      },
      "source": [
        "# Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcmJM9pH8LPD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "\n",
        "def randomChoice(l):\n",
        "    return l[random.randint(0, len(l) - 1)]\n",
        "\n",
        "def randomTrainingExample():\n",
        "    category = randomChoice(all_categories)\n",
        "    line = randomChoice(category_lines[category])\n",
        "    category_tensor = torch.tensor([all_categories.index(category)], dtype=torch.long)\n",
        "    line_tensor = lineToTensor(line)\n",
        "    return category, line, category_tensor, line_tensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMo2Udbmjfpl",
        "colab_type": "text"
      },
      "source": [
        "# Training the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iL6P_orZ9fm8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_lstm(criterion, model, device, optimizer, category_tensor, line_tensor, batch_size):\n",
        "    hidden, cell = model.initHidden(batch_size)\n",
        "    model.train()\n",
        "    model.zero_grad()\n",
        "    hidden, cell = hidden.to(device), cell.to(device)\n",
        "    output, (hidden, cell) = model(line_tensor, (hidden, cell))\n",
        "    output = output[-1]\n",
        "    # print(output.shape, category_tensor.shape)\n",
        "    # print(\"out:\", output.shape, \"out squeeze: \", output.squeeze(1).shape, \"category:\", category_tensor.shape, \"hidden:\", hidden.shape, \"cell state:\", cell.shape)\n",
        "    loss = criterion(output.squeeze(1), category_tensor)\n",
        "    loss.backward()\n",
        "\n",
        "    # Add parameters' gradients to their values, multiplied by learning rate\n",
        "    # for p in model.parameters():\n",
        "    #     p.data.add_(-learning_rate, p.grad.data)\n",
        "    optimizer.step()\n",
        "\n",
        "    return output, loss.item()\n",
        "\n",
        "def train_gru(criterion, model, device, optimizer, category_tensor, line_tensor, batch_size):\n",
        "    model.train()\n",
        "    hidden = model.initHidden(batch_size)\n",
        "    # print(hidden.shape)\n",
        "    model.zero_grad()\n",
        "\n",
        "    hidden = hidden.to(device)\n",
        "    output, hidden = model(line_tensor, hidden)\n",
        "    output = output[-1]\n",
        "\n",
        "    # print(output.shape, hidden.shape)\n",
        "\n",
        "    loss = criterion(output, category_tensor)\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "    return output, loss.item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-S1na2WGaPcg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define dataloader\n",
        "import os\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "\n",
        "class nameLanguageDataset(Dataset):\n",
        "    \"\"\" Name Language Dataset \"\"\"\n",
        "\n",
        "    def __init__(self, language_name_dict, dataset_type, train_ratio, transform=None):\n",
        "        self.keys = language_name_dict.keys()\n",
        "        self.names = []\n",
        "        self.labels = []\n",
        "        self.dataset_type = dataset_type\n",
        "        self.train_ratio = train_ratio\n",
        "        self.transform=transform\n",
        "        self.utils = utils()\n",
        "\n",
        "        for key in self.keys:\n",
        "            for label in language_name_dict[key]:\n",
        "                self.names.append(label)\n",
        "                self.labels.append(key)\n",
        "\n",
        "        z = list(zip(self.names, self.labels))\n",
        "        random.shuffle(z)\n",
        "        self.names[:], self.labels[:] = zip(*z)\n",
        "\n",
        "        self.split_index = int(len(self.names)*train_ratio)\n",
        "        self.test_split_index = int(len(self.names)*(1+train_ratio)/2)\n",
        "        self.names_train, self.names_val, self.names_test = self.names[:self.split_index], self.names[self.split_index:self.test_split_index], self.names[self.test_split_index:]\n",
        "        self.labels_train, self.labels_val, self.labels_test = self.labels[:self.split_index], self.labels[self.split_index:self.test_split_index], self.labels[self.test_split_index:]\n",
        "\n",
        "    def __len__(self):\n",
        "        if self.dataset_type == \"train\":\n",
        "            return len(self.names_train)\n",
        "        elif self.dataset_type == \"test\":\n",
        "            return len(self.names_test)\n",
        "        elif self.dataset_type == \"val\":\n",
        "            return len(self.names_val)\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.dataset_type == \"train\":\n",
        "            name = self.names_train[idx]\n",
        "            label = self.labels_train[idx]\n",
        "            sample = (label, name, self.utils.category_to_tensor(label), self.utils.lineToTensor(name))\n",
        "\n",
        "            return sample\n",
        "\n",
        "        elif self.dataset_type == \"val\":\n",
        "            name = self.names_val[idx]\n",
        "            label = self.labels_val[idx]\n",
        "            sample = (label, name, self.utils.category_to_tensor(label), self.utils.lineToTensor(name))\n",
        "\n",
        "            return sample\n",
        "\n",
        "        elif self.dataset_type == \"test\":\n",
        "            name = self.names_test[idx]\n",
        "            label = self.labels_test[idx]\n",
        "\n",
        "            sample = (label, name, self.utils.category_to_tensor(label), self.utils.lineToTensor(name))\n",
        "\n",
        "            return sample\n",
        "\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "# from torch.autograd import Variable\n",
        "import math\n",
        "\n",
        "# create iterator to return batch size of tensors\n",
        "class iteratefromDict():\n",
        "    def __init__(self, dataset, batch_size):\n",
        "        self.dataset = dataset\n",
        "        self.batch_size = batch_size\n",
        "        self.count = 0\n",
        "\n",
        "    def __iter__(self):\n",
        "        return self\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)//self.batch_size + math.ceil(len(self.dataset) % self.batch_size)\n",
        "\n",
        "    def __next__(self):\n",
        "        if self.count == len(self.dataset):\n",
        "            self.count = 0\n",
        "            raise StopIteration()\n",
        "\n",
        "        else:\n",
        "            if len(self.dataset) - self.count < self.batch_size:\n",
        "                self.batch_size = len(self.dataset) - self.count\n",
        "            samples = [self.dataset[self.count+i][3] for i in range(0, self.batch_size)]\n",
        "            labels = [self.dataset[self.count+i][2] for i in range(0, self.batch_size)]\n",
        "\n",
        "            self.count += self.batch_size\n",
        "            \n",
        "            mini_batch_sample = pad_sequence(samples, padding_value = 0).squeeze(2)\n",
        "            mini_batch_label = torch.Tensor(labels).long()\n",
        "\n",
        "            return mini_batch_sample, mini_batch_label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFDelDGbHoCy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def eval_model(model, model_type, device, criterion, batch_size, category_tensor, line_tensor):\n",
        "    model.eval()\n",
        "    if model_type == \"gru\":\n",
        "        hidden = model.initHidden(batch_size)\n",
        "        hidden = hidden.to(device)\n",
        "        with torch.no_grad():\n",
        "            output, hidden = model(line_tensor, hidden)\n",
        "            \n",
        "    else:\n",
        "        hidden, cell = model.initHidden(batch_size)\n",
        "        hidden = hidden.to(device)\n",
        "        cell = cell.to(device)\n",
        "        with torch.no_grad():\n",
        "            output, (hidden, cell) = model(line_tensor, (hidden, cell))\n",
        "\n",
        "    output = output[-1]\n",
        "    loss = criterion(output.squeeze(1), category_tensor)\n",
        "    \n",
        "        \n",
        "    return output, loss.item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eW8vf3zkCHfF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def eval_phase(dataloader, device, model, model_type, criterion):\n",
        "    \n",
        "    best_weights = None\n",
        "    best_loss = 1000\n",
        "    for iter, data in enumerate(dataloader):\n",
        "        line_tensor, category_tensor = data[0].to(device), data[1].to(device)\n",
        "        output, loss = eval_model(model, model_type, device, criterion, data[0].shape[1], category_tensor, line_tensor)\n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZbRS3lLD2EL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_phase(trainloader, device, model, model_type, criterion, optimizer):\n",
        "    train_loss = []\n",
        "    for iter, data in enumerate(trainloader):\n",
        "        line_tensor, category_tensor = data[0].to(device), data[1].to(device)\n",
        "        if model_type == \"lstm\":\n",
        "            output, loss = train_lstm(criterion, model, device, optimizer, category_tensor, line_tensor, data[0].shape[1])\n",
        "        elif model_type == \"gru\":\n",
        "            # todo: change to GRU method\n",
        "            output, loss = train_gru(criterion, model, device, optimizer, category_tensor, line_tensor, data[0].shape[1])\n",
        "        train_loss.append(loss)\n",
        "    return np.mean(train_loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAehJNQbF46S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_phase(util_class, dataloader, device, model, model_type, criterion):\n",
        "    best_weights = None\n",
        "    best_loss = 1000\n",
        "    correct = 0\n",
        "    test_loss = []\n",
        "    total = 0\n",
        "    for iter, data in enumerate(dataloader):\n",
        "        line_tensor, category_tensor = data[0].to(device), data[1].to(device)\n",
        "        total += data[0].shape[1]\n",
        "        output, loss = eval_model(model, model_type, device, criterion, data[0].shape[1], category_tensor, line_tensor)\n",
        "        category = util_class.batch_categoryFromOutput(output)\n",
        "        batch_correct = (torch.tensor(category) == category_tensor.cpu()).sum()\n",
        "        correct += batch_correct\n",
        "        test_loss.append(loss)\n",
        "    acc = correct/float(total)\n",
        "    return np.mean(test_loss), acc.data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCcsOI24dCno",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "\n",
        "# name_lang_dataset_train = nameLanguageDataset(util_class.category_lines, \"train\", 0.8)\n",
        "# name_lang_dataset_val = nameLanguageDataset(util_class.category_lines, \"val\", 0.8)\n",
        "# name_lang_dataset_test = nameLanguageDataset(util_class.category_lines, \"test\", 0.8)\n",
        "\n",
        " \n",
        "def train_test(util_class, model, model_type, device, dataset, batch_size, epochs):\n",
        "    model.to(device)\n",
        "    criterion = nn.NLLLoss()\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=0.005)\n",
        "    \n",
        "    total = 0\n",
        "    epochs_train_loss = []\n",
        "    epochs_test_loss = []\n",
        "    epochs_test_acc = []\n",
        "    best_loss = 1000\n",
        "    epoch_test_loss = []\n",
        "    epoch_test_accuracy = []\n",
        "\n",
        "    # define datasets\n",
        "    name_lang_dataset_train = nameLanguageDataset(dataset, \"train\", 0.8)\n",
        "    name_lang_dataset_val = nameLanguageDataset(dataset, \"val\", 0.8)\n",
        "    name_lang_dataset_test = nameLanguageDataset(dataset, \"test\", 0.8)\n",
        "\n",
        "    # define dataloaders\n",
        "    trainloader = iteratefromDict(name_lang_dataset_train, batch_size)\n",
        "    valloader = iteratefromDict(name_lang_dataset_val, batch_size)\n",
        "    testloader = iteratefromDict(name_lang_dataset_test, batch_size)\n",
        "    \n",
        "    best_weights = None\n",
        "    best_loss = 1000\n",
        "\n",
        "    # starting of train val test loop\n",
        "    for step in range(epochs):\n",
        "        print('\\n')\n",
        "        print(\"Epoch %i\" % step)\n",
        "        print(\"=\"*10)\n",
        "        train_loss = []\n",
        "        val_loss = []\n",
        "        current_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        # train loop\n",
        "        \n",
        "            \n",
        "        loss_per_epoch = train_phase(trainloader, device, model, model_type, criterion, optimizer)\n",
        "        epochs_train_loss.append(loss_per_epoch)\n",
        "        print(\"Current training loss: %f at epoch %i\" % (loss_per_epoch, step))\n",
        "            \n",
        "        # validation phase\n",
        "        \n",
        "        loss = eval_phase(valloader, device, model, model_type, criterion)\n",
        "        print(\"Current val loss: %f at epoch: %i\" % (loss, step))\n",
        "\n",
        "        test_loss, test_acc = test_phase(util_class, testloader, device, model, model_type, criterion)\n",
        "        print(\"Test loss: %f , test accuracy %f at epoch: %i\" % (test_loss, test_acc, step))\n",
        "\n",
        "        epochs_test_loss.append(test_loss)\n",
        "        epochs_test_acc.append(test_acc)\n",
        "    return epochs_test_loss, epochs_train_loss, epochs_test_acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwRQfm-nB2bH",
        "colab_type": "text"
      },
      "source": [
        "# Task 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xP7Y4KoJfIZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def taskA():\n",
        "    util_class = utils()\n",
        "    lstm_metrics = {}\n",
        "    gru_metrics = {}\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    n_hidden = [128, 256]\n",
        "    epochs = 8\n",
        "    # rnn = RNN(util_class.n_letters, n_hidden, util_class.n_categories)\n",
        "    for i in range(1,3):\n",
        "        lstm_metrics[i] = {}\n",
        "        if i == 1:\n",
        "            gru_metrics[i] = {}\n",
        "        for j in n_hidden:\n",
        "            print(\"=\"*20)\n",
        "            print(\"Layer: %i , hidden layer size: %i\" % (i, j))\n",
        "            print(\"=\"*20)\n",
        "            if i == 1:\n",
        "                print(\"++++++++++\")\n",
        "                print(\"+GRU phase\")\n",
        "                print(\"++++++++++\")\n",
        "                gru_batch = GRU(util_class.n_letters, j, util_class.n_categories)\n",
        "                gepochs_test_loss, gepochs_train_loss, gepochs_test_acc = train_test(util_class, gru_batch, \"gru\", device, util_class.category_lines, 1, epochs)\n",
        "                gru_metrics[i][j] = {\"epoch_test_loss\": gepochs_test_loss, \"epochs_train_loss\": gepochs_train_loss, \"epochs_test_acc\": gepochs_test_acc}\n",
        "                print(\"=\"*40)\n",
        "                print(\"++++++++++\")\n",
        "                print(\"+LSTM phase\")\n",
        "                print(\"++++++++++\")\n",
        "            lstm_batch = LSTM_batchy(util_class.n_letters, j, util_class.n_categories, i)\n",
        "            epochs_test_loss, epochs_train_loss, epochs_test_acc = train_test(util_class, lstm_batch, \"lstm\", device, util_class.category_lines, 1, epochs)\n",
        "            lstm_metrics[i][j] = {\"epoch_test_loss\": epochs_test_loss, \"epochs_train_loss\": epochs_train_loss, \"epochs_test_acc\":epochs_test_acc}\n",
        "    return lstm_metrics, gru_metrics\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mp8jKZoIyHVh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_taskA(lstm_met, gru_met):\n",
        "    layer_nums = [1, 2]\n",
        "    hidden_nums = [128, 256]\n",
        "    for layers in layer_nums:\n",
        "        for hidden_num in hidden_nums:\n",
        "            plt.plot(lstm_met[layers][hidden_num]['epochs_test_acc'])\n",
        "            plt.title(f\"LSTM {layers} layer(s), {hidden_num} hidden\")\n",
        "            plt.show()\n",
        "    plt.plot(gru_met[1][128]['epochs_test_acc'])\n",
        "    plt.title(f\"GRU 1 layer, 128 hidden\")\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uzhTXsHLG1H",
        "colab_type": "code",
        "outputId": "d38c4d07-d816-49a2-d492-147e842243cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 526
        }
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "    lstm_metrics, gru_metrics = taskA()\n",
        "    plot_taskA(lstm_metrics, gru_metrics)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "====================\n",
            "Layer: 1 , hidden layer size: 128\n",
            "====================\n",
            "++++++++++\n",
            "+GRU phase\n",
            "++++++++++\n",
            "\n",
            "\n",
            "Epoch 0\n",
            "==========\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-3e954276cd76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mlstm_metrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgru_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtaskA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mplot_taskA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_metrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgru_metrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-9ed657b9f84f>\u001b[0m in \u001b[0;36mtaskA\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"++++++++++\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0mgru_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGRU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutil_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_letters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutil_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_categories\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                 \u001b[0mgepochs_test_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgepochs_train_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgepochs_test_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutil_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgru_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"gru\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutil_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategory_lines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m                 \u001b[0mgru_metrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"epoch_test_loss\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgepochs_test_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"epochs_train_loss\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgepochs_train_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"epochs_test_acc\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgepochs_test_acc\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-aea2d94f1050>\u001b[0m in \u001b[0;36mtrain_test\u001b[0;34m(util_class, model, model_type, device, dataset, batch_size, epochs)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mloss_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0mepochs_train_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_per_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Current training loss: %f at epoch %i\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mloss_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-ebd420cc8082>\u001b[0m in \u001b[0;36mtrain_phase\u001b[0;34m(trainloader, device, model, model_type, criterion, optimizer)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmodel_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"gru\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0;31m# todo: change to GRU method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_gru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-08bad8ed7afb>\u001b[0m in \u001b[0;36mtrain_gru\u001b[0;34m(criterion, model, device, optimizer, category_tensor, line_tensor, batch_size)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsdaZEiVB9xB",
        "colab_type": "text"
      },
      "source": [
        "# Task 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXDm1q2RuFX_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def taskB():\n",
        "    util_class = utils()\n",
        "    lstm_metrics = {}\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    n_hidden = 128\n",
        "    n_layer = 1\n",
        "    epochs = 10\n",
        "    batch_sizes = [1,10,30]\n",
        "    for batch_size in batch_sizes:\n",
        "        lstm_batch = LSTM_batchy(util_class.n_letters, n_hidden, util_class.n_categories, n_layer)\n",
        "        epochs_test_loss, epochs_train_loss, epochs_test_acc = train_test(util_class, lstm_batch, \"lstm\", device, util_class.category_lines, batch_size, epochs)\n",
        "        lstm_metrics[batch_size] = {\"epochs_test_loss\": epochs_test_loss, \"epochs_train_loss\": epochs_train_loss, \"epochs_test_acc\":epochs_test_acc}\n",
        "    return lstm_metrics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYQg4KWT1W_U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_taskB(lstm_metrics):\n",
        "    batch_sizes = [1,10,30]\n",
        "    metrics = ['epochs_test_acc', 'epochs_train_loss', 'epochs_test_loss']\n",
        "    for batch_size in batch_sizes:\n",
        "        for metric in metrics:\n",
        "            plt.plot(lstm_metrics[batch_size][metric])\n",
        "            plt.title(f\"LSTM trained on batch size {batch_size}. Metric: {metric}\")\n",
        "            plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNhowDZ-vHhh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "    lstm_metrics = taskB()\n",
        "    plot_taskB(lstm_metrics)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTLBkjTk_laW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}